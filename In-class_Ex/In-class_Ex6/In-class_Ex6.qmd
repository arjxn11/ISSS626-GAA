---
title: "In Class Exercise 6"
author: "Arjun Singh"
date: 2024-09-30
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
  warning: false
format:
  html:
    css: styles.css 
---

# 6 Introduction

In this in-class exercise, we will reinforce our learning from Hands-on Exercise 6 and conduct Emerging Hot/Cold Spot Analysis.

For this exercise we will use Hunan GDPPC data.

::: insights-box
Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:

-   Building a space-time cube,
-   Calculating Getis-Ord local Gi\* statistic for each bin by using an FDR correction,
-   Evaluating these hot and cold spot trends by using Mann-Kendall trend test,
-   Categorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.
:::

# 6.1 Data and Packages

We first import the necessary packages using the p_load() function of the pacman package.

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, plotly, Kendall)
set.seed(1234)
```

The data that we use for this exercise are as follows:

-   Hunan, which is a geospatial dataset in ESRI shapefile format.

-   Hunan_GDPPC, attribute data in csv format.

We now import the Hunan Shapefile data into our environment using the st_read() function of the sf package.

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

We now import the aspatial data, Hunan_GDPPC into our environment using the read_csv() function.

```{r}
GDPPC <- read_csv("data/aspatial/Hunan_GDPPC.csv")
```

# 6.2 Creating a Space-Time Cube

We now use the [`spacetime()`](https://sfdep.josiahparry.com/reference/spacetime.html) function of the sfdep package to create a spatio-temporal cube.

```{r}
GDPPC_st <- spacetime(GDPPC, hunan,
                      .loc_col = "County",
                      .time_col = "Year")
```

To verify if the cube has been create, we implement the is_spacetime_cube() function of the sfdep package as shown in the code chunk eblow.

```{r}
is_spacetime_cube(GDPPC_st)
```

Based on the above output, we can confirm that it has been created as intended.

# 6.3 Computing Local Gi statistics

## 6.3.1 Deriving the Spatial Weights

We implement the below code chunk to identify neighbors and calculate the inverse-distance weights.

```{r}
GDPPC_nb <- GDPPC_st %>%
  activate("geometry") %>%
  mutate(nb = include_self(
    st_contiguity(geometry)),
    wt = st_inverse_distance(nb, 
                             geometry, 
                             scale = 1,
                             alpha = 1),
    .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```

::: insights-box
-   `activate()` of dplyr package is used to activate the geometry context
-   `mutate()` of dplyr package is used to create two new columns *nb* and *wt*.
-   Then we will activate the data context again and copy over the nb and wt columns to each time-slice using `set_nbs()` and `set_wts()`
    -   row order is very important so do not rearrange the observations after using `set_nbs()` or `set_wts()`.
:::

## 6.3.2 Computing Gi

We can use these new columns to manually calculate the local Gi for each location. We do this by grouping by *Year* and using the `local_gstar_perm()` function of the sfdep package. After this, we use the `unnest()` function to unnest the *gi_star* column of the newly created *gi_starts* data.frame.

```{r}
gi_stars <- GDPPC_nb %>% 
  group_by(Year) %>% 
  mutate(gi_star = local_gstar_perm(
    GDPPC, nb, wt)) %>% 
  tidyr::unnest(gi_star)
```

## 6.3.3 Mann-Kendall Test

We the above Gi calculations, we can now conduct the Mann-Kendall test to evaluate each location for a trend.

In the code chunk below, we use Changsha,

```{r}
cbg <- gi_stars %>% 
  ungroup() %>% 
  filter(County == "Changsha") |> 
  select(County, Year, gi_star)
```

We can now produce a plot by using the ggplot package.

```{r}
ggplot(data = cbg, 
       aes(x = Year, 
           y = gi_star)) +
  geom_line() +
  theme_light()
```

Alternatively, we can also create an interactive plot using the ggplotly() function of the plotly package.

```{r}
p <- ggplot(data = cbg, 
       aes(x = Year, 
           y = gi_star)) +
  geom_line() +
  theme_light()

ggplotly(p)
```

### 6.3.3.1 Mann-Kendall Test Report

We implement the below code chunk to obtain the required report.

```{r}
cbg %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

::: note-box
Note that `sl`in the output above is the p-value in this situation.
:::

From the above output, we can infer that there is a slight upward but insignificant trend.

### 6.3.3.2 Mann-Kendall Test Data-Frame

We can perform the above steps for every location by using the group_by() function of the dplyr package.

```{r}
ehsa <- gi_stars %>%
  group_by(County) %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>%
  tidyr::unnest_wider(mk)
head(ehsa)
```

We can sort the data-frame to highlight emerging hot/cold spots by implementing the below code chunk.

```{r}
emerging <- ehsa %>% 
  arrange(sl, abs(tau)) %>% 
  slice(1:10)
head(emerging)
```

# 6.4 Emerging hot/cold spot analysis

We now perform EHSA by using the [`emerging_hotspot_analysis()`](https://sfdep.josiahparry.com/reference/emerging_hotspot_analysis.html) function of the sfdep package.

It takes a spacetime object x (i.e. `GDPPC_st`), and the quoted name of the variable of interest (i.e. GDPPC) as the .var argument.

The `k` argument is used to specify the number of time lags which is set to 1 by default.

`nsim` is number of simulations to be performed.

```{r}
ehsa <- emerging_hotspot_analysis(
  x = GDPPC_st, 
  .var = "GDPPC", 
  k = 1, 
  nsim = 99
)
```

## 6.4.1 Visualizing the distribution of EHSA Classes

We now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.

```{r}
ggplot(data = ehsa,
       aes(x = classification)) +
  geom_bar()
```

The figure above shows that the 'sporadic coldspot' class has a high number of county's.

## 6.4.2 Visualizing EHSA 

Before we can proceed with visualization, we need to join both *hunan* and *ehsa* together by using the code chunk below.

```{r}
hunan_ehsa <- hunan %>%
  left_join(ehsa,
            by = join_by(County == location))
```

We can now implement functions of the tmap package to produce a visualization for the above.

```{r}
ehsa_sig <- hunan_ehsa  %>%
  filter(p_value < 0.05)
tmap_mode("plot")
tm_shape(hunan_ehsa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(ehsa_sig) +
  tm_fill("classification") + 
  tm_borders(alpha = 0.4)
```
