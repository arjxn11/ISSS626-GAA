[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "",
    "text": "In this Hands-On Exercise we are going to focus on computing spatial weights using appropriate functions of the spdep package on R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#performing-relational-joins",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#performing-relational-joins",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.2.1 Performing relational joins",
    "text": "4.2.1 Performing relational joins\nWe will proceed to join this to the simple feature data-frame, hunan, obtained above using a relational join technique.\nThe left_join() function of the dplyr package is used as shown in the code chunk below.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen-contiguity-based-neighbors",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.4.1 Computing (QUEEN) contiguity based neighbors",
    "text": "4.4.1 Computing (QUEEN) contiguity based neighbors\nWe use the poly2nb() function as shown in the code chunk below. Using this, we are able to compute a Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the output above, we can infer that there are 88 area units in total in Hunan. The most connected area unit has 11 neighbors. There are two area units with just 1 neighbor, while 24 area units have 5 neighbors.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygo in the object.\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors as shown above. The numbers in the output represent the polygon IDs as stored in the Hunan SpatialPolygonsDataFrame class.\n\nWe can retrieve the county name of selected polygon IDs by using the code chunk below. In the below example, we retrieve the county name for the county with Polygon-ID=1.\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe name of the county with Polygon-ID 1 is Anxiang.\n\nTo retrieve the name of the 5 neighboring polygons, the below code chunk is used.\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can proceed to retrieve the GDP Per Capita for each of these regions using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nFrom the above output, we infer that the GDP Per Capita of the five nearest neighbors based on the Queen method are 20981, 34592, 24473, 21311, and 22879, which happen to be on the lower middle end of the spectrum of GDP Per Capita.\nThe entire weight matrix can be displayed using the str() function.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\nDo note that sometimes the output of the str() function may be very long. Save the trees if you are going to print out the report."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-rook-contiguity-based-neighbors",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-rook-contiguity-based-neighbors",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.4.2 Creating (ROOK) contiguity based neighbors",
    "text": "4.4.2 Creating (ROOK) contiguity based neighbors\nThe below code chunk helps us compute the Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe most connected area unit has 10 neighbors. 5 neighbors are most commonly seen, similar to the Queen method."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-contiguity-weights",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.4.3 Visualizing contiguity weights",
    "text": "4.4.3 Visualizing contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons in this situation, so we need to ensure that our points are in order to produce our connectivity graphs.\nUsually, the method of choice will be polygon centroids. We calculate using the sf package before moving onto the graphs. Getting latitude and longitude of the Polygon Centroids.\nWe need points to associate with each polygon before we can make our connectivity graph. It won’t be as simple as applying the st_centroid() function of the sf sf object: us.bound. We need the coordinates in a separate data-frame for this to work.\nTo do this, we will use a mapping function which will apply a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\nThe function that we implement in this situation will be st_centroid().\nWe will be using the map_dbl variation of map from the purrr package.\n\n4.4.3.1 Longitude and Latitude values\n\nLongitude ValuesLatitude Values\n\n\nTo obtain our longitude values, we map the st_centroid function over the geometry column of us.bound and access the longitude value through the double bracket notation [[]] and 1. This allows us to extract the longitude value, the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\n\nWe proceed to do the same method to extract latitude values, with one key difference. We access the second value in each centroid using [[2]] instead of [[1]] like we did when obtaining the longitude values.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\n\n\nNow that we have the latitude and longitude values, we can use the cbind() function to put the longitude and latitude values into the same object, coords.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe use the head() function to verify if coords is in the correct format.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n4.4.3.2 Plotting Queen and Rook Contiguity Based Neighbors Map\n\nQueen Contiguity Based Neighbors MapRook Contiguity Based Neighbors Map\n\n\nWe use the plot() function as shown in the code chunk below to plot the map.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"purple\")\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\n\n\nWe can plot both side by side to compare the two methods using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"purple\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\n\nQueen Contiguity: In this plot, points are connected if they share either an edge or a vertex. This results in more connections, including diagonal ones, creating a denser network.\nRook Contiguity: In this plot, points are only connected if they share an edge, not a vertex. This results in a grid-like pattern without diagonal connections, making the network less dense compared to Queen Contiguity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determining-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#determining-the-cut-off-distance",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.5.1 Determining the cut-off distance",
    "text": "4.5.1 Determining the cut-off distance\nWe first determine the upper limit for the distance band by using the steps shown below:\n\nFind k Nearest Neighbours: Use knearneigh() from the spdep package to get a matrix of indices for the k nearest neighbours of each point.\nConvert to Neighbours List: Convert the knn object returned by knearneigh() into a neighbours list of class nb using knn2nb(). This list contains integer vectors with neighbour region number IDs.\nCalculate Edge Lengths: Use nbdists() from spdep to return the lengths of neighbour relationship edges. The function returns distances in the units of the coordinates if projected, otherwise in kilometers.\nFlatten the List: Remove the list structure of the returned object using unlist()\n\nThe code chunk below is implemented.\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the output above, we can infer that the largest first nearest neighbor distance is just under 62KM. Using this value, 61.79KM, as the upper threshold gives certainty that all units will have at least one neighbor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.5.2 Computing Fixed Distance weight matrix",
    "text": "4.5.2 Computing Fixed Distance weight matrix\nWe now implement the dnearneigh() function to compute the distance weight matrix.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nFrom the output above, we infer that there are 88 distinct regions, as we identified earlier. There are 324 connections between regions where the distance is within the threshold that we have set. 4.18% of all possible region pairs have a connection. On average, each region is connected to approximately 3.68 other regions.\n\nWe now implement the str() function to display the entirety of the wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\nAs an alternative to str(), we can also use the combination of table() and card() functions from the spdep package to display the structure of the weight matrix.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nNext, we implement the n.comp.nb() function to identify the number of connected components in a neighbor list object of class nb.\n\nNote: A connected component is a subset of regions where each region is reachable from any other region within the same subset. The function returns an object that includes the number of connected components (nc) and a vector indicating the component membership for each region.\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\nThe output [1] 1 from n_comp$nc indicates that there is one connected component in your neighbour list wm_d62. This means all 88 regions are part of a single, interconnected network with no isolated subgroups.\n\n\n4.5.2.1 Plotting fixed distance weight matrix\nWe now plot the distance weight matrix using the plot() function.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"purple\", length=0.08)\n\n\n\n\n\n\n\n\nIn the plot above, the purple lines show the links of 1st nearest neighbors and the black lines show the links of neighbors within the specified cut-off distance of 62KM.\nWe can also plot the separately, side by side, using the code chunk below. Doing so gives us a clearer visualization and facilitates comparison.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.5.3 Computing Adaptive Distance Weight Matrix",
    "text": "4.5.3 Computing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrices is that the more densely settled areas (usually urban areas) tend to have more neighbors and the less densely settled areas (usually rural areas) tend to have lesser neighbors.\nHaving many neighbors smoothens the neighbor relationship across more neighbors.\nIt is possible to control the numbers of neighbors directly using k-nearest neighbors by either accepting asymmetric neighbors or imposing symmetry\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nEach region has an average of 6 neighbors in this scenario.\nWe will display the matrix by implementing the str() function as earlier.\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nAs it turns out, each county has exactly 6 neighbors!\n\n4.5.3.1 Plotting distance based neighbors\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.8.1 Spatial Lag With Row-Standardized Weights",
    "text": "4.8.1 Spatial Lag With Row-Standardized Weights\nWe now compute the average neighbor GDP Per Capita value for each polygon. We often refer to these values as Spatially Lagged Values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nWe can retrieve the GDP Per Capita by using the code Chunk Below\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nA spatial lag with row-standardized weights means that each observation’s value is influenced by the average values of its neighboring observations. Specifically, the weights are standardized so that the sum of the weights for each observation equals one. This approach ensures that the spatial lag is essentially the weighted average of the neighboring values.\n\nWe can append the spatially lagged GDP Per Capita values onto Hunan sf data-frame by using the code chunk shown below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following table shows the average neighboring income values (stored in the lnc.lab object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe now plot the GDP Per Capita and Spatial Lag GDP Per Capita for comparison.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThere is a difference especially in the eastern half of Hunan when spatially lagged GDP Per Capita is plotted."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.8.2 Spatial Lag as a sum of neighboring values",
    "text": "4.8.2 Spatial Lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. For this, we must apply a function that will assign binary weights to our neighbors list. We then use the glist argument in the nb2listw function to explicitly assign these weights.\nWe first apply a function that assigns a value of 1 per neighbor. This is done with help of lapply(), which helps manipulate the neighbors structure. It basically applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nNow that we have assigned the proper weights, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nWe check the result below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nWe now append the lag_sum GDP Per Capita field into hunan sf data-frame and then plot the GDP Per Capita and Spatial Lag Sum GDP Per Capita for comparison.\n\nhunan &lt;- left_join(hunan, lag.res)\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThere is a big difference throughout the region when using Spatial Lag Sum GDP Per Capita."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-average",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.8.3 Spatial Window Average",
    "text": "4.8.3 Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we use the include.self() function from the spdep package.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nThere is a difference in the key statistics shown above when compared to wm_q. The average number of links, the number of non-zero links as well as percentage of non-zero weights are all higher for wm_qs.\nWe look at the neighbor list of area [1] using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nThis region has 6 neighbors.\nWe now implement the nb2listw() function to obtain weights.\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nWe now create the lag variable from our weight structure and GDP Per Capita variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nWe now convert the lag variable listwobject into a data-frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\nWe now append the lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, The kable() function of the Knitr package is used to prepare a table.\n\nhunan %&gt;%\n  dplyr::select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nWe now plot the lag_gdppc and w_ave_gdppc maps next to each other for comparison using the qtm() function of the tmap package.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#spatial-window-sum",
    "title": "Hands On Exercise 4- Spatial Weights and Applications",
    "section": "4.8.4 Spatial Window Sum",
    "text": "4.8.4 Spatial Window Sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nWe now assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our newly obtained weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\n\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nFinally, we plot the lag_sum GDP Per Capita and w_sum_gdppc maps next to each other using the qtm() function of the tmap package.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "Introduction\nWelcome to my journey through ISSS626 Geospatial Analytics. This website contains my coursework that were completed through this course.\n\n\n\nAbout\nMy name is Arjun Singh and I am a student at Singapore Management University pursuing a Masters degree in Analytics. This website documents my journey of learning Geospatial Analytics under the guidance of Professor Tin Seong Kam.\nIf you have any inquiries, feel free to reach out to me at arjun.singh.2023@smu.edu.sg\n“It is a rough road that leads to the heights of greatness.”- Seneca"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPAA) is a specialized suite of methods designed for analyzing spatial point events that occur on or near networks. These events could include locations such as traffic accidents or childcare centers, while the networks themselves might be road or river networks.\nIn this exercise, we will use the spNetwork package to perform Network Kernel Density Estimation (NKDE). Additionally, we will also conduct network G-function and K-function analyses."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#preparing-the-lixel-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#preparing-the-lixel-objects",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.1 Preparing the Lixel Objects",
    "text": "3.4.1 Preparing the Lixel Objects\nBefore we can proceed with computing NKDE, we must first cut the SpatialLines object into Lixels with a specified minimal distance.\n\nLixels (short for “line pixels”) are small, evenly spaced segments or units derived from a larger line or polyline. In geospatial analysis, lixelization refers to the process of breaking down a line into these smaller, discrete segments. Each lixel represents a portion of the original line, typically at a consistent length, allowing for more detailed spatial analysis\n\nThis can be done using the lixelize_lines() functions of the spNetwork package. In the code chunk below, we set the length of the lixel (lx_length) to 700, while the minimum length of the lixel (mindist) is set to 375.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\n\nThere is another function, lixelize_lines.mc() that provides multicore support and is typically used in spatial analysis or geospatial data processing, specifically in contexts where large datasets of lines (such as roads, paths, or boundaries) need to be broken down into smaller, equally spaced segments or “lixels” (line pixels). This process is known as “lixelization.”\nThe main purpose of the lixelize_lines.mc() function is to improve the efficiency of the lixelization process by utilizing multiple CPU cores simultaneously. This is particularly beneficial when dealing with large datasets, as processing each line sequentially can be time-consuming.\n\nAfter a cut, if the length of the final lixel is shorter than the specified minimum distance, then it is added to the previous lixel. If it is null, then mindist=maxdist/10.\nNote that the segments that are shorter than the minimum distance are not modified."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#generating-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#generating-line-centre-points",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.2 Generating Line Centre Points",
    "text": "3.4.2 Generating Line Centre Points\nWe will now generate a SpatialPointsDataFrame with line centre points using the lines_center() function of spNetwork.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at the centre of the line based on the length of the line.\n\nThe function lines_center() from the spNetwork package in R is used to generate a SpatialPointsDataFrame where each point corresponds to the center of a line segment (or lixel) based on its length."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#performing-nkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#performing-nkde",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.3 Performing NKDE",
    "text": "3.4.3 Performing NKDE\nNow, we come to the main topic of this exercise- performing Network Kernel Density Estimation.\nWe use the nkde() function to carry it out. The code chunk below shows the implementation.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  method = \"simple\")\n\n[1] \"checking inputs ...\"\n[1] \"prior data preparation ...\"\n[1] \"Splitting the data with the spatial grid ...\"\n[1] \"start calculating the kernel values ...\"\n[1] \"    quadra 1/1\"\n[1] \"    build graph ...\"\n[1] \"        calculating NKDE values ...\"\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%[1] \"combining the results ...\"\n\n\n\n\nThe kernel_name argument specifies the type of kernel function used.\nPossible kernel methods supported by spNetwork include:\n\nQuartic\nTriangle\nGaussian\nScaled Gaussian\nTricube\nCosine\nTriweight\nEpanechnikov\nUniform\n\nThe method argument indicates the method used to calculate Network Kernel Density Estimation (NKDE).\nspNetwork supports three popular methods:\n\nSimple (method = \"simple\"):\n\nIntroduced by Xie et al. (2008).\nDistances between events and sampling points are replaced by network distances.\nThe kernel formula is adapted to calculate density over a linear unit instead of an areal unit.\n\nDiscontinuous (method = \"discontinuous\"):\n\nProposed by Okabe et al. (2008).\nDivides the mass density of an event at intersections of lixels.\nResults in a discontinuous kernel function.\n\nContinuous (method = \"continuous\"):\n\nAlso proposed by Okabe et al. (2008).\nAdjusts the density before intersections to create a continuous kernel function.\nStill divides the mass of the density at intersections but with a continuous adjustment.\n\n\n\n\n\n3.4.3.1 Visualizing NKDE\nWe must first insert the computed density values (i.e: densities) into samples and lixels objects as the density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nWe now convert the scale from number of events per meter (as data is projected using the SVY21 coordinate system) to number of events per kilometer, as the computed density values are very small if the unit is event per meter.\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nWe can now plot the map as the data is now prepared.\nWe will use the tmap package to produce a highly cartographic and interactive map.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres with the help of shading. The roads with darker shades have a relatively higher density."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices. On the other hands, Geovisualization works by providing graphical ideations to render a place, a phenomenon or a process visible, enabling a humans most powerful information-processing abilities- those of spatial cognition associated with our eye-brain vision system, to be directly brought to bear.\n\n\nTo fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nAs discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "To fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "As discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Choropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of the pacman package to check if tidyverse has been installed. If it has been, it will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\nThe relevant data is now going to be imported using the st_read() function of package sf.\n\nmpsz=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output above, it can be inferred that there are 323 multipolygon features and 15 fields in mpsz, which is projected in the SVY21 coordinate system.\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output above reveals that there are 3138 features and 2 fields in the cyclingpath linestring feature data frame, which is also projected in the SVY21 coordinate system.\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data-frame, with 2290 features and 2 fields. Unlike the two previous simple feature data-frames, preschoolis projected using the WGS84 coordinate system.\n\n\n\n\nWe now focus on the different methods of retrieving information related to the contents of a simple feature data-frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list of class sfc. The geometry list–column can be retrieved using the mpsz$geom or mpsz[[1]], but st_geometry, shown below, is the most commonly used method.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\nUsing glimpse(), a function of the dplyr package, we can learn more about the data-frame beyond the basic feature information.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nThe function head(), an in-built R function, will reveal complete information about a feature object.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\nIn Geopspatial Data Science, simply looking at the feature information is not enough. Visualizing the geospatial features is a key step to improve our understanding of the data. We can use plot(), an in-built function of R Graphic, to facilitate visualization.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nBy default, a multi-plot of all attributes is obtained, up to a reasonable maximum as shown above. We can also choose to plot only the geometry by implementing the code shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz['PLN_AREA_N'])\n\n\n\n\n\n\n\n\nIt must be noted that plot() plots the geospatial data for a quick overview. For high cartographic quality, R packages such as tmap should be used.\n\n\n\nMap projection is an important property of geospatial data. When performing geoprocessing using two geospatial datasets, we need to ensure that they are both projected using similar coordinate systems.\n\n\nOne of the most common issues faced when importing Geospatial data into R is that the coordinate system of the source data was either missing (for example, due to missing .proj for ESRI Shapefile) or wrongly assigned during the importing process.\nBy using the st_crs() function of the sf package, we can view the Coordinate Reference System of mpsz.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data-frame is projected in SVY21, it indicates that the EPSG is 9001. This is the wrong EPSG- the correct EPSG code for SVY21 should be 3414.\nTo correct the EPSG code, we use st_set_crs() of the sf package as shown below.\n\nmpsz3414&lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe now check the CSR again using the st_crs() function from earlier,\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nWhen analyzing geospatial data, its common to have to transform the original data from geographic coordinate system to project coordinate system because the geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\nEarlier, we learnt that the preschool simple feature data-frame was in WGS84 format. In this scenario, using st_set_crs() is not appropriate because we need to re-project preschool from one coordinate system to another coordinate system mathematically.\nWe use the st_transform() function for this.\n\npreschool3414&lt;- st_transform(preschool, crs=3414)\n\nWe now check for the contents of the newly transformed data-frame using the st_geometry() function from earlier.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nIt is now the appropriate projected coordinate system now- SVY21. Additionally, if you refer to the Bounding Box data above, the values are greater than the 0-360 range of decimal degrees commonly used by most geographic coordinate systems.\n\n\n\n\nIt is not unusual to come across data such as the listingdata set obtained from AirBnb. Such data is called Aspatial data. This is because it has separate data fields containing the x and y coordinates of the data points, unlike Geospatial data.\n\n\nSince the listing data set is in csv format, we use the read_csv() function of the readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will now examine if the data file has been imported correctly for analysis.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe above output informs us that there are 18 columns and 3540 rows of data. Two important columns that will be used in the next phase of the analysis are the latitude and longitude columns. These columns are in decimal degree format. As a best guess, it is assumed that the data is projected in the WGS84 Geographic Coordinate System.\n\n\n\nThe st_as_sf() function of the sf package is used to convert the listing data-frame into a simple feature data-frame.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe now examine the contents of the newly created data-frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nA new column ‘geometry’ has been added into the data-frame, while the latitude and longitude columns have been dropped.\n\n\n\n\nThe sf package offers a wide range of geoprocessing (also known as GIS analysis) functions in addition to the functions it provides to facilitate handling of geospatial data.\n\n\nScenario: The authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. We are tasked with determining the extent of the land that needs to be acquired and the total area.\nSolution:\nThe st_buffer() function of the sf package is used to ciompute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNow, we calculate the area of the buffers using the st_area() function.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nFinally, we use sum() to derive the total area of land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nQ.E.D\n\n\n\nScenario: A pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\nSolution:\nUsing the code chunk below, we are able to firstly identify the pre-schools located inside each Planning Subzone (using the st_intersects() function), after which we use the length() function to calculate the number of pre-schools that fall inside each Planning Subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe summary statistics are below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo obtain a list of the Planning Subzones with the most pre-schools, we use the top_n() function of the dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe density of pre-schools by Planning Subzone is now calculated using the st_area() function of the sf package and the mutate() function of the dplyr package.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nWe now conduct Exploratory Data Analysis to gain a better understanding of the data using relevant visualizations plotted using the ggplot2 package.\nFirst, we plot a histogram to reveal the distribution of PreSch Density using the hist() function of R Graphics.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the method is straightforward, the output is far from the required quality and has limited room for further customization. Using ggplot2, we create a higher quality histogram that fits our needs better.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"purple\") +\n  labs(title = \"Are pre-schools evenly distributed across Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nTo gain a better understanding of the relationship between pre-school density and pre-school count, we plot a scatterplot using ggplot2.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\",\n             na.rm=TRUE) +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started.",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of the pacman package to check if tidyverse has been installed. If it has been, it will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\nThe relevant data is now going to be imported using the st_read() function of package sf.\n\nmpsz=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output above, it can be inferred that there are 323 multipolygon features and 15 fields in mpsz, which is projected in the SVY21 coordinate system.\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output above reveals that there are 3138 features and 2 fields in the cyclingpath linestring feature data frame, which is also projected in the SVY21 coordinate system.\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data-frame, with 2290 features and 2 fields. Unlike the two previous simple feature data-frames, preschoolis projected using the WGS84 coordinate system.\n\n\n\n\nWe now focus on the different methods of retrieving information related to the contents of a simple feature data-frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list of class sfc. The geometry list–column can be retrieved using the mpsz$geom or mpsz[[1]], but st_geometry, shown below, is the most commonly used method.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\nUsing glimpse(), a function of the dplyr package, we can learn more about the data-frame beyond the basic feature information.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nThe function head(), an in-built R function, will reveal complete information about a feature object.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\nIn Geopspatial Data Science, simply looking at the feature information is not enough. Visualizing the geospatial features is a key step to improve our understanding of the data. We can use plot(), an in-built function of R Graphic, to facilitate visualization.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nBy default, a multi-plot of all attributes is obtained, up to a reasonable maximum as shown above. We can also choose to plot only the geometry by implementing the code shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz['PLN_AREA_N'])\n\n\n\n\n\n\n\n\nIt must be noted that plot() plots the geospatial data for a quick overview. For high cartographic quality, R packages such as tmap should be used.\n\n\n\nMap projection is an important property of geospatial data. When performing geoprocessing using two geospatial datasets, we need to ensure that they are both projected using similar coordinate systems.\n\n\nOne of the most common issues faced when importing Geospatial data into R is that the coordinate system of the source data was either missing (for example, due to missing .proj for ESRI Shapefile) or wrongly assigned during the importing process.\nBy using the st_crs() function of the sf package, we can view the Coordinate Reference System of mpsz.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data-frame is projected in SVY21, it indicates that the EPSG is 9001. This is the wrong EPSG- the correct EPSG code for SVY21 should be 3414.\nTo correct the EPSG code, we use st_set_crs() of the sf package as shown below.\n\nmpsz3414&lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe now check the CSR again using the st_crs() function from earlier,\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nWhen analyzing geospatial data, its common to have to transform the original data from geographic coordinate system to project coordinate system because the geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\nEarlier, we learnt that the preschool simple feature data-frame was in WGS84 format. In this scenario, using st_set_crs() is not appropriate because we need to re-project preschool from one coordinate system to another coordinate system mathematically.\nWe use the st_transform() function for this.\n\npreschool3414&lt;- st_transform(preschool, crs=3414)\n\nWe now check for the contents of the newly transformed data-frame using the st_geometry() function from earlier.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nIt is now the appropriate projected coordinate system now- SVY21. Additionally, if you refer to the Bounding Box data above, the values are greater than the 0-360 range of decimal degrees commonly used by most geographic coordinate systems.\n\n\n\n\nIt is not unusual to come across data such as the listingdata set obtained from AirBnb. Such data is called Aspatial data. This is because it has separate data fields containing the x and y coordinates of the data points, unlike Geospatial data.\n\n\nSince the listing data set is in csv format, we use the read_csv() function of the readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will now examine if the data file has been imported correctly for analysis.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe above output informs us that there are 18 columns and 3540 rows of data. Two important columns that will be used in the next phase of the analysis are the latitude and longitude columns. These columns are in decimal degree format. As a best guess, it is assumed that the data is projected in the WGS84 Geographic Coordinate System.\n\n\n\nThe st_as_sf() function of the sf package is used to convert the listing data-frame into a simple feature data-frame.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe now examine the contents of the newly created data-frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nA new column ‘geometry’ has been added into the data-frame, while the latitude and longitude columns have been dropped.\n\n\n\n\nThe sf package offers a wide range of geoprocessing (also known as GIS analysis) functions in addition to the functions it provides to facilitate handling of geospatial data.\n\n\nScenario: The authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. We are tasked with determining the extent of the land that needs to be acquired and the total area.\nSolution:\nThe st_buffer() function of the sf package is used to ciompute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNow, we calculate the area of the buffers using the st_area() function.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nFinally, we use sum() to derive the total area of land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nQ.E.D\n\n\n\nScenario: A pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\nSolution:\nUsing the code chunk below, we are able to firstly identify the pre-schools located inside each Planning Subzone (using the st_intersects() function), after which we use the length() function to calculate the number of pre-schools that fall inside each Planning Subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe summary statistics are below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo obtain a list of the Planning Subzones with the most pre-schools, we use the top_n() function of the dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe density of pre-schools by Planning Subzone is now calculated using the st_area() function of the sf package and the mutate() function of the dplyr package.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nWe now conduct Exploratory Data Analysis to gain a better understanding of the data using relevant visualizations plotted using the ggplot2 package.\nFirst, we plot a histogram to reveal the distribution of PreSch Density using the hist() function of R Graphics.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the method is straightforward, the output is far from the required quality and has limited room for further customization. Using ggplot2, we create a higher quality histogram that fits our needs better.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"purple\") +\n  labs(title = \"Are pre-schools evenly distributed across Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nTo gain a better understanding of the relationship between pre-school density and pre-school count, we plot a scatterplot using ggplot2.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\",\n             na.rm=TRUE) +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Welcome to the first part of Hands-On Exercise 2 where we explore 1st Order Spatial Point Pattern Analysis Methods.\n\n\nThe data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#data-and-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#data-and-libraries",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "The data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-the-spatial-data",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.2.1 Importing the Spatial Data",
    "text": "2.2.1 Importing the Spatial Data\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.2.2 Mapping the Geospatial Data",
    "text": "2.2.2 Mapping the Geospatial Data\nWe prepare a pin map using functions from the tmap package.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are several benefits to using a pin map in this situation. Firstly, since it is an interactive map we can move around the map freely and look at specific areas that we’re interested in. Second, we can query the information for each simple feature by simply clicking them. Additionally, you can also change the background of the internet map layer- currently, three internet map layers are provided (ESRI.WorldGrayCanvas [default], ESRI.WorldTopoMap, and OpenStreetMap.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.1 Converting simple feature data-frames to sp’s Spatial Class",
    "text": "2.3.1 Converting simple feature data-frames to sp’s Spatial Class\nWe can convert geospatial data from a simple feature data-frame to sp’s Spatial class using the as_Spatial() function of the sf package. The code chunk below showcases how it will be done.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nNow, we want to have a look at each of these data-frames. We do it using the glimpse() function.\n\nChildcareMPSZsg\n\n\n\nglimpse(childcare)\n\nFormal class 'SpatialPointsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 1545 obs. of  2 variables:\n  .. ..$ Name       : chr [1:1545] \"kml_1\" \"kml_2\" \"kml_3\" \"kml_4\" ...\n  .. ..$ Description: chr [1:1545] \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ ...\n  ..@ coords.nrs : num(0) \n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Points Data-Frame.\n\n\n\nglimpse(mpsz)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 323 obs. of  15 variables:\n  .. ..$ OBJECTID  : int [1:323] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ SUBZONE_NO: int [1:323] 1 1 3 8 3 7 9 2 13 7 ...\n  .. ..$ SUBZONE_N : chr [1:323] \"MARINA SOUTH\" \"PEARL'S HILL\" \"BOAT QUAY\" \"HENDERSON HILL\" ...\n  .. ..$ SUBZONE_C : chr [1:323] \"MSSZ01\" \"OTSZ01\" \"SRSZ03\" \"BMSZ08\" ...\n  .. ..$ CA_IND    : chr [1:323] \"Y\" \"Y\" \"Y\" \"N\" ...\n  .. ..$ PLN_AREA_N: chr [1:323] \"MARINA SOUTH\" \"OUTRAM\" \"SINGAPORE RIVER\" \"BUKIT MERAH\" ...\n  .. ..$ PLN_AREA_C: chr [1:323] \"MS\" \"OT\" \"SR\" \"BM\" ...\n  .. ..$ REGION_N  : chr [1:323] \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" ...\n  .. ..$ REGION_C  : chr [1:323] \"CR\" \"CR\" \"CR\" \"CR\" ...\n  .. ..$ INC_CRC   : chr [1:323] \"5ED7EB253F99252E\" \"8C7149B9EB32EEFC\" \"C35FEFF02B13E0E5\" \"3775D82C5DDBEFBD\" ...\n  .. ..$ FMEL_UPD_D: Date[1:323], format: \"2014-12-05\" \"2014-12-05\" ...\n  .. ..$ X_ADDR    : num [1:323] 31596 28679 29655 26783 26202 ...\n  .. ..$ Y_ADDR    : num [1:323] 29220 29782 29975 29934 30006 ...\n  .. ..$ SHAPE_Leng: num [1:323] 5267 3506 1741 3314 2826 ...\n  .. ..$ SHAPE_Area: num [1:323] 1630379 559816 160807 595429 387429 ...\n  ..@ polygons   :List of 323\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. [list output truncated]\n  ..@ plotOrder  : int [1:323] 285 302 313 16 269 75 297 276 213 56 ...\n  ..@ bbox       : num [1:2, 1:2] 2668 15749 56396 50256\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame.\n\n\n\nglimpse(sg)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 60 obs. of  4 variables:\n  .. ..$ GDO_GID   : num [1:60] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ MSLINK    : num [1:60] 1 3 5 6 7 8 9 10 11 12 ...\n  .. ..$ MAPID     : num [1:60] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ COSTAL_NAM: chr [1:60] \"Linkway\" \"SENTOSA\" \"PULAU SARIMBUN\" \"PULAU SAMULUN\" ...\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-spatial-class-into-generic-sp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-spatial-class-into-generic-sp-format.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.2 Converting Spatial Class into generic sp format.",
    "text": "2.3.2 Converting Spatial Class into generic sp format.\nIn order to use the spatstat package, the data must be in ppp object form. There is no direct way to convert Spatial Classes into ppp objects. So, we start by converting the Spatial Classes into Spatial Objects first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_spsg_sp\n\n\n\nglimpse(childcare_sp)\n\nFormal class 'SpatialPoints' [package \"sp\"] with 3 slots\n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\nglimpse(sg_sp)\n\nFormal class 'SpatialPolygons' [package \"sp\"] with 4 slots\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\n\n\nshow/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\nGenerally, Spatial Classes are more structured and more suitable for complex and more rigorous Spatial Analytics. Generic ‘sp’ objects allow for simpler, more flexible, data manipulation where having a format Spatial Class is necessary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.3 Converting the generic sp format into Spatstat’s ppp format.",
    "text": "2.3.3 Converting the generic sp format into Spatstat’s ppp format.\nTo convert the spatial data into the required ppp form, we implement the as.ppp() function of the spatstat package. ::: panel-tabset ## Conversion to ppp object\n\nchildcare_ppp=as.ppp(childcare_sf)\n(childcare_ppp)\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#summary-of-newly-obtained-ppp-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#summary-of-newly-obtained-ppp-object",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Summary of newly obtained ppp object",
    "text": "Summary of newly obtained ppp object\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n:::\nWe will now plot the newly obtained ppp object to visualize the differences to previous data-frames.\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#handling-duplicated-points",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.4 Handling duplicated points",
    "text": "2.3.4 Handling duplicated points\nWe check childcare_ppp for any duplicates in order to handle duplicates if they are present.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nWe now check for the points of co-incidence using the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe further verify if there are any duplicates by checking to see if there are any points occurring more than once in the object using the code chunk below.\n\nsum(multiplicity(childcare_ppp)&gt;1)\n\n[1] 0\n\n\nIt appears that there is indeed 0 duplicated point events.\n\nIn the case that there are duplicates, they can be handled as follows. We use jittering (shown in the code chunk below), which adds a small perturbation to the duplicate points so that they do not occupy the exact same space. Additionally, we could also make each point unique and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need to implement analytical techniques that take these marks into account.\n\n#childcare_ppp_jit &lt;- rjitter(childcare_ppp, \n #                            retry=TRUE, \n  #                           nsim=1, \n   #                          drop=TRUE)\n\n\n\nAnd then we can check for any duplicates to ensure that the above function worked using the following code chunk, the same as earlier.\n\n# any(duplicated(childcare_ppp_jit))\n\n\n\n2.3.5 Creating an owin object\nWhen analyzing Spatial Point patterns, it is a good practice to confine the boundaries of the analysis with a Geographical area, such as Singapore’s boundary. Using the spatstat package, we can create an owin object that is designed to represent such polygonal regions.\nWe use the as.owin() function from spatstat for this transformation.\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot of the newly obtained sg_owin objectSummary of the object\n\n\nWe can plot the newly obtained object using the code chunk below.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nFrom the summary, we see that the object itself is a polygonal boundary with a window area of 725376000 square units."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-kde",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.4.1 Kernel Density Estimation (KDE)",
    "text": "2.4.1 Kernel Density Estimation (KDE)\nKDE will allow us to better estimate the distribution of childcare services acrosss Singapore. Using this, we can make more informed decisions on where to focus resources on to improve the accessibility to these services across the nation.\n\n2.4.1.1 Computing KDE using automatic bandwidth selection.\nWe use the density() function of the spatstat package to compute the kernel density. These are the key configurations used in the computation:\n\nbw.diggle() automatic bandwidth selection method.\nThe smoothing kernel used in this instance is gaussian. Other smoothing methods include “epanechnikov”, “quartic”. or “disc”.\n\n\nkde_childcareSG_bw &lt;- density(childcare_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nThe other two methods aside from bw.diggle() are bw.scott() and bw.ppl(). While bw.diggle() focuses on minimizing error in spatial density estimation for point process data and is tailor-made for spatial applications, bw.scott() (Scott’s rule) provides a rule-of-thumb bandwidth and is used in several KDE applications across different types of data besides just spatial data. bw.ppl() uses a more complex and data-driven approach (plug-in) for selecting the bandwidth, aiming to minimize the error in KDE. Like bw.diggle(), It is also tailor-made for spatial point processes, however, it takes a slightly different approach to bw.diggle()\n\nWe now use the plot() function to display the above kernel density estimate.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nImmediately we notice that the density values are very small. This is because when the data is projected in the SVY21 coordinate system, the unit of measurement is in meter, meaning that the density values are computed with a unit of ‘number of points per square meter.’\nWe can also determine the bandwidth that was used to compute the above KDE layer by implementing the code chunk below.\n\nbw &lt;- bw.diggle(childcare_ppp)\nbw\n\n   sigma \n294.8378 \n\n\n\n\n2.4.1.2 Re-scaling KDE values\nWe now use the rescale.ppp() function of the spatstat package to convert the unit of measurement from meter to kilometer. This is done by implementing the code chunk below.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcare_ppp, 1000, \"km\")\n\nAfter this, we re-deploy the density() function using the re-scaled data and plot the KDE map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNow, while the image itself looks similar distribution wise, notice that the units of measurement have changed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-bandwidth-selection-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-bandwidth-selection-methods",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.4.2 Working with different automatic bandwidth selection methods",
    "text": "2.4.2 Working with different automatic bandwidth selection methods\n\n2.4.2.1 Comparing the impact of using different smoothing kernels\nBelow, we use the bw.ppl() bandwidth selection method on all 4 types of smoothing kernels to visualize the difference between them.\n\n# Set up a 2x2 plotting area\npar(mfrow=c(2,2))\n\n# KDE with Gaussian kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian (bw.ppl)\")\n\n# KDE with Epanechnikov kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov (bw.ppl)\")\n\n# KDE with Quartic kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic (bw.ppl)\")\n\n# KDE with Disc kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc (bw.ppl)\")\n\n\n\n\n\n\n\n\nThere is no real difference in the 4 plots when using the same bandwidth selection method regardless of the smoothing kernel selected.\n\n\n2.4.2.2 The impact of using different smoothing kernels and bandwidth selection methods.\n\nEpanechnikov smoothing kernel and bw.scott() bandwidth selectionQuartic smoothing kernel and bw.ppl() bandwidth selectionDisc smoothing kernel and bw.CvL() bandwidth selection\n\n\n\nbw_scott &lt;- bw.scott(childcareSG_ppp.km)\n\nkde_childcareSG_bw_scott &lt;- density(childcareSG_ppp.km,\n                                    sigma=bw_scott,\n                                    edge=TRUE,\n                                    kernel=\"epanechnikov\")\n\nplot(kde_childcareSG_bw_scott, main=\"KDE of Childcare Services in Singapore using bw.scott\")\n\n\n\n\n\n\n\n\nWe notice that the plot is of a different kind entirely however the distribution does look pretty similar.\nWe check the bandwidth selected using the code chunk below.\n\nbw2=bw.scott(childcareSG_ppp.km)\nbw2\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\nImmediately you see a difference in the bandwidth- there are two values (x and y) rather than just the one when using bw.diggle()\n\n\n\nbw_ppl &lt;- bw.ppl(childcareSG_ppp.km)\n\nkde_childcareSG_bw_ppl_qua &lt;- density(childcareSG_ppp.km,\n                                      sigma=bw_ppl,\n                                      edge=TRUE,\n                                      kernel=\"quartic\")\n\nplot(kde_childcareSG_bw_ppl_qua, main=\"KDE of Childcare Services in Singapore using bw.ppl and Quartic Kernel\")\n\n\n\n\n\n\n\n\nAgain, we see a different kind of plot, however the distribution seems consistent in all plots.\nWe now check the bandwidth using the code chunk below.\n\nbw3=bw.ppl(childcareSG_ppp.km)\nbw3\n\n    sigma \n0.3283284 \n\n\nAgain, we see a different bandwidth value to the previous two methods, however only one coordinate as opposed to the two when using the bw.scott() technique.\n\n\n\nbw_cvl &lt;- bw.CvL(childcareSG_ppp.km)\n\nkde_childcareSG_cvl &lt;- density(childcareSG_ppp.km,\n                               sigma=bw_cvl,\n                               edge=TRUE,\n                               kernel=\"disc\")\n\nplot(kde_childcareSG_cvl, main = \"KDE of Childcare Services using bw.cvl and Gaussian Kernel\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.2 Computing KDE by using adaptive bandwidth",
    "text": "2.5.2 Computing KDE by using adaptive bandwidth\nA fixed bandwidth approach is highly sensitive to spatial point distributions that are highly skewed over geographical units (e.g: urban vs rural). To alleviate this issue, adopting an adaptive bandwidth approach is suitable.\nWe use the density.adaptive() function of spatstat for this.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the two methods using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\nWe see a clear difference between the two plots, indicating that the fixed bandwidth approach may have heavily influenced by skewness of the distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-kde-output-into-a-grid-object.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-kde-output-into-a-grid-object.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.3 Converting the KDE output into a grid object.",
    "text": "2.5.3 Converting the KDE output into a grid object.\n\n2.5.3.1 Converting gridded output into raster.\nWe convert the gridded kernel density objects into RasterLayer object by using raster() of the raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nWe now examine the properties of the above object.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.2671971, 0.184635  (x, y)\nextent     : 11.20301, 45.40424, 25.6676, 49.30088  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -3.65694e-15, 28.48563  (min, max)\n\n\nThe CRS above is NA, so we now set the CRS to EPSG 3414 of Singapore.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nplot(kde_childcareSG_bw_raster)\n\n\n\n\n\n\n\n\n\nYou could also use the tmap package to draw a map for the above. This allows for more customization to suit your needs.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE, \n            legend.text.color = \"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.4 Comparing Spatial Point Patterns using KDE",
    "text": "2.5.4 Comparing Spatial Point Patterns using KDE\nUsing the methods below we can compare the KDE of childcare in selected locations such as Punggol, Jurong West, Bukit Batok and Yishun.\n\n2.5.4.1 Extracting the Study Area\nUsing the code chunk below, we filter out all data aside from our target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\nys &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"YISHUN\")\nbbk &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"BUKIT BATOK\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nAfter this, we can plot these target planning areas using the code chunk below.\n\nPunggolYishunBukit BatokJurong West\n\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\n\n\nplot(ys, main = \"Yishun\")\n\n\n\n\n\n\n\n\n\n\n\nplot(bbk, main = \"Bukit Batok\")\n\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nWe see a difference in the distribution in all 4 of these regions.\n\n\n2.5.4.2 Creating owin objects\nWe now proceed to convert these simple feature objects into the owin objects that are required in order to use spatstat.\n\npg_owin = as.owin(pg)\nys_owin = as.owin(ys)\nbbk_owin = as.owin(bbk)\njw_owin = as.owin(jw)\n\n\n\n2.5.4.3 Combining childcare points and the study area.\nWe implement the code chunk below in order to extract any childcare centers that are within the specific regions in order to carry out our analysis later.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                          retry=TRUE, \n                           nsim=1, \n                            drop=TRUE)\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_ys_ppp = childcare_ppp_jit[ys_owin]\nchildcare_bbk_ppp = childcare_ppp_jit[bbk_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nFollowing this, we apply the rescale.ppp() function to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_ys_ppp.km = rescale.ppp(childcare_ys_ppp, 1000, \"km\")\nchildcare_bbk_ppp.km = rescale.ppp(childcare_bbk_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nNow, we can plot the four study areas and visualize the distribution of childcare centers across the four target areas.\n\npar(mfrow=c(2,2)) \n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_ys_ppp.km, main=\"Yishun\")\nplot(childcare_bbk_ppp.km, main=\"Bukit Batok\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n2.5.4.4 Computing the KDE\nWe now implement the bw.diggle() method to compute the respective KDEs of the four target planning areas.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_ys_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Yishun\")\nplot(density(childcare_bbk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bukit Batok\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n2.5.4.5 Computing Fixed Bandwidth KDEs\nIn the interest of determining the best method to use, we also adopt a fixed bandwidth approach for comparison to the bw.diggle() method above.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_ys_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Yishun\")\nplot(density(childcare_bbk_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bukit Batok\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "We now focus on Global Measures of Spatial Autocorrelation (GMSA) with the help of the spdep package. Through this exercise we:\n\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#performing-relational-join",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.3.1 Performing relational join",
    "text": "5.3.1 Performing relational join\nWe will update the attribute table of Hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data-frame. We can do this by using the left_join() function of the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.5.1 Computing Contiguity Spatial Weights",
    "text": "5.5.1 Computing Contiguity Spatial Weights\nBefore computing the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area, the spatial weights are used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe now implement the poly2nb() function of the spdep package to compute contiguity weight matrices for the study area selected.\nUsing this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.\nIn this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.\nYou may refer to the spdep package documentation here to learn more about its functions and arguments.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the output above, we can infer that there are 88 area units in total in Hunan. The most connected area unit has 11 neighbors. There are two area units with just 1 neighbor, while 24 area units have 5 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#row-standardized-weights-matrix",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.5.2 Row-Standardized Weights Matrix",
    "text": "5.5.2 Row-Standardized Weights Matrix\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nThe nb2listw() function requires an input of class nb, representing a neighborhood object. The function’s two key arguments are style and zero.policy.\n\nThe style argument defines how the weights are calculated. It can take several values:\n\n\"B\": Binary coding, where weights are either 0 or 1.\n\"W\": Row-standardized, where the sum of weights across all neighbors equals 1.\n\"C\": Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.\n\"U\": A variation of \"C\", where weights are normalized by the number of neighbors.\n\"S\": A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.\n\nThe zero.policy argument, when set to TRUE, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector x, effectively setting the lagged value to zero for those regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#marons-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#marons-i-test",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.1 Maron’s I test",
    "text": "5.6.1 Maron’s I test\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar GDP Per Capita are randomly distributed.\nH1: Regions with similar GDP Per Capita are not randomly distributed and exhibit spatial clustering.\n\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nFrom the output above, we can infer the following:\n\nThe p-value (1.095e-06)&lt;0.05, indicating that the observed spatial autocorrelation is statistically significant.\nMoran’s I statistic: The observed value of 0.3007 indicates positive spatial autocorrelation, meaning that regions with similar GDP Per Capita are more likely to be located near each other.\n\nSince Moran’s I Statistic is significantly greater than what we would expect in a randomly distributed region. There is significant evidence to reject H0 and conclude that there is indeed spatial clustering with regards to GDP Per Capita in Hunan."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-morans-i",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.2 Computing Monte Carlo Moran’s I",
    "text": "5.6.2 Computing Monte Carlo Moran’s I\nWe now implement the moran.mc() function of the spdep package. In this scenario, we will run 1000 simulations.\n\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nBased on the above output, p-value (0.001)&lt;0.05, thus we can reject the null hypothesis at a 5% significance level and conclude that there is indeed spatial clustering."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-morans-i",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.3 Visualizing Monte Carlo Moran’s I",
    "text": "5.6.3 Visualizing Monte Carlo Moran’s I\nWe can visualize the test statistics obtained from the simulation above by implementing the hist() and abline() functions of R graphics.\n\nSummary StatisticsThe Plotggplot2 method\n\n\nWe first calculate the mean and variance, and obtain the summary statistics.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\nFrom the above, we can infer that over half of all simulations indicate a negative value for Moran’s I statistic. Generally, a negative value indicates that dissimilar regions are located next to each other. (i.e: regions with dissimilar GDP Per Capita are located next to each other)\n\n\nWe can also use ggplot2 package to plot the above.\n\ndata &lt;- data.frame(simulated_moran = bperm$res)\n\nggplot(data, aes(x = simulated_moran)) +\n  geom_histogram(binwidth = (max(data$simulated_moran) - min(data$simulated_moran)) / 20, \n                 fill = \"lightblue\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Simulated Moran's I\", \n       y = \"Frequency\",\n       title = \"Histogram of Simulated Moran's I\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nIf Morans I Statistic is = 0, there is Random Spatial Distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-gearys-c",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.7.1 Computing Monte Carlo Geary’s C",
    "text": "5.7.1 Computing Monte Carlo Geary’s C\nWe implement the the geary.mc() function of the spdep package to conduct 1000 simulations.\n\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nWe can infer that there is sufficient evidence to reject the null hypothesis (as p-value (0.001)&lt;0.05) and conclude that there is indeed Positive Spatial Autocorrelation (as statistic= 0.691.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-gearys-c",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.7.2 Visualizing Monte Carlo Geary’s C",
    "text": "5.7.2 Visualizing Monte Carlo Geary’s C\n\nSummary StatisticsThe plot\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.003309\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.006955922\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7645  0.9435  1.0044  1.0033  1.0565  1.2883 \n\n\n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\nFrom the plot, we infer that out of the 1000 simulations the value of the statistic is distributed approximately normally, however generally values are close to 1 indicating a lack of spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "",
    "text": "Spatial Point Pattern Analysis involves examining the distribution or arrangement of a set of points on a surface. These points can represent various phenomena, such as:\n\nEvents like crime, traffic accidents, or disease onset,\nBusiness services, such as coffee shops and fast-food outlets,\nFacilities like childcare and eldercare centers.\n\nIn this hands-on exercise, we will utilize functions from the spatstat package to explore the spatial distribution of childcare centers in Singapore.\nOur primary questions are:\n\nAre childcare centers in Singapore randomly distributed across the country?\nIf they are not randomly distributed, where are the areas with a higher concentration of childcare centers?\n\n\n\nThe data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\n\n\nClick to show/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\n\nSetting seed\n\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#data-and-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#data-and-libraries",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "",
    "text": "The data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\n\n\nClick to show/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\n\nSetting seed\n\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#importing-the-spatial-data",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.8.1 Importing the Spatial Data",
    "text": "2.8.1 Importing the Spatial Data\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently.\n\nNote that when working transforming crs, we can code more efficiently by using the code chunk below for example (which we implemented above). Using ‘%&gt;%’ allows you to chain multiple operations together.\n\n#childcare_sf=st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n # st_transform(crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-data",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.8.2 Mapping the Geospatial Data",
    "text": "2.8.2 Mapping the Geospatial Data\nWe prepare a pin map using functions from the tmap package.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are several benefits to using a pin map in this situation. Firstly, since it is an interactive map we can move around the map freely and look at specific areas that we’re interested in. Second, we can query the information for each simple feature by simply clicking them. Additionally, you can also change the background of the internet map layer- currently, three internet map layers are provided (ESRI.WorldGrayCanvas [default], ESRI.WorldTopoMap, and OpenStreetMap.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.1 Converting simple feature data-frames to sp’s Spatial Class",
    "text": "2.9.1 Converting simple feature data-frames to sp’s Spatial Class\nWe can convert geospatial data from a simple feature data-frame to sp’s Spatial class using the as_Spatial() function of the sf package. The code chunk below showcases how it will be done.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nNow, we want to have a look at each of these data-frames. We do it using the glimpse() function.\n\nChildcareMPSZsg\n\n\n\nglimpse(childcare)\n\nFormal class 'SpatialPointsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 1545 obs. of  2 variables:\n  .. ..$ Name       : chr [1:1545] \"kml_1\" \"kml_2\" \"kml_3\" \"kml_4\" ...\n  .. ..$ Description: chr [1:1545] \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ ...\n  ..@ coords.nrs : num(0) \n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Points Data-Frame.\n\n\n\nglimpse(mpsz)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 323 obs. of  15 variables:\n  .. ..$ OBJECTID  : int [1:323] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ SUBZONE_NO: int [1:323] 1 1 3 8 3 7 9 2 13 7 ...\n  .. ..$ SUBZONE_N : chr [1:323] \"MARINA SOUTH\" \"PEARL'S HILL\" \"BOAT QUAY\" \"HENDERSON HILL\" ...\n  .. ..$ SUBZONE_C : chr [1:323] \"MSSZ01\" \"OTSZ01\" \"SRSZ03\" \"BMSZ08\" ...\n  .. ..$ CA_IND    : chr [1:323] \"Y\" \"Y\" \"Y\" \"N\" ...\n  .. ..$ PLN_AREA_N: chr [1:323] \"MARINA SOUTH\" \"OUTRAM\" \"SINGAPORE RIVER\" \"BUKIT MERAH\" ...\n  .. ..$ PLN_AREA_C: chr [1:323] \"MS\" \"OT\" \"SR\" \"BM\" ...\n  .. ..$ REGION_N  : chr [1:323] \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" ...\n  .. ..$ REGION_C  : chr [1:323] \"CR\" \"CR\" \"CR\" \"CR\" ...\n  .. ..$ INC_CRC   : chr [1:323] \"5ED7EB253F99252E\" \"8C7149B9EB32EEFC\" \"C35FEFF02B13E0E5\" \"3775D82C5DDBEFBD\" ...\n  .. ..$ FMEL_UPD_D: Date[1:323], format: \"2014-12-05\" \"2014-12-05\" ...\n  .. ..$ X_ADDR    : num [1:323] 31596 28679 29655 26783 26202 ...\n  .. ..$ Y_ADDR    : num [1:323] 29220 29782 29975 29934 30006 ...\n  .. ..$ SHAPE_Leng: num [1:323] 5267 3506 1741 3314 2826 ...\n  .. ..$ SHAPE_Area: num [1:323] 1630379 559816 160807 595429 387429 ...\n  ..@ polygons   :List of 323\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. [list output truncated]\n  ..@ plotOrder  : int [1:323] 285 302 313 16 269 75 297 276 213 56 ...\n  ..@ bbox       : num [1:2, 1:2] 2668 15749 56396 50256\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame.\n\n\n\nglimpse(sg)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 60 obs. of  4 variables:\n  .. ..$ GDO_GID   : num [1:60] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ MSLINK    : num [1:60] 1 3 5 6 7 8 9 10 11 12 ...\n  .. ..$ MAPID     : num [1:60] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ COSTAL_NAM: chr [1:60] \"Linkway\" \"SENTOSA\" \"PULAU SARIMBUN\" \"PULAU SAMULUN\" ...\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-spatial-class-into-generic-sp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-spatial-class-into-generic-sp-format.",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.2 Converting Spatial Class into generic sp format.",
    "text": "2.9.2 Converting Spatial Class into generic sp format.\nIn order to use the spatstat package, the data must be in ppp object form. There is no direct way to convert Spatial Classes into ppp objects. So, we start by converting the Spatial Classes into Spatial Objects first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_spsg_sp\n\n\n\nglimpse(childcare_sp)\n\nFormal class 'SpatialPoints' [package \"sp\"] with 3 slots\n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\nglimpse(sg_sp)\n\nFormal class 'SpatialPolygons' [package \"sp\"] with 4 slots\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\n\nGenerally, Spatial Classes are more structured and more suitable for complex and more rigorous Spatial Analytics. Generic ‘sp’ objects allow for simpler, more flexible, data manipulation where having a format Spatial Class is necessary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.3 Converting the generic sp format into Spatstat’s ppp format.",
    "text": "2.9.3 Converting the generic sp format into Spatstat’s ppp format.\nTo convert the spatial data into the required ppp form, we implement the as.ppp() function of the spatstat package. ::: panel-tabset ## Conversion to ppp object\n\nchildcare_ppp=as.ppp(childcare_sf)\n(childcare_ppp)\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#summary-of-newly-obtained-ppp-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#summary-of-newly-obtained-ppp-object",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "Summary of newly obtained ppp object",
    "text": "Summary of newly obtained ppp object\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n:::\nWe will now plot the newly obtained ppp object to visualize the differences to previous data-frames.\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#handling-duplicated-points",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.4 Handling duplicated points",
    "text": "2.9.4 Handling duplicated points\nWe check childcare_ppp for any duplicates in order to handle duplicates if they are present.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nWe now check for the points of co-incidence using the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe further verify if there are any duplicates by checking to see if there are any points occurring more than once in the object using the code chunk below.\n\nsum(multiplicity(childcare_ppp)&gt;1)\n\n[1] 0\n\n\nIt appears that there is indeed 0 duplicated point events.\n\nIn the case that there are duplicates, they can be handled as follows. We use jittering (shown in the code chunk below), which adds a small perturbation to the duplicate points so that they do not occupy the exact same space. Additionally, we could also make each point unique and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need to implement analytical techniques that take these marks into account.\n\n#childcare_ppp_jit &lt;- rjitter(childcare_ppp, \n #                            retry=TRUE, \n  #                           nsim=1, \n   #                          drop=TRUE)\n\n\n\nAnd then we can check for any duplicates to ensure that the above function worked using the following code chunk, the same as earlier.\n\n# any(duplicated(childcare_ppp_jit))\n\n\n\n2.9.5 Creating an owin object\nWhen analyzing Spatial Point patterns, it is a good practice to confine the boundaries of the analysis with a Geographical area, such as Singapore’s boundary. Using the spatstat package, we can create an owin object that is designed to represent such polygonal regions.\nWe use the as.owin() function from spatstat for this transformation.\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot of the newly obtained sg_owin objectSummary of the object\n\n\nWe can plot the newly obtained object using the code chunk below.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nFrom the summary, we see that the object itself is a polygonal boundary with a window area of 725376000 square units."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-the-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-the-g-function",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.10.1 Analysing Spatial Point Process Using the G-Function",
    "text": "2.10.1 Analysing Spatial Point Process Using the G-Function\nIn this section we will learn how to compute a G-function estimation by using the Gest() function of the spatstat package.\nWe will also perform a monte-carlo simulation test using envelope() function of the spatstat package.\n\n2.10.1.1 Extracting target planning areas.\nUsing the code chunk below, as in Hands-on Exercise 2 Part 1, we will extract the data for selected target planning areas for analysis.\nThe code chunk below will first extract the target planning areas and then convert it into the required form for analysis.\n\n\nClick to show/hide code.\n\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\nys &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"YISHUN\")\nbbk &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"BUKIT BATOK\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\npg_owin = as.owin(pg)\nys_owin = as.owin(ys)\nbbk_owin = as.owin(bbk)\njw_owin = as.owin(jw)\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                          retry=TRUE, \n                           nsim=1, \n                            drop=TRUE)\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_ys_ppp = childcare_ppp_jit[ys_owin]\nchildcare_bbk_ppp = childcare_ppp_jit[bbk_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\n\n\n2.10.1.2 Calculating G-function estimates and testing for Complete Spatial Randomness.\n\nJurong West Planning AreaYishun Planning Area\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for the Jurong West planning area. Following that, we plot the result.\n\nG_JW = Gest(childcare_jw_ppp, correction = \"border\")\nplot(G_JW, xlim=c(0,500))\n\n\n\n\n\n\n\n\nThe empirical G(r) (the solid black line in the plot above) consistently lies above the theoretical G(r) (dashed red line in the plot above) across a significant range of r. This indicates that the points in our data—childcare centers in Jurong West—exhibit a higher degree of clustering than would be expected under a completely random distribution.\nTo confirm our findings above, we carry out a hypothesis test. The following are our hypotheses:\n\nHo = The distribution of childcare services at Jurong West are randomly distributed.\nH1= The distribution of childcare services at Jurong West are not randomly distributed.\n\nThe null hypothesis (Ho) will be rejected if p-value&lt;0.001.\nWe will perform a monte-carlo simulation, using the envelope() function of the spatstat package, using the g-function.\n\nG_JW.csr &lt;- envelope(childcare_jw_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nThe nsim argument in the envelope() function tells the function how many simulations to run.\n\n\nWe can also calculate an estimate for the p-value using the code chunk below.\n\n# Number of simulations where the observed value is more extreme\n#more_extreme &lt;- sum(G_JW.csr$obs &gt; G_JW.csr$hi | G_JW.csr$obs &lt; #G_JW.csr$lo)\n\n# Calculate the p-value\n#p_value &lt;- (more_extreme + 1) / (G_JW.csr$nsim + 1)\n\n\nWe now create a plot to visualize this.\n\nplot(G_JW.csr)\n\n\n\n\n\n\n\n\nThe observed spatial distribution of childcare centers in Jurong West indicates that the overall pattern does not significantly deviate from what would be expected under complete spatial randomness (CSR) for most distances.\n\n\nWe now carry out the exact same steps as above for the Yishun Planning area.\nFirst, we implement the gest() function to compute a G-function estimate.\n\nG_YS = Gest(childcare_ys_ppp, correction = \"border\")\nplot(G_YS, xlim=c(0,500))\n\n\n\n\n\n\n\n\nOnce again we see that the solid black line, the empirical G(r) lies over the dashed red line consistently. This indicates a higher level of clustering, even more so than in Jurong West, than would be expected under a completely random distribution.\nWe now carry out the hypothesis test using the envelope() function. The following are our hypotheses: -\n\nHo = The distribution of childcare services at Yishun are randomly distributed.\nH1= The distribution of childcare services at Yishun are not randomly distributed.\n\nThe null hypothesis (Ho) will be rejected if p-value&lt;0.001.\n\nG_YS.csr &lt;- envelope(childcare_ys_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe now create a plot to visualize this.\n\nplot(G_YS.csr)\n\n\n\n\n\n\n\n\nThe observed spatial distribution of childcare centers in Yishun exhibits a slight tendency, more so than Jurong West, towards clustering at certain distances, as evidenced by the brief instances where the empirical G(r) exceeds the Monte Carlo envelope. We do have sufficient evidence to reject the null hypothesis.\n\n\n\n\nWhen using the envelope() test like above, we generally reject the null hypothesis based on whether the observed function lies inside or outside the ‘envelope’. Another key factor to note is the distances depicted by the x-axis. For example, the black line (observed values) may cross the upper bound of the upper envelope at a certain distance, below which there is random distribution, while above it there is more clustering.\n\n\n\nThe grey zone indicates the confidence envelop (In this case, we have set it as 95% as indicated by the critical value of 0.05)\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\nFor reference, this is how we can perform the Clark-Evans test to obtain the test statistics, namely the R value, to draw insights. Closer to zero means more cluster. If the index is equal to 1, the pattern is random, and if its more than 1, the trend is towards dispersion or competition.\n\n# Perform the Clark-Evans test\nclark_evans_result &lt;- clarkevans(childcare_jw_ppp, correction = \"none\")\n\n# Print the result\nprint(clark_evans_result)\n\n[1] 0.9264018"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the spatial relationships between individual observations and their neighboring areas, rather than summarizing these relationships across an entire map. Unlike global summary statistics, LMSA provides localized scores that reveal the spatial structure within the data. Despite this difference, the underlying intuition behind these local metrics is similar to that of global ones. In fact, some global measures can be broken down into their local counterparts. For example, Local Indicators of Spatial Association (LISA) are derived from global measures of spatial autocorrelation.\nIn addition to LISA, another important LMSA is the Getis-Ord Gi-statistic, which offers complementary insights. Both LISA and Getis-Ord’s Gi-statistics help us understand spatial patterns in geographically referenced data, providing valuable tools for localized spatial analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#performing-relational-join",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.10.1 Performing relational join",
    "text": "5.10.1 Performing relational join\nWe will update the attribute table of Hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data-frame. We can do this by using the left_join() function of the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.1 Computing Contiguity Spatial Weights",
    "text": "5.12.1 Computing Contiguity Spatial Weights\nBefore computing the local spatial autocorrelation statistics, we need to construct a spatial weights of the study area, the spatial weights are used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe now implement the poly2nb() function of the spdep package to compute contiguity weight matrices for the study area selected.\nUsing this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.\nIn this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.\nYou may refer to the spdep package documentation here to learn more about its functions and arguments.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the output above, we can infer that there are 88 area units in total in Hunan. The most connected area unit has 11 neighbors. There are two area units with just 1 neighbor, while 24 area units have 5 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#row-standardized-weights-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.2 Row-Standardized Weights Matrix",
    "text": "5.12.2 Row-Standardized Weights Matrix\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nThe nb2listw() function requires an input of class nb, representing a neighborhood object. The function’s two key arguments are style and zero.policy.\n\nThe style argument defines how the weights are calculated. It can take several values:\n\n\"B\": Binary coding, where weights are either 0 or 1.\n\"W\": Row-standardized, where the sum of weights across all neighbors equals 1.\n\"C\": Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.\n\"U\": A variation of \"C\", where weights are normalized by the number of neighbors.\n\"S\": A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.\n\nThe zero.policy argument, when set to TRUE, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector x, effectively setting the lagged value to zero for those regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-local-morans-i",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.3 Computing local Moran’s I",
    "text": "5.12.3 Computing local Moran’s I\nWe implement the localmoran() function of spdep compute the local Moran’s I statistic. This function helps us compute li values, given a set of zi values and a listw object providing neighbor weighting information for the polygon associated with the zi values.\nWe compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nWe now use the printCoefmat() to display the content of the local Moran matrix that we created.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n5.12.3.1 Mapping the local Moran’s I\nBefore we map the local Moran’s I map, it is wise to append the local Moran’s data-frame (localMI) onto the Hunan SpatialPolygonDataFrame.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n5.12.3.2 Mapping Local Moran’s I values\nWe now make use of the tmap package and its choropleth mapping functions to plot the local Moran’s I values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n5.12.3.3 Mapping Local Moran’s I p-values.\nThe Choropleth reveals the presence of both positive, as well as negative I values. This indicates that there are varying levels of spatial autocorrelation, however, we must examine the p-values for these I values to check for statistical significance.\nWe use the tmap package to draw a choropleth map of Moran’s I p-values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n5.12.3.4 Mapping both local Moran’s I values and p-values.\nIn the interest of easier analysis and interpretation, we plot the two maps next to each other.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.1 Plotting Moran Scatterplot",
    "text": "5.12.1 Plotting Moran Scatterplot\nThe Moran Scatterplot depicts the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will implement the moran.plot() function of the spdep package to create the plot.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants.\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.2 Plotting Moran Scatterplot with Standardised variable",
    "text": "5.12.2 Plotting Moran Scatterplot with Standardised variable\nWe first implement the scale() function to center and scale the variable. Here, centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nNote that the as.vector() function is added so that we get a vector as the output. This allows us to map it neatly into our data-frame.\n\nWe can now plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#preparing-lisa-map-classes",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.3 Preparing LISA map classes",
    "text": "5.12.3 Preparing LISA map classes\nWe now prepare the data in order to facilitate plotting a LISA Cluster Map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNow, we will derive the spatially lagged variable of interest (i.e: GDPPC) and center the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nNow, we work on centering the local Moran around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nWe set the significance level for the Local Moran in the code chunk below.\n\nsignif &lt;- 0.05       \n\nThe following code chunk defines the four categories (low-low (1), low-high (2), high-low (3), high-high (4))\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nFinally, we place the non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\nYou can simply write all of this in one code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-lisa-map",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.4 Plotting LISA Map",
    "text": "5.12.4 Plotting LISA Map\nWe now use the tmap package to plot the LISA Map.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nIn the interest of easier visualization and interpretation, we plot the GDPPC and their corresponding quadrants next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nFrom the LISA map, we can see that the regions in the top 2 quadrants are next to each others, indicating positive spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getis-and-ords-g-statistics",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.1 Getis and Ord’s G-Statistics",
    "text": "5.13.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistic used to detect spatial anomalies is the Getis-Ord G-statistic (Getis and Ord, 1972; Ord and Getis, 1995). This method examines spatial relationships within a defined proximity to identify clusters of high or low values. Statistically significant hotspots are areas where high values are spatially clustered, meaning that not only do these areas have high values, but their neighboring areas also exhibit similarly high values.\nThe analysis involves three key steps:\n\nDeriving the spatial weight matrix: This defines the spatial relationships between areas, specifying which locations are considered neighbors based on proximity.\nComputing the Gi statistic: This step calculates the G-statistic for each location, identifying regions where values are significantly higher or lower than expected.\nMapping the Gi statistics: The results are visualized to reveal spatial patterns of high-value clusters (hotspots) and low-value clusters (cold spots).\n\nThis approach is useful for identifying localized patterns of spatial clustering and detecting significant anomalies in the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#deriving-distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#deriving-distance-based-weight-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.2 Deriving Distance Based Weight Matrix",
    "text": "5.13.2 Deriving Distance Based Weight Matrix\nWe start by defining a new set of neighbors. While the spatial autocorrelation considered units which shared borders, for Getis-Ord, we will define the neighbors based on distance.\n\nThere are two types of distance-based proximity matrices:\n\nFixed Distance Weight Matrix\nAdaptive Distance Weight Matrix\n\n\n\n5.13.2.1 Deriving distance-based weight matrix\nBefore creating our connectivity graph, we need to assign a point to each polygon. This requires more than simply running st_centroid() on the us.bound spatial object. Specifically, we need to extract the coordinates into a separate data frame. To achieve this, we’ll use a mapping function.\nMapping functions apply a specific operation to each element of a vector and return a vector of the same length. In our case, the input vector will be the geometry column from us.bound, and the function we’ll apply is st_centroid(). We’ll use the map_dbl variation from the purrr package, which is designed to return numeric (double) values.\nTo extract the longitude values, we’ll map the st_centroid() function over the geometry column and use double bracket notation [[]] with 1 to access the first element of each centroid, which corresponds to the longitude.\nFor more detailed information, you can refer to the map documentation here.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude, but with one key difference- we access the second value per centroid with [[2]] instead of [[1]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have obtained both latitude and longitude, we will put them into the same object using the cbind() function.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n5.13.2.2 Determine the cut-off distance\nTo determine the upper limit for the distance band, we follow these steps:\n\nFind the k-nearest neighbors: Use the knearneigh() function from the spdep package. This function returns a matrix that contains the indices of points corresponding to the k-nearest neighbors for each observation.\nConvert to a neighbors list: Take the k-nearest neighbors object returned by knearneigh() and convert it into a neighbors list (class nb) by using the knn2nb() function. This generates a list of integer vectors, where each vector contains the region numbers corresponding to its neighbors.\nCalculate neighbor distances: Use the nbdists() function from spdep to calculate the distances between neighbors. The function returns the lengths of neighbor relationship edges in the units of the coordinates (e.g., kilometers if the coordinates are geographic).\nFlatten the distance list: The distances returned by nbdists() are stored in a list. Use the unlist() function to remove the list structure and return a single vector of distances.\n\nThis process helps identify the upper limit for a distance band by analyzing the distances between neighboring regions.\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the output above, we can infer that the largest first-nearest neighbor distance is 61.79KM- using this as the upper threshold gives certainty that all units will have at least one neighbor.\n\n\n5.13.2.3 Computing fixed distance weight matrix\nWe implement the dnearneigh() function of the spdep package to compute the distance weight matrix.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAfter this, we implement the nb2listw() function to convert the nb object into spatial weights object.\nOn average, each region has approximately 3.68 neighbors.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.3 Computing Adaptive Distance Weight Matrix",
    "text": "5.13.3 Computing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually urban areas) tend to have more neighbours and the less densely settled areas (usually the rural areas) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either by accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAfter this, we implement the nb2list2() function to convert the nb object into a spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "title": "In Class Exercise 2",
    "section": "",
    "text": "Introduction\nIn this exercise, we reinforce our learning and deal with any problems we faced from Hands-On Exercise 2 by further application of the skills gained from it.\n\n\nData and Packages\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\nset.seed(1234)\n\n\nTo install the maptools package, which is now retired, we will use the code chunk below.\n\ninstall.packages(\"maptools\", repos=\"https://packagemanager.posit.co/cran/2023-10-13\") #Posit is a great source for downloading retired libraries, and even facilitates the development of Shiny apps.\n\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently.\n\n\nCreating a coastal outline\nUsing the st_union() function, we can derive the coastal outline of the sf tibble data-frame.\n\nsg_sf= mpsz_sf %&gt;% st_union\n\nWe will then have the figure below, which will help improve the quality of our analysis.\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation\nWe now implement two different methods to convert KDE output into grid object.\nWe first convert the data into the right format for analysis.\n\nchildcare_ppp=as.ppp(childcare_sf)\nchildcareSG_ppp.km &lt;- rescale.ppp(childcare_ppp, 1000, \"km\")\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\n\nmaptools methodspatstat.geom method\n\n\n\ngridded_kde_childcareSG_ad=maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\nplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_ad=as(kde_childcareSG_adaptive, \"SpatialGridDataFrame\")\nplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\nAs we can see, both have very similar/same results however we prefer to use spatstat.geom as maptools has been retired..\n\n\nPart 2- The data\nFor the purpose of this exercise, three basic data sets are needed, they are:\n\nThailand Road Accident (2019-2022) on Kaggle\nThailand Roads (OpenStreetMap Export) on HDX.\nThailand- Subnational Administrative Boundaries on HDX.\n\n\n\nImporting the Traffic Accident Data\nWe will import the data file into our environment.\n\nrdacc_sf=read_csv(\"data/thai_road_accident_2019_2022.csv\")%&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude !=\"\")%&gt;%\n  st_as_sf(coords=c(\n    \"longitude\", \"latitude\"), \n    crs=4326)%&gt;%\n  st_transform(crs=32647)\n\n\n\nVisualizing the data"
  }
]