[
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex1.html",
    "title": "Take Home Exercise 1: Geospatial Analytics for Social Good",
    "section": "",
    "text": "1 Introduction\nThailand highest death rate amongst ASEAN countries. Give more facts about road accidents from WHO.\nStudy area will be Bangkok Metropolitan Region.\nProjected coordinate system of Thailand is WGS84, UTM ZONE 47N and EPSG CODE IS 32647"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "href": "In-class_Ex/In-class_Ex2/In-class_Ex2.html",
    "title": "In Class Exercise 2",
    "section": "",
    "text": "Introduction\nIn this exercise, we reinforce our learning and deal with any problems we faced from Hands-On Exercise 2 by further application of the skills gained from it.\n\n\nData and Packages\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\nset.seed(1234)\n\n\nTo install the maptools package, which is now retired, we will use the code chunk below.\n\ninstall.packages(\"maptools\", repos=\"https://packagemanager.posit.co/cran/2023-10-13\") #Posit is a great source for downloading retired libraries, and even facilitates the development of Shiny apps.\n\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex2\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently.\n\n\nCreating a coastal outline\nUsing the st_union() function, we can derive the coastal outline of the sf tibble data-frame.\n\nsg_sf= mpsz_sf %&gt;% st_union\n\nWe will then have the figure below, which will help improve the quality of our analysis.\n\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\nKernel Density Estimation\nWe now implement two different methods to convert KDE output into grid object.\nWe first convert the data into the right format for analysis.\n\nchildcare_ppp=as.ppp(childcare_sf)\nchildcareSG_ppp.km &lt;- rescale.ppp(childcare_ppp, 1000, \"km\")\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\n\nmaptools methodspatstat.geom method\n\n\n\ngridded_kde_childcareSG_ad=maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\nplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\ngridded_kde_childcareSG_ad=as(kde_childcareSG_adaptive, \"SpatialGridDataFrame\")\nplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n\nAs we can see, both have very similar/same results however we prefer to use spatstat.geom as maptools has been retired..\n\n\nImporting the Traffic Accident Data\nWe will import the data file into our environment.\n\nrdacc_sf=read_csv(\"data/thai_road_accident_2019_2022.csv\")%&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude !=\"\")%&gt;%\n  st_as_sf(coords=c(\n    \"longitude\", \"latitude\"), \n    crs=4326)%&gt;%\n  st_transform(crs=32647)\n\n\nVisualizing the accident data."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex1/data/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "",
    "text": "Spatial Point Pattern Analysis involves examining the distribution or arrangement of a set of points on a surface. These points can represent various phenomena, such as:\n\nEvents like crime, traffic accidents, or disease onset,\nBusiness services, such as coffee shops and fast-food outlets,\nFacilities like childcare and eldercare centers.\n\nIn this hands-on exercise, we will utilize functions from the spatstat package to explore the spatial distribution of childcare centers in Singapore.\nOur primary questions are:\n\nAre childcare centers in Singapore randomly distributed across the country?\nIf they are not randomly distributed, where are the areas with a higher concentration of childcare centers?\n\n\n\nThe data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\n\n\nClick to show/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\n\nSetting seed\n\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#data-and-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#data-and-libraries",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "",
    "text": "The data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)\n\n\n\n\nClick to show/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\n\nSetting seed\n\n\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#importing-the-spatial-data",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.8.1 Importing the Spatial Data",
    "text": "2.8.1 Importing the Spatial Data\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently.\n\nNote that when working transforming crs, we can code more efficiently by using the code chunk below for example (which we implemented above). Using ‘%&gt;%’ allows you to chain multiple operations together.\n\n#childcare_sf=st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n # st_transform(crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#mapping-the-geospatial-data",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.8.2 Mapping the Geospatial Data",
    "text": "2.8.2 Mapping the Geospatial Data\nWe prepare a pin map using functions from the tmap package.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are several benefits to using a pin map in this situation. Firstly, since it is an interactive map we can move around the map freely and look at specific areas that we’re interested in. Second, we can query the information for each simple feature by simply clicking them. Additionally, you can also change the background of the internet map layer- currently, three internet map layers are provided (ESRI.WorldGrayCanvas [default], ESRI.WorldTopoMap, and OpenStreetMap.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.1 Converting simple feature data-frames to sp’s Spatial Class",
    "text": "2.9.1 Converting simple feature data-frames to sp’s Spatial Class\nWe can convert geospatial data from a simple feature data-frame to sp’s Spatial class using the as_Spatial() function of the sf package. The code chunk below showcases how it will be done.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nNow, we want to have a look at each of these data-frames. We do it using the glimpse() function.\n\nChildcareMPSZsg\n\n\n\nglimpse(childcare)\n\nFormal class 'SpatialPointsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 1545 obs. of  2 variables:\n  .. ..$ Name       : chr [1:1545] \"kml_1\" \"kml_2\" \"kml_3\" \"kml_4\" ...\n  .. ..$ Description: chr [1:1545] \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ ...\n  ..@ coords.nrs : num(0) \n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Points Data-Frame.\n\n\n\nglimpse(mpsz)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 323 obs. of  15 variables:\n  .. ..$ OBJECTID  : int [1:323] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ SUBZONE_NO: int [1:323] 1 1 3 8 3 7 9 2 13 7 ...\n  .. ..$ SUBZONE_N : chr [1:323] \"MARINA SOUTH\" \"PEARL'S HILL\" \"BOAT QUAY\" \"HENDERSON HILL\" ...\n  .. ..$ SUBZONE_C : chr [1:323] \"MSSZ01\" \"OTSZ01\" \"SRSZ03\" \"BMSZ08\" ...\n  .. ..$ CA_IND    : chr [1:323] \"Y\" \"Y\" \"Y\" \"N\" ...\n  .. ..$ PLN_AREA_N: chr [1:323] \"MARINA SOUTH\" \"OUTRAM\" \"SINGAPORE RIVER\" \"BUKIT MERAH\" ...\n  .. ..$ PLN_AREA_C: chr [1:323] \"MS\" \"OT\" \"SR\" \"BM\" ...\n  .. ..$ REGION_N  : chr [1:323] \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" ...\n  .. ..$ REGION_C  : chr [1:323] \"CR\" \"CR\" \"CR\" \"CR\" ...\n  .. ..$ INC_CRC   : chr [1:323] \"5ED7EB253F99252E\" \"8C7149B9EB32EEFC\" \"C35FEFF02B13E0E5\" \"3775D82C5DDBEFBD\" ...\n  .. ..$ FMEL_UPD_D: Date[1:323], format: \"2014-12-05\" \"2014-12-05\" ...\n  .. ..$ X_ADDR    : num [1:323] 31596 28679 29655 26783 26202 ...\n  .. ..$ Y_ADDR    : num [1:323] 29220 29782 29975 29934 30006 ...\n  .. ..$ SHAPE_Leng: num [1:323] 5267 3506 1741 3314 2826 ...\n  .. ..$ SHAPE_Area: num [1:323] 1630379 559816 160807 595429 387429 ...\n  ..@ polygons   :List of 323\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. [list output truncated]\n  ..@ plotOrder  : int [1:323] 285 302 313 16 269 75 297 276 213 56 ...\n  ..@ bbox       : num [1:2, 1:2] 2668 15749 56396 50256\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame.\n\n\n\nglimpse(sg)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 60 obs. of  4 variables:\n  .. ..$ GDO_GID   : num [1:60] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ MSLINK    : num [1:60] 1 3 5 6 7 8 9 10 11 12 ...\n  .. ..$ MAPID     : num [1:60] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ COSTAL_NAM: chr [1:60] \"Linkway\" \"SENTOSA\" \"PULAU SARIMBUN\" \"PULAU SAMULUN\" ...\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-spatial-class-into-generic-sp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-spatial-class-into-generic-sp-format.",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.2 Converting Spatial Class into generic sp format.",
    "text": "2.9.2 Converting Spatial Class into generic sp format.\nIn order to use the spatstat package, the data must be in ppp object form. There is no direct way to convert Spatial Classes into ppp objects. So, we start by converting the Spatial Classes into Spatial Objects first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_spsg_sp\n\n\n\nglimpse(childcare_sp)\n\nFormal class 'SpatialPoints' [package \"sp\"] with 3 slots\n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\nglimpse(sg_sp)\n\nFormal class 'SpatialPolygons' [package \"sp\"] with 4 slots\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\n\nGenerally, Spatial Classes are more structured and more suitable for complex and more rigorous Spatial Analytics. Generic ‘sp’ objects allow for simpler, more flexible, data manipulation where having a format Spatial Class is necessary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.3 Converting the generic sp format into Spatstat’s ppp format.",
    "text": "2.9.3 Converting the generic sp format into Spatstat’s ppp format.\nTo convert the spatial data into the required ppp form, we implement the as.ppp() function of the spatstat package. ::: panel-tabset ## Conversion to ppp object\n\nchildcare_ppp=as.ppp(childcare_sf)\n(childcare_ppp)\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#summary-of-newly-obtained-ppp-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#summary-of-newly-obtained-ppp-object",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "Summary of newly obtained ppp object",
    "text": "Summary of newly obtained ppp object\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n:::\nWe will now plot the newly obtained ppp object to visualize the differences to previous data-frames.\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#handling-duplicated-points",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.9.4 Handling duplicated points",
    "text": "2.9.4 Handling duplicated points\nWe check childcare_ppp for any duplicates in order to handle duplicates if they are present.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nWe now check for the points of co-incidence using the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe further verify if there are any duplicates by checking to see if there are any points occurring more than once in the object using the code chunk below.\n\nsum(multiplicity(childcare_ppp)&gt;1)\n\n[1] 0\n\n\nIt appears that there is indeed 0 duplicated point events.\n\nIn the case that there are duplicates, they can be handled as follows. We use jittering (shown in the code chunk below), which adds a small perturbation to the duplicate points so that they do not occupy the exact same space. Additionally, we could also make each point unique and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need to implement analytical techniques that take these marks into account.\n\n#childcare_ppp_jit &lt;- rjitter(childcare_ppp, \n #                            retry=TRUE, \n  #                           nsim=1, \n   #                          drop=TRUE)\n\n\n\nAnd then we can check for any duplicates to ensure that the above function worked using the following code chunk, the same as earlier.\n\n# any(duplicated(childcare_ppp_jit))\n\n\n\n2.9.5 Creating an owin object\nWhen analyzing Spatial Point patterns, it is a good practice to confine the boundaries of the analysis with a Geographical area, such as Singapore’s boundary. Using the spatstat package, we can create an owin object that is designed to represent such polygonal regions.\nWe use the as.owin() function from spatstat for this transformation.\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot of the newly obtained sg_owin objectSummary of the object\n\n\nWe can plot the newly obtained object using the code chunk below.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nFrom the summary, we see that the object itself is a polygonal boundary with a window area of 725376000 square units."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-the-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-the-g-function",
    "title": "Hands On Exercise 2- Part 2: 2nd order Spatial Point Patterns",
    "section": "2.10.1 Analysing Spatial Point Process Using the G-Function",
    "text": "2.10.1 Analysing Spatial Point Process Using the G-Function\nIn this section we will learn how to compute a G-function estimation by using the Gest() function of the spatstat package.\nWe will also perform a monte-carlo simulation test using envelope() function of the spatstat package.\n\n2.10.1.1 Extracting target planning areas.\nUsing the code chunk below, as in Hands-on Exercise 2 Part 1, we will extract the data for selected target planning areas for analysis.\nThe code chunk below will first extract the target planning areas and then convert it into the required form for analysis.\n\n\nClick to show/hide code.\n\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\nys &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"YISHUN\")\nbbk &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"BUKIT BATOK\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\npg_owin = as.owin(pg)\nys_owin = as.owin(ys)\nbbk_owin = as.owin(bbk)\njw_owin = as.owin(jw)\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                          retry=TRUE, \n                           nsim=1, \n                            drop=TRUE)\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_ys_ppp = childcare_ppp_jit[ys_owin]\nchildcare_bbk_ppp = childcare_ppp_jit[bbk_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\n\n\n2.10.1.2 Calculating G-function estimates and testing for Complete Spatial Randomness.\n\nJurong West Planning AreaYishun Planning Area\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for the Jurong West planning area. Following that, we plot the result.\n\nG_JW = Gest(childcare_jw_ppp, correction = \"border\")\nplot(G_JW, xlim=c(0,500))\n\n\n\n\n\n\n\n\nThe empirical G(r) (the solid black line in the plot above) consistently lies above the theoretical G(r) (dashed red line in the plot above) across a significant range of r. This indicates that the points in our data—childcare centers in Jurong West—exhibit a higher degree of clustering than would be expected under a completely random distribution.\nTo confirm our findings above, we carry out a hypothesis test. The following are our hypotheses:\n\nHo = The distribution of childcare services at Jurong West are randomly distributed.\nH1= The distribution of childcare services at Jurong West are not randomly distributed.\n\nThe null hypothesis (Ho) will be rejected if p-value&lt;0.001.\nWe will perform a monte-carlo simulation, using the envelope() function of the spatstat package, using the g-function.\n\nG_JW.csr &lt;- envelope(childcare_jw_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nThe nsim argument in the envelope() function tells the function how many simulations to run.\n\n\nWe can also calculate an estimate for the p-value using the code chunk below.\n\n# Number of simulations where the observed value is more extreme\n#more_extreme &lt;- sum(G_JW.csr$obs &gt; G_JW.csr$hi | G_JW.csr$obs &lt; #G_JW.csr$lo)\n\n# Calculate the p-value\n#p_value &lt;- (more_extreme + 1) / (G_JW.csr$nsim + 1)\n\n\nWe now create a plot to visualize this.\n\nplot(G_JW.csr)\n\n\n\n\n\n\n\n\nThe observed spatial distribution of childcare centers in Jurong West indicates that the overall pattern does not significantly deviate from what would be expected under complete spatial randomness (CSR) for most distances.\n\n\nWe now carry out the exact same steps as above for the Yishun Planning area.\nFirst, we implement the gest() function to compute a G-function estimate.\n\nG_YS = Gest(childcare_ys_ppp, correction = \"border\")\nplot(G_YS, xlim=c(0,500))\n\n\n\n\n\n\n\n\nOnce again we see that the solid black line, the empirical G(r) lies over the dashed red line consistently. This indicates a higher level of clustering, even more so than in Jurong West, than would be expected under a completely random distribution.\nWe now carry out the hypothesis test using the envelope() function. The following are our hypotheses: -\n\nHo = The distribution of childcare services at Yishun are randomly distributed.\nH1= The distribution of childcare services at Yishun are not randomly distributed.\n\nThe null hypothesis (Ho) will be rejected if p-value&lt;0.001.\n\nG_YS.csr &lt;- envelope(childcare_ys_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe now create a plot to visualize this.\n\nplot(G_YS.csr)\n\n\n\n\n\n\n\n\nThe observed spatial distribution of childcare centers in Yishun exhibits a slight tendency, more so than Jurong West, towards clustering at certain distances, as evidenced by the brief instances where the empirical G(r) exceeds the Monte Carlo envelope. We do have sufficient evidence to reject the null hypothesis.\n\n\n\n\nWhen using the envelope() test like above, we generally reject the null hypothesis based on whether the observed function lies inside or outside the ‘envelope’. Another key factor to note is the distances depicted by the x-axis. For example, the black line (observed values) may cross the upper bound of the upper envelope at a certain distance, below which there is random distribution, while above it there is more clustering.\n\n\n\nThe grey zone indicates the confidence envelop (In this case, we have set it as 95% as indicated by the critical value of 0.05)\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\nFor reference, this is how we can perform the Clark-Evans test to obtain the test statistics, namely the R value, to draw insights. Closer to zero means more cluster. If the index is equal to 1, the pattern is random, and if its more than 1, the trend is towards dispersion or competition.\n\n# Perform the Clark-Evans test\nclark_evans_result &lt;- clarkevans(childcare_jw_ppp, correction = \"none\")\n\n# Print the result\nprint(clark_evans_result)\n\n[1] 0.9264018"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices. On the other hands, Geovisualization works by providing graphical ideations to render a place, a phenomenon or a process visible, enabling a humans most powerful information-processing abilities- those of spatial cognition associated with our eye-brain vision system, to be directly brought to bear.\n\n\nTo fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nAs discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#getting-started",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "To fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#importing-the-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#importing-the-data-into-r",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "As discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#chropleth-mapping-geospatial-data-using-tmap.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01_2.html#chropleth-mapping-geospatial-data-using-tmap.",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Choropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of the pacman package to check if tidyverse has been installed. If it has been, it will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\nThe relevant data is now going to be imported using the st_read() function of package sf.\n\nmpsz=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output above, it can be inferred that there are 323 multipolygon features and 15 fields in mpsz, which is projected in the SVY21 coordinate system.\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output above reveals that there are 3138 features and 2 fields in the cyclingpath linestring feature data frame, which is also projected in the SVY21 coordinate system.\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data-frame, with 2290 features and 2 fields. Unlike the two previous simple feature data-frames, preschoolis projected using the WGS84 coordinate system.\n\n\n\n\nWe now focus on the different methods of retrieving information related to the contents of a simple feature data-frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list of class sfc. The geometry list–column can be retrieved using the mpsz$geom or mpsz[[1]], but st_geometry, shown below, is the most commonly used method.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\nUsing glimpse(), a function of the dplyr package, we can learn more about the data-frame beyond the basic feature information.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nThe function head(), an in-built R function, will reveal complete information about a feature object.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\nIn Geopspatial Data Science, simply looking at the feature information is not enough. Visualizing the geospatial features is a key step to improve our understanding of the data. We can use plot(), an in-built function of R Graphic, to facilitate visualization.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nBy default, a multi-plot of all attributes is obtained, up to a reasonable maximum as shown above. We can also choose to plot only the geometry by implementing the code shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz['PLN_AREA_N'])\n\n\n\n\n\n\n\n\nIt must be noted that plot() plots the geospatial data for a quick overview. For high cartographic quality, R packages such as tmap should be used.\n\n\n\nMap projection is an important property of geospatial data. When performing geoprocessing using two geospatial datasets, we need to ensure that they are both projected using similar coordinate systems.\n\n\nOne of the most common issues faced when importing Geospatial data into R is that the coordinate system of the source data was either missing (for example, due to missing .proj for ESRI Shapefile) or wrongly assigned during the importing process.\nBy using the st_crs() function of the sf package, we can view the Coordinate Reference System of mpsz.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data-frame is projected in SVY21, it indicates that the EPSG is 9001. This is the wrong EPSG- the correct EPSG code for SVY21 should be 3414.\nTo correct the EPSG code, we use st_set_crs() of the sf package as shown below.\n\nmpsz3414&lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe now check the CSR again using the st_crs() function from earlier,\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nWhen analyzing geospatial data, its common to have to transform the original data from geographic coordinate system to project coordinate system because the geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\nEarlier, we learnt that the preschool simple feature data-frame was in WGS84 format. In this scenario, using st_set_crs() is not appropriate because we need to re-project preschool from one coordinate system to another coordinate system mathematically.\nWe use the st_transform() function for this.\n\npreschool3414&lt;- st_transform(preschool, crs=3414)\n\nWe now check for the contents of the newly transformed data-frame using the st_geometry() function from earlier.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nIt is now the appropriate projected coordinate system now- SVY21. Additionally, if you refer to the Bounding Box data above, the values are greater than the 0-360 range of decimal degrees commonly used by most geographic coordinate systems.\n\n\n\n\nIt is not unusual to come across data such as the listingdata set obtained from AirBnb. Such data is called Aspatial data. This is because it has separate data fields containing the x and y coordinates of the data points, unlike Geospatial data.\n\n\nSince the listing data set is in csv format, we use the read_csv() function of the readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will now examine if the data file has been imported correctly for analysis.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe above output informs us that there are 18 columns and 3540 rows of data. Two important columns that will be used in the next phase of the analysis are the latitude and longitude columns. These columns are in decimal degree format. As a best guess, it is assumed that the data is projected in the WGS84 Geographic Coordinate System.\n\n\n\nThe st_as_sf() function of the sf package is used to convert the listing data-frame into a simple feature data-frame.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe now examine the contents of the newly created data-frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nA new column ‘geometry’ has been added into the data-frame, while the latitude and longitude columns have been dropped.\n\n\n\n\nThe sf package offers a wide range of geoprocessing (also known as GIS analysis) functions in addition to the functions it provides to facilitate handling of geospatial data.\n\n\nScenario: The authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. We are tasked with determining the extent of the land that needs to be acquired and the total area.\nSolution:\nThe st_buffer() function of the sf package is used to ciompute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNow, we calculate the area of the buffers using the st_area() function.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nFinally, we use sum() to derive the total area of land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nQ.E.D\n\n\n\nScenario: A pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\nSolution:\nUsing the code chunk below, we are able to firstly identify the pre-schools located inside each Planning Subzone (using the st_intersects() function), after which we use the length() function to calculate the number of pre-schools that fall inside each Planning Subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe summary statistics are below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo obtain a list of the Planning Subzones with the most pre-schools, we use the top_n() function of the dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe density of pre-schools by Planning Subzone is now calculated using the st_area() function of the sf package and the mutate() function of the dplyr package.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nWe now conduct Exploratory Data Analysis to gain a better understanding of the data using relevant visualizations plotted using the ggplot2 package.\nFirst, we plot a histogram to reveal the distribution of PreSch Density using the hist() function of R Graphics.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the method is straightforward, the output is far from the required quality and has limited room for further customization. Using ggplot2, we create a higher quality histogram that fits our needs better.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"purple\") +\n  labs(title = \"Are pre-schools evenly distributed across Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nTo gain a better understanding of the relationship between pre-school density and pre-school count, we plot a scatterplot using ggplot2.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\",\n             na.rm=TRUE) +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started.",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of the pacman package to check if tidyverse has been installed. If it has been, it will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\n\n\n\n\n\nThe relevant data is now going to be imported using the st_read() function of package sf.\n\nmpsz=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFrom the output above, it can be inferred that there are 323 multipolygon features and 15 fields in mpsz, which is projected in the SVY21 coordinate system.\n\n\n\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe output above reveals that there are 3138 features and 2 fields in the cyclingpath linestring feature data frame, which is also projected in the SVY21 coordinate system.\n\n\n\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe output reveals that preschool is a point feature data-frame, with 2290 features and 2 fields. Unlike the two previous simple feature data-frames, preschoolis projected using the WGS84 coordinate system.\n\n\n\n\nWe now focus on the different methods of retrieving information related to the contents of a simple feature data-frame.\n\n\nThe column in the sf data.frame that contains the geometries is a list of class sfc. The geometry list–column can be retrieved using the mpsz$geom or mpsz[[1]], but st_geometry, shown below, is the most commonly used method.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\n\nUsing glimpse(), a function of the dplyr package, we can learn more about the data-frame beyond the basic feature information.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n\nThe function head(), an in-built R function, will reveal complete information about a feature object.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n\n\nIn Geopspatial Data Science, simply looking at the feature information is not enough. Visualizing the geospatial features is a key step to improve our understanding of the data. We can use plot(), an in-built function of R Graphic, to facilitate visualization.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nBy default, a multi-plot of all attributes is obtained, up to a reasonable maximum as shown above. We can also choose to plot only the geometry by implementing the code shown below.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose to plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz['PLN_AREA_N'])\n\n\n\n\n\n\n\n\nIt must be noted that plot() plots the geospatial data for a quick overview. For high cartographic quality, R packages such as tmap should be used.\n\n\n\nMap projection is an important property of geospatial data. When performing geoprocessing using two geospatial datasets, we need to ensure that they are both projected using similar coordinate systems.\n\n\nOne of the most common issues faced when importing Geospatial data into R is that the coordinate system of the source data was either missing (for example, due to missing .proj for ESRI Shapefile) or wrongly assigned during the importing process.\nBy using the st_crs() function of the sf package, we can view the Coordinate Reference System of mpsz.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough the mpsz data-frame is projected in SVY21, it indicates that the EPSG is 9001. This is the wrong EPSG- the correct EPSG code for SVY21 should be 3414.\nTo correct the EPSG code, we use st_set_crs() of the sf package as shown below.\n\nmpsz3414&lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe now check the CSR again using the st_crs() function from earlier,\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nWhen analyzing geospatial data, its common to have to transform the original data from geographic coordinate system to project coordinate system because the geographic coordinate system is not appropriate if the analysis needs to use distance and/or area measurements.\nEarlier, we learnt that the preschool simple feature data-frame was in WGS84 format. In this scenario, using st_set_crs() is not appropriate because we need to re-project preschool from one coordinate system to another coordinate system mathematically.\nWe use the st_transform() function for this.\n\npreschool3414&lt;- st_transform(preschool, crs=3414)\n\nWe now check for the contents of the newly transformed data-frame using the st_geometry() function from earlier.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)\n\n\nIt is now the appropriate projected coordinate system now- SVY21. Additionally, if you refer to the Bounding Box data above, the values are greater than the 0-360 range of decimal degrees commonly used by most geographic coordinate systems.\n\n\n\n\nIt is not unusual to come across data such as the listingdata set obtained from AirBnb. Such data is called Aspatial data. This is because it has separate data fields containing the x and y coordinates of the data points, unlike Geospatial data.\n\n\nSince the listing data set is in csv format, we use the read_csv() function of the readr package to import it.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe will now examine if the data file has been imported correctly for analysis.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe above output informs us that there are 18 columns and 3540 rows of data. Two important columns that will be used in the next phase of the analysis are the latitude and longitude columns. These columns are in decimal degree format. As a best guess, it is assumed that the data is projected in the WGS84 Geographic Coordinate System.\n\n\n\nThe st_as_sf() function of the sf package is used to convert the listing data-frame into a simple feature data-frame.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nWe now examine the contents of the newly created data-frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nA new column ‘geometry’ has been added into the data-frame, while the latitude and longitude columns have been dropped.\n\n\n\n\nThe sf package offers a wide range of geoprocessing (also known as GIS analysis) functions in addition to the functions it provides to facilitate handling of geospatial data.\n\n\nScenario: The authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. We are tasked with determining the extent of the land that needs to be acquired and the total area.\nSolution:\nThe st_buffer() function of the sf package is used to ciompute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nNow, we calculate the area of the buffers using the st_area() function.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nFinally, we use sum() to derive the total area of land required.\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nQ.E.D\n\n\n\nScenario: A pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\nSolution:\nUsing the code chunk below, we are able to firstly identify the pre-schools located inside each Planning Subzone (using the st_intersects() function), after which we use the length() function to calculate the number of pre-schools that fall inside each Planning Subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nThe summary statistics are below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo obtain a list of the Planning Subzones with the most pre-schools, we use the top_n() function of the dplyr package.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nThe density of pre-schools by Planning Subzone is now calculated using the st_area() function of the sf package and the mutate() function of the dplyr package.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n\n\n\n\nWe now conduct Exploratory Data Analysis to gain a better understanding of the data using relevant visualizations plotted using the ggplot2 package.\nFirst, we plot a histogram to reveal the distribution of PreSch Density using the hist() function of R Graphics.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the method is straightforward, the output is far from the required quality and has limited room for further customization. Using ggplot2, we create a higher quality histogram that fits our needs better.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"purple\") +\n  labs(title = \"Are pre-schools evenly distributed across Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nTo gain a better understanding of the relationship between pre-school density and pre-school count, we plot a scatterplot using ggplot2.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\",\n             na.rm=TRUE) +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices. On the other hands, Geovisualization works by providing graphical ideations to render a place, a phenomenon or a process visible, enabling a humans most powerful information-processing abilities- those of spatial cognition associated with our eye-brain vision system, to be directly brought to bear.\n\n\nTo fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nAs discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "To fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "As discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Choropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Welcome to the first part of Hands-On Exercise 2 where we explore 1st Order Spatial Point Pattern Analysis Methods.\n\n\nThe data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#data-and-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#data-and-libraries",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "The data being used are as follows:\n\nCHILDCARE, a point feature data providing both location and attribute information of childcare centres. It was downloaded from Data.gov.sg and is in geojson format.\nMP14_SUBZONE_WEB_PL, a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg.\nCostalOutline, a polygon feature data showing the national boundary of Singapore. It is provided by SLA and is in ESRI shapefile format.\n\nFor this exercise, we will use the following R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nraster, which reads, writes, manipulates, analyses and model of gridded spatial data (i.e. raster). In this hands-on exercise, it will be used to convert image output generate by spatstat into raster format.\ntidyverse simplifies spatial analysis by offering a consistent and efficient framework that facilitates working with spatial data.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\n\nWe will load in the packages above by implementing the code chunk below.\n\n\nClick to show/hide code\n\n\npacman::p_load(sf, spatstat, raster, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-the-spatial-data",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.2.1 Importing the Spatial Data",
    "text": "2.2.1 Importing the Spatial Data\nWe will now import the GEOJSON using the st_read() function of the sf package.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe notice that its projected in the WGS84 system so we transformed the EPSG code to 3414, to be consistent with the SVY21 projected coordinate system of Singapore.\nWe will now import the coastal outline data using the st_read() function again.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nThis is projected correctly in the SVY21 system, however we will verify the EPSG code using the st_crs() function of the sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe notice that the EPSG code isn’t correct, so we transform it to the correct value of 3414 using the st_transform() function.\n\nst_transform(sg_sf, 3414)\n\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   GDO_GID MSLINK MAPID              COSTAL_NAM                       geometry\n1        1      1     0                 Linkway POLYGON ((14362.86 32307.49...\n2        2      3     0                 SENTOSA POLYGON ((25683.97 26236.91...\n3        3      5     0          PULAU SARIMBUN POLYGON ((11471.97 46273.01...\n4        4      6     0           PULAU SAMULUN POLYGON ((12602.3 32061.35,...\n5        5      7     0 SINGAPORE - MAIN ISLAND POLYGON ((17915.53 46770.73...\n6        6      8     0            PULAU KEPPEL POLYGON ((25606.84 27481.21...\n7        7      9     0             PULAU BRANI POLYGON ((27778.17 27321.28...\n8        8     10     0                   ISLET POLYGON ((25874.11 26121.48...\n9        9     11     0           PULAU PALAWAN POLYGON ((25937.33 25797.66...\n10      10     12     0                   ISLET POLYGON ((27459.33 24854.08...\n\n\nNow, we import the Master Planning Subzone data using the st_read() function\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                   layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe must now verify the EPSG code for mpsz_sf before proceeding to facilitate analysis.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nSince it has the wrong EPSG code, we will transform it to the correct value of 3414.\n\nst_transform(mpsz_sf, 3414)\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNow, we can proceed with the analysis as all the data-frames are projected consistently."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#mapping-the-geospatial-data",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.2.2 Mapping the Geospatial Data",
    "text": "2.2.2 Mapping the Geospatial Data\nWe prepare a pin map using functions from the tmap package.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are several benefits to using a pin map in this situation. Firstly, since it is an interactive map we can move around the map freely and look at specific areas that we’re interested in. Second, we can query the information for each simple feature by simply clicking them. Additionally, you can also change the background of the internet map layer- currently, three internet map layers are provided (ESRI.WorldGrayCanvas [default], ESRI.WorldTopoMap, and OpenStreetMap.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-simple-feature-data-frames-to-sps-spatial-class",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.1 Converting simple feature data-frames to sp’s Spatial Class",
    "text": "2.3.1 Converting simple feature data-frames to sp’s Spatial Class\nWe can convert geospatial data from a simple feature data-frame to sp’s Spatial class using the as_Spatial() function of the sf package. The code chunk below showcases how it will be done.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nNow, we want to have a look at each of these data-frames. We do it using the glimpse() function.\n\nChildcareMPSZsg\n\n\n\nglimpse(childcare)\n\nFormal class 'SpatialPointsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 1545 obs. of  2 variables:\n  .. ..$ Name       : chr [1:1545] \"kml_1\" \"kml_2\" \"kml_3\" \"kml_4\" ...\n  .. ..$ Description: chr [1:1545] \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ \"&lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\\\"#E3E3F3\\\"&gt; &lt;th&gt;ADD\"| __truncated__ ...\n  ..@ coords.nrs : num(0) \n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Points Data-Frame.\n\n\n\nglimpse(mpsz)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 323 obs. of  15 variables:\n  .. ..$ OBJECTID  : int [1:323] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ SUBZONE_NO: int [1:323] 1 1 3 8 3 7 9 2 13 7 ...\n  .. ..$ SUBZONE_N : chr [1:323] \"MARINA SOUTH\" \"PEARL'S HILL\" \"BOAT QUAY\" \"HENDERSON HILL\" ...\n  .. ..$ SUBZONE_C : chr [1:323] \"MSSZ01\" \"OTSZ01\" \"SRSZ03\" \"BMSZ08\" ...\n  .. ..$ CA_IND    : chr [1:323] \"Y\" \"Y\" \"Y\" \"N\" ...\n  .. ..$ PLN_AREA_N: chr [1:323] \"MARINA SOUTH\" \"OUTRAM\" \"SINGAPORE RIVER\" \"BUKIT MERAH\" ...\n  .. ..$ PLN_AREA_C: chr [1:323] \"MS\" \"OT\" \"SR\" \"BM\" ...\n  .. ..$ REGION_N  : chr [1:323] \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" \"CENTRAL REGION\" ...\n  .. ..$ REGION_C  : chr [1:323] \"CR\" \"CR\" \"CR\" \"CR\" ...\n  .. ..$ INC_CRC   : chr [1:323] \"5ED7EB253F99252E\" \"8C7149B9EB32EEFC\" \"C35FEFF02B13E0E5\" \"3775D82C5DDBEFBD\" ...\n  .. ..$ FMEL_UPD_D: Date[1:323], format: \"2014-12-05\" \"2014-12-05\" ...\n  .. ..$ X_ADDR    : num [1:323] 31596 28679 29655 26783 26202 ...\n  .. ..$ Y_ADDR    : num [1:323] 29220 29782 29975 29934 30006 ...\n  .. ..$ SHAPE_Leng: num [1:323] 5267 3506 1741 3314 2826 ...\n  .. ..$ SHAPE_Area: num [1:323] 1630379 559816 160807 595429 387429 ...\n  ..@ polygons   :List of 323\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. .. [list output truncated]\n  ..@ plotOrder  : int [1:323] 285 302 313 16 269 75 297 276 213 56 ...\n  ..@ bbox       : num [1:2, 1:2] 2668 15749 56396 50256\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame.\n\n\n\nglimpse(sg)\n\nFormal class 'SpatialPolygonsDataFrame' [package \"sp\"] with 5 slots\n  ..@ data       :'data.frame': 60 obs. of  4 variables:\n  .. ..$ GDO_GID   : num [1:60] 1 2 3 4 5 6 7 8 9 10 ...\n  .. ..$ MSLINK    : num [1:60] 1 3 5 6 7 8 9 10 11 12 ...\n  .. ..$ MAPID     : num [1:60] 0 0 0 0 0 0 0 0 0 0 ...\n  .. ..$ COSTAL_NAM: chr [1:60] \"Linkway\" \"SENTOSA\" \"PULAU SARIMBUN\" \"PULAU SAMULUN\" ...\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe verify that is now in the form that we intended for it to be in- Spatial Polygons Data-Frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-spatial-class-into-generic-sp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-spatial-class-into-generic-sp-format.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.2 Converting Spatial Class into generic sp format.",
    "text": "2.3.2 Converting Spatial Class into generic sp format.\nIn order to use the spatstat package, the data must be in ppp object form. There is no direct way to convert Spatial Classes into ppp objects. So, we start by converting the Spatial Classes into Spatial Objects first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\n\nchildcare_spsg_sp\n\n\n\nglimpse(childcare_sp)\n\nFormal class 'SpatialPoints' [package \"sp\"] with 3 slots\n  ..@ coords     : num [1:1545, 1:3] 27977 25824 31399 29268 41218 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ bbox       : num [1:3, 1:2] 11203 25668 0 45404 49301 ...\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\nglimpse(sg_sp)\n\nFormal class 'SpatialPolygons' [package \"sp\"] with 4 slots\n  ..@ polygons   :List of 60\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  .. ..$ :Formal class 'Polygons' [package \"sp\"] with 5 slots\n  ..@ plotOrder  : int [1:60] 5 51 55 53 29 50 2 40 36 21 ...\n  ..@ bbox       : num [1:2, 1:2] 2664 16358 56048 50244\n  .. ..- attr(*, \"dimnames\")=List of 2\n  ..@ proj4string:Formal class 'CRS' [package \"sp\"] with 1 slot\n  ..$ comment: chr \"TRUE\"\n\n\nWe have successfully converted to an object as opposed to a class like above.\n\n\n\n\n\nshow/hide code\n\n\n.insights-box {\n  background-color: #f0f9f5;\n  border-left: 5px solid #28a745;\n  padding: 15px;\n  border-radius: 5px;\n  margin: 20px 0;\n  font-size: 1rem;\n  display: flex;\n  align-items: flex-start;\n}\n\n.insights-box::before {\n  content: \"\\1F4A1\"; /* Light bulb emoji */\n  font-size: 1.5rem;\n  margin-right: 10px;\n  color: #28a745;\n}\n\n\n\n\nGenerally, Spatial Classes are more structured and more suitable for complex and more rigorous Spatial Analytics. Generic ‘sp’ objects allow for simpler, more flexible, data manipulation where having a format Spatial Class is necessary."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-generic-sp-format-into-spatstats-ppp-format.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.3 Converting the generic sp format into Spatstat’s ppp format.",
    "text": "2.3.3 Converting the generic sp format into Spatstat’s ppp format.\nTo convert the spatial data into the required ppp form, we implement the as.ppp() function of the spatstat package. ::: panel-tabset ## Conversion to ppp object\n\nchildcare_ppp=as.ppp(childcare_sf)\n(childcare_ppp)\n\nMarked planar point pattern: 1545 points\nmarks are of storage type  'character'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#summary-of-newly-obtained-ppp-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#summary-of-newly-obtained-ppp-object",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Summary of newly obtained ppp object",
    "text": "Summary of newly obtained ppp object\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\n:::\nWe will now plot the newly obtained ppp object to visualize the differences to previous data-frames.\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#handling-duplicated-points",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.3.4 Handling duplicated points",
    "text": "2.3.4 Handling duplicated points\nWe check childcare_ppp for any duplicates in order to handle duplicates if they are present.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nWe now check for the points of co-incidence using the multiplicity() function.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe further verify if there are any duplicates by checking to see if there are any points occurring more than once in the object using the code chunk below.\n\nsum(multiplicity(childcare_ppp)&gt;1)\n\n[1] 0\n\n\nIt appears that there is indeed 0 duplicated point events.\n\nIn the case that there are duplicates, they can be handled as follows. We use jittering (shown in the code chunk below), which adds a small perturbation to the duplicate points so that they do not occupy the exact same space. Additionally, we could also make each point unique and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need to implement analytical techniques that take these marks into account.\n\n#childcare_ppp_jit &lt;- rjitter(childcare_ppp, \n #                            retry=TRUE, \n  #                           nsim=1, \n   #                          drop=TRUE)\n\n\n\nAnd then we can check for any duplicates to ensure that the above function worked using the following code chunk, the same as earlier.\n\n# any(duplicated(childcare_ppp_jit))\n\n\n\n2.3.5 Creating an owin object\nWhen analyzing Spatial Point patterns, it is a good practice to confine the boundaries of the analysis with a Geographical area, such as Singapore’s boundary. Using the spatstat package, we can create an owin object that is designed to represent such polygonal regions.\nWe use the as.owin() function from spatstat for this transformation.\n\nsg_owin &lt;- as.owin(sg_sf)\n\n\nplot of the newly obtained sg_owin objectSummary of the object\n\n\nWe can plot the newly obtained object using the code chunk below.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nFrom the summary, we see that the object itself is a polygonal boundary with a window area of 725376000 square units."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-kde",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.4.1 Kernel Density Estimation (KDE)",
    "text": "2.4.1 Kernel Density Estimation (KDE)\nKDE will allow us to better estimate the distribution of childcare services acrosss Singapore. Using this, we can make more informed decisions on where to focus resources on to improve the accessibility to these services across the nation.\n\n2.4.1.1 Computing KDE using automatic bandwidth selection.\nWe use the density() function of the spatstat package to compute the kernel density. These are the key configurations used in the computation:\n\nbw.diggle() automatic bandwidth selection method.\nThe smoothing kernel used in this instance is gaussian. Other smoothing methods include “epanechnikov”, “quartic”. or “disc”.\n\n\nkde_childcareSG_bw &lt;- density(childcare_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nThe other two methods aside from bw.diggle() are bw.scott() and bw.ppl(). While bw.diggle() focuses on minimizing error in spatial density estimation for point process data and is tailor-made for spatial applications, bw.scott() (Scott’s rule) provides a rule-of-thumb bandwidth and is used in several KDE applications across different types of data besides just spatial data. bw.ppl() uses a more complex and data-driven approach (plug-in) for selecting the bandwidth, aiming to minimize the error in KDE. Like bw.diggle(), It is also tailor-made for spatial point processes, however, it takes a slightly different approach to bw.diggle()\n\nWe now use the plot() function to display the above kernel density estimate.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nImmediately we notice that the density values are very small. This is because when the data is projected in the SVY21 coordinate system, the unit of measurement is in meter, meaning that the density values are computed with a unit of ‘number of points per square meter.’\nWe can also determine the bandwidth that was used to compute the above KDE layer by implementing the code chunk below.\n\nbw &lt;- bw.diggle(childcare_ppp)\nbw\n\n   sigma \n294.8378 \n\n\n\n\n2.4.1.2 Re-scaling KDE values\nWe now use the rescale.ppp() function of the spatstat package to convert the unit of measurement from meter to kilometer. This is done by implementing the code chunk below.\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcare_ppp, 1000, \"km\")\n\nAfter this, we re-deploy the density() function using the re-scaled data and plot the KDE map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nNow, while the image itself looks similar distribution wise, notice that the units of measurement have changed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-bandwidth-selection-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#working-with-different-automatic-bandwidth-selection-methods",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.4.2 Working with different automatic bandwidth selection methods",
    "text": "2.4.2 Working with different automatic bandwidth selection methods\n\n2.4.2.1 Comparing the impact of using different smoothing kernels\nBelow, we use the bw.ppl() bandwidth selection method on all 4 types of smoothing kernels to visualize the difference between them.\n\n# Set up a 2x2 plotting area\npar(mfrow=c(2,2))\n\n# KDE with Gaussian kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian (bw.ppl)\")\n\n# KDE with Epanechnikov kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov (bw.ppl)\")\n\n# KDE with Quartic kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic (bw.ppl)\")\n\n# KDE with Disc kernel\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc (bw.ppl)\")\n\n\n\n\n\n\n\n\nThere is no real difference in the 4 plots when using the same bandwidth selection method regardless of the smoothing kernel selected.\n\n\n2.4.2.2 The impact of using different smoothing kernels and bandwidth selection methods.\n\nEpanechnikov smoothing kernel and bw.scott() bandwidth selectionQuartic smoothing kernel and bw.ppl() bandwidth selectionDisc smoothing kernel and bw.CvL() bandwidth selection\n\n\n\nbw_scott &lt;- bw.scott(childcareSG_ppp.km)\n\nkde_childcareSG_bw_scott &lt;- density(childcareSG_ppp.km,\n                                    sigma=bw_scott,\n                                    edge=TRUE,\n                                    kernel=\"epanechnikov\")\n\nplot(kde_childcareSG_bw_scott, main=\"KDE of Childcare Services in Singapore using bw.scott\")\n\n\n\n\n\n\n\n\nWe notice that the plot is of a different kind entirely however the distribution does look pretty similar.\nWe check the bandwidth selected using the code chunk below.\n\nbw2=bw.scott(childcareSG_ppp.km)\nbw2\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\nImmediately you see a difference in the bandwidth- there are two values (x and y) rather than just the one when using bw.diggle()\n\n\n\nbw_ppl &lt;- bw.ppl(childcareSG_ppp.km)\n\nkde_childcareSG_bw_ppl_qua &lt;- density(childcareSG_ppp.km,\n                                      sigma=bw_ppl,\n                                      edge=TRUE,\n                                      kernel=\"quartic\")\n\nplot(kde_childcareSG_bw_ppl_qua, main=\"KDE of Childcare Services in Singapore using bw.ppl and Quartic Kernel\")\n\n\n\n\n\n\n\n\nAgain, we see a different kind of plot, however the distribution seems consistent in all plots.\nWe now check the bandwidth using the code chunk below.\n\nbw3=bw.ppl(childcareSG_ppp.km)\nbw3\n\n    sigma \n0.3283284 \n\n\nAgain, we see a different bandwidth value to the previous two methods, however only one coordinate as opposed to the two when using the bw.scott() technique.\n\n\n\nbw_cvl &lt;- bw.CvL(childcareSG_ppp.km)\n\nkde_childcareSG_cvl &lt;- density(childcareSG_ppp.km,\n                               sigma=bw_cvl,\n                               edge=TRUE,\n                               kernel=\"disc\")\n\nplot(kde_childcareSG_cvl, main = \"KDE of Childcare Services using bw.cvl and Gaussian Kernel\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.2 Computing KDE by using adaptive bandwidth",
    "text": "2.5.2 Computing KDE by using adaptive bandwidth\nA fixed bandwidth approach is highly sensitive to spatial point distributions that are highly skewed over geographical units (e.g: urban vs rural). To alleviate this issue, adopting an adaptive bandwidth approach is suitable.\nWe use the density.adaptive() function of spatstat for this.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the two methods using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\nWe see a clear difference between the two plots, indicating that the fixed bandwidth approach may have heavily influenced by skewness of the distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-kde-output-into-a-grid-object.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#converting-the-kde-output-into-a-grid-object.",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.3 Converting the KDE output into a grid object.",
    "text": "2.5.3 Converting the KDE output into a grid object.\n\n2.5.3.1 Converting gridded output into raster.\nWe convert the gridded kernel density objects into RasterLayer object by using raster() of the raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\n\nWe now examine the properties of the above object.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.2671971, 0.184635  (x, y)\nextent     : 11.20301, 45.40424, 25.6676, 49.30088  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -3.65694e-15, 28.48563  (min, max)\n\n\nThe CRS above is NA, so we now set the CRS to EPSG 3414 of Singapore.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nplot(kde_childcareSG_bw_raster)\n\n\n\n\n\n\n\n\n\nYou could also use the tmap package to draw a map for the above. This allows for more customization to suit your needs.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE, \n            legend.text.color = \"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2.5.4 Comparing Spatial Point Patterns using KDE",
    "text": "2.5.4 Comparing Spatial Point Patterns using KDE\nUsing the methods below we can compare the KDE of childcare in selected locations such as Punggol, Jurong West, Bukit Batok and Yishun.\n\n2.5.4.1 Extracting the Study Area\nUsing the code chunk below, we filter out all data aside from our target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\nys &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"YISHUN\")\nbbk &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"BUKIT BATOK\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nAfter this, we can plot these target planning areas using the code chunk below.\n\nPunggolYishunBukit BatokJurong West\n\n\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\n\n\n\n\n\n\nplot(ys, main = \"Yishun\")\n\n\n\n\n\n\n\n\n\n\n\nplot(bbk, main = \"Bukit Batok\")\n\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\nWe see a difference in the distribution in all 4 of these regions.\n\n\n2.5.4.2 Creating owin objects\nWe now proceed to convert these simple feature objects into the owin objects that are required in order to use spatstat.\n\npg_owin = as.owin(pg)\nys_owin = as.owin(ys)\nbbk_owin = as.owin(bbk)\njw_owin = as.owin(jw)\n\n\n\n2.5.4.3 Combining childcare points and the study area.\nWe implement the code chunk below in order to extract any childcare centers that are within the specific regions in order to carry out our analysis later.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                          retry=TRUE, \n                           nsim=1, \n                            drop=TRUE)\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_ys_ppp = childcare_ppp_jit[ys_owin]\nchildcare_bbk_ppp = childcare_ppp_jit[bbk_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nFollowing this, we apply the rescale.ppp() function to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_ys_ppp.km = rescale.ppp(childcare_ys_ppp, 1000, \"km\")\nchildcare_bbk_ppp.km = rescale.ppp(childcare_bbk_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nNow, we can plot the four study areas and visualize the distribution of childcare centers across the four target areas.\n\npar(mfrow=c(2,2)) \n\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_ys_ppp.km, main=\"Yishun\")\nplot(childcare_bbk_ppp.km, main=\"Bukit Batok\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n2.5.4.4 Computing the KDE\nWe now implement the bw.diggle() method to compute the respective KDEs of the four target planning areas.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_ys_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Yishun\")\nplot(density(childcare_bbk_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bukit Batok\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n2.5.4.5 Computing Fixed Bandwidth KDEs\nIn the interest of determining the best method to use, we also adopt a fixed bandwidth approach for comparison to the bw.diggle() method above.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_ys_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Yishun\")\nplot(density(childcare_bbk_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Bukit Batok\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPAA) is a specialized suite of methods designed for analyzing spatial point events that occur on or near networks. These events could include locations such as traffic accidents or childcare centers, while the networks themselves might be road or river networks.\nIn this exercise, we will use the spNetwork package to perform Network Kernel Density Estimation (NKDE). Additionally, we will also conduct network G-function and K-function analyses."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "Welcome to In Class Exercise 1. The following documents our in class learnings to improve our understanding of hands on exercise 1 and beyond.\n\n\nWe start off by loading the packages required to carry out our analysis. For this analysis, we will use the sf, tidyverse, ggstatsplot and tmap packages to carry out our analysis.\nThis is done using the code chunk below.\n\npacman::p_load(sf, tmap, tidyverse, ggstatsplot)\n\n\n\n\nNow, we will import the data used for this analysis. We use the st_read() function of the sf package for our case.\n\nmpsz14_shp=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe see that it is a simple feature data-frame with 323 features and 15 fields, projected using the SVY21 coordinate system.\nWe attempted to import the main KML file, but it was corrupted.\nWe then implemented the code chunk below to create the correct KML file for the same. This is a standard procedure that must be followed when dealing with corrupted files in geospatial analysis.\n\nst_write(mpsz14_shp, \n         \"data/geospatial/MP14_SUBZONE_PL.kml\", \n         delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14_SUBZONE_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_PL' to data source \n  `data/geospatial/MP14_SUBZONE_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\n\nWe now import the preschools data. The KML file will be imported using the st_read() function of the sf package.\n\npreschool=st_read(\"data/geospatial/PreSchoolsLocation.kml\")%&gt;%\n  st_transform(crs=3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNotice that we change the EPSG code above to be consistent with the SVY21 projected coordinate system of Singapore.\n\n\n\nWe work with an updated version of the data released in 2019 for this. We import the shapefile as well as the KML files using the code chunks below.\n\nmpsz19_shp=st_read(dsn = \"data\", \n                     layer = \"MPSZ-2019\" ) %&gt;%\n  st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nNotice that we transformed the EPSG code has been transformed to 3414. This allows our data to be consistent with Singapore’s projected coordinate system, SVY21.\n\nmpsz19_kml=st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe see a difference in the the number of fields. The shapefile has 6 fields while the KML file has 2 fields. Both files have 332 features and are projected in the WGS84 coordinate system.\nBoth mpsz19_shp and mpsz19_kml are simple feature data-frames.\n1.2.1.1 Glimpse of the data frame.\n\n\nWe will use the st_crs() function to check the coordinate systems and verify the EPSG code.\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nBased on the above, we verify that the correct EPSG code for SVY21 projected data, 3414, is in place.\n\n\n\n\nNow, we determine the number of pre-schools in each planning subzone using the code chunk below. The mutate() function of the dplyr package and st_intersects() function of the sf package are used.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\nAfter doing this, we can proceed to find the density of pre-schools based on Planning Subzones.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )\n\n\n\nNow, we want to verify the relationship between the Pre-School count and Pre-School Density. We use the ggplot() function of the ggplot2 package to create a plot for the same.\n\nggplot(mpsz19_shp, aes(x = `PreSch Density`, y = `PreSch Count`)) +\n    geom_point() +  # Scatter plot\n    geom_smooth(method = \"lm\", se = FALSE) +  \n    theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFrom the above, we can infer that there is indeed a positive relationship between the two variables, Pre-School count and Pre-School Density.\n\n\n\n\n\npopdata=read_csv(\"data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npopdata2023=popdata%&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(POP=sum(Pop))%&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from = AG, \n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[, 3:6]) + rowSums(.[, 14])) %&gt;%  # Aged 0-24, 10-24 + Aged 5-9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[, 7:13]) + rowSums(.[, 15])) %&gt;%  # Aged 25-59 + Aged 60-64\n  mutate(AGED = rowSums(.[, 16:21])) %&gt;%  # Aged 65 and above\n  mutate(TOTAL = rowSums(.[, 3:21])) %&gt;%  # Total population\n  mutate(DEPENDENCY = (YOUNG + AGED) / `ECONOMY ACTIVE`) %&gt;%  # Dependency ratio\n  select(PA, SZ, YOUNG, `ECONOMY ACTIVE`, AGED, TOTAL, DEPENDENCY)\n\nNow, we take a look at the updated popdata2023 data-frame.\n\nglimpse(popdata2023)\n\nRows: 332\nColumns: 7\n$ PA               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio…\n$ SZ               &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Cheng San\", \"Chong Boon\", …\n$ YOUNG            &lt;dbl&gt; 1240, 5150, 4620, 4320, 1840, 3810, 1870, 3750, 0, 10…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2830, 15600, 14120, 12400, 3670, 9600, 4320, 11090, 0…\n$ AGED             &lt;dbl&gt; 890, 6580, 7060, 5640, 1420, 4320, 1790, 5390, 0, 880…\n$ TOTAL            &lt;dbl&gt; 4960, 27330, 25800, 22360, 6930, 17730, 7980, 20230, …\n$ DEPENDENCY       &lt;dbl&gt; 0.7526502, 0.7519231, 0.8271955, 0.8032258, 0.8882834…\n\n\n\n\n\n\nWe implement the basic join functions to join popdata2023 to mpsz19_shp.\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\n\n\nAfter joining the two tables, we can draw a Choropleth map of Dependency ratio by Planning subzone to get a better understanding of how the region impacts the level of dependency and if there is a relationship between the two. the tm_shape() and tm_fill() functions of the tmap package are used for this.\n\ntm_shape(mpsz_pop2023)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nWe start off by preparing the data.\nNull values are dropped using the code chunk below.\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\n\nNow, we will define a function that will help us get the input data and field that will be used for drawing the Percentile Map.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nNow, we create a function that will compute and plot the percentile map.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Oranges\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\nAfter defining the function above, we can implement it to draw the Percentile Map based on Dependency by Planning Subzone.\n\npercentmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\n\n\n\nTo plot a box map, we define a new function that will create breakpoints to be used for the box map.\nThe arguments are as follows: v (vector with observations), mult (multiplier for IQR [default value is 1.5[).\nIt returns bb, a vector with 7 breakpoints to compute the quartiles and fences for the box map.\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\nFollowing this, we define a function that will help us extract a variable as a vector from a simple feature data-frame.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nNow, we can create the Box Map. We must define a function for this.\nThe arguments are as follows; vnam (variable name), df (simple features polygon layer), legtitle (legend title), mtitle (map title), mult (multiplier for IQR).\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Oranges\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\nThe box map can now be created by using the function defined above.\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\n\n\n\nWe can create an interactive box map to get a more in-depth understanding of the relationship between Dependency and Planning Subzones.\nThe code chunk below is implemented for the same.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#loading-the-required-packages",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#loading-the-required-packages",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "We start off by loading the packages required to carry out our analysis. For this analysis, we will use the sf, tidyverse, ggstatsplot and tmap packages to carry out our analysis.\nThis is done using the code chunk below.\n\npacman::p_load(sf, tmap, tidyverse, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#importing-the-data",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "Now, we will import the data used for this analysis. We use the st_read() function of the sf package for our case.\n\nmpsz14_shp=st_read(dsn = \"data/geospatial\",\n             layer=\"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe see that it is a simple feature data-frame with 323 features and 15 fields, projected using the SVY21 coordinate system.\nWe attempted to import the main KML file, but it was corrupted.\nWe then implemented the code chunk below to create the correct KML file for the same. This is a standard procedure that must be followed when dealing with corrupted files in geospatial analysis.\n\nst_write(mpsz14_shp, \n         \"data/geospatial/MP14_SUBZONE_PL.kml\", \n         delete_dsn = TRUE)\n\nDeleting source `data/geospatial/MP14_SUBZONE_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_PL' to data source \n  `data/geospatial/MP14_SUBZONE_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\n\n\nWe now import the preschools data. The KML file will be imported using the st_read() function of the sf package.\n\npreschool=st_read(\"data/geospatial/PreSchoolsLocation.kml\")%&gt;%\n  st_transform(crs=3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNotice that we change the EPSG code above to be consistent with the SVY21 projected coordinate system of Singapore.\n\n\n\nWe work with an updated version of the data released in 2019 for this. We import the shapefile as well as the KML files using the code chunks below.\n\nmpsz19_shp=st_read(dsn = \"data\", \n                     layer = \"MPSZ-2019\" ) %&gt;%\n  st_transform(crs=3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nNotice that we transformed the EPSG code has been transformed to 3414. This allows our data to be consistent with Singapore’s projected coordinate system, SVY21.\n\nmpsz19_kml=st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex1\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe see a difference in the the number of fields. The shapefile has 6 fields while the KML file has 2 fields. Both files have 332 features and are projected in the WGS84 coordinate system.\nBoth mpsz19_shp and mpsz19_kml are simple feature data-frames.\n1.2.1.1 Glimpse of the data frame.\n\n\nWe will use the st_crs() function to check the coordinate systems and verify the EPSG code.\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nBased on the above, we verify that the correct EPSG code for SVY21 projected data, 3414, is in place.\n\n\n\n\nNow, we determine the number of pre-schools in each planning subzone using the code chunk below. The mutate() function of the dplyr package and st_intersects() function of the sf package are used.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\nAfter doing this, we can proceed to find the density of pre-schools based on Planning Subzones.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )\n\n\n\nNow, we want to verify the relationship between the Pre-School count and Pre-School Density. We use the ggplot() function of the ggplot2 package to create a plot for the same.\n\nggplot(mpsz19_shp, aes(x = `PreSch Density`, y = `PreSch Count`)) +\n    geom_point() +  # Scatter plot\n    geom_smooth(method = \"lm\", se = FALSE) +  \n    theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFrom the above, we can infer that there is indeed a positive relationship between the two variables, Pre-School count and Pre-School Density.\n\n\n\n\n\npopdata=read_csv(\"data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npopdata2023=popdata%&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(POP=sum(Pop))%&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from = AG, \n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG = rowSums(.[, 3:6]) + rowSums(.[, 14])) %&gt;%  # Aged 0-24, 10-24 + Aged 5-9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[, 7:13]) + rowSums(.[, 15])) %&gt;%  # Aged 25-59 + Aged 60-64\n  mutate(AGED = rowSums(.[, 16:21])) %&gt;%  # Aged 65 and above\n  mutate(TOTAL = rowSums(.[, 3:21])) %&gt;%  # Total population\n  mutate(DEPENDENCY = (YOUNG + AGED) / `ECONOMY ACTIVE`) %&gt;%  # Dependency ratio\n  select(PA, SZ, YOUNG, `ECONOMY ACTIVE`, AGED, TOTAL, DEPENDENCY)\n\nNow, we take a look at the updated popdata2023 data-frame.\n\nglimpse(popdata2023)\n\nRows: 332\nColumns: 7\n$ PA               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio…\n$ SZ               &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Cheng San\", \"Chong Boon\", …\n$ YOUNG            &lt;dbl&gt; 1240, 5150, 4620, 4320, 1840, 3810, 1870, 3750, 0, 10…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2830, 15600, 14120, 12400, 3670, 9600, 4320, 11090, 0…\n$ AGED             &lt;dbl&gt; 890, 6580, 7060, 5640, 1420, 4320, 1790, 5390, 0, 880…\n$ TOTAL            &lt;dbl&gt; 4960, 27330, 25800, 22360, 6930, 17730, 7980, 20230, …\n$ DEPENDENCY       &lt;dbl&gt; 0.7526502, 0.7519231, 0.8271955, 0.8032258, 0.8882834…"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#joining-population-data-to-mpsz-2019-data",
    "href": "In-class_Ex/In-class_Ex1/In-class_Ex1.html#joining-population-data-to-mpsz-2019-data",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "We implement the basic join functions to join popdata2023 to mpsz19_shp.\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\n\n\nAfter joining the two tables, we can draw a Choropleth map of Dependency ratio by Planning subzone to get a better understanding of how the region impacts the level of dependency and if there is a relationship between the two. the tm_shape() and tm_fill() functions of the tmap package are used for this.\n\ntm_shape(mpsz_pop2023)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nWe start off by preparing the data.\nNull values are dropped using the code chunk below.\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\n\nNow, we will define a function that will help us get the input data and field that will be used for drawing the Percentile Map.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nNow, we create a function that will compute and plot the percentile map.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Oranges\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\nAfter defining the function above, we can implement it to draw the Percentile Map based on Dependency by Planning Subzone.\n\npercentmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\n\n\n\nTo plot a box map, we define a new function that will create breakpoints to be used for the box map.\nThe arguments are as follows: v (vector with observations), mult (multiplier for IQR [default value is 1.5[).\nIt returns bb, a vector with 7 breakpoints to compute the quartiles and fences for the box map.\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\nFollowing this, we define a function that will help us extract a variable as a vector from a simple feature data-frame.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nNow, we can create the Box Map. We must define a function for this.\nThe arguments are as follows; vnam (variable name), df (simple features polygon layer), legtitle (legend title), mtitle (map title), mult (multiplier for IQR).\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Oranges\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\nThe box map can now be created by using the function defined above.\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\n\n\n\nWe can create an interactive box map to get a more in-depth understanding of the relationship between Dependency and Planning Subzones.\nThe code chunk below is implemented for the same.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "Introduction\nWelcome to my journey through ISSS626 Geospatial Analytics. This website contains my coursework that were completed through this course.\n\n\n\nAbout\nMy name is Arjun Singh and I am a student at Singapore Management University pursuing a Masters degree in Analytics. This website documents my journey of learning Geospatial Analytics under the guidance of Professor Tin Seong Kam.\nIf you have any inquiries, feel free to reach out to me at arjun.singh.2023@smu.edu.sg\n“It is a rough road that leads to the heights of greatness.”- Seneca"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#preparing-the-lixel-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#preparing-the-lixel-objects",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.1 Preparing the Lixel Objects",
    "text": "3.4.1 Preparing the Lixel Objects\nBefore we can proceed with computing NKDE, we must first cut the SpatialLines object into Lixels with a specified minimal distance.\n\nLixels (short for “line pixels”) are small, evenly spaced segments or units derived from a larger line or polyline. In geospatial analysis, lixelization refers to the process of breaking down a line into these smaller, discrete segments. Each lixel represents a portion of the original line, typically at a consistent length, allowing for more detailed spatial analysis\n\nThis can be done using the lixelize_lines() functions of the spNetwork package. In the code chunk below, we set the length of the lixel (lx_length) to 700, while the minimum length of the lixel (mindist) is set to 350.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\n\nThere is another function, lixelize_lines.mc() that provides multicore support and is typically used in spatial analysis or geospatial data processing, specifically in contexts where large datasets of lines (such as roads, paths, or boundaries) need to be broken down into smaller, equally spaced segments or “lixels” (line pixels). This process is known as “lixelization.”\nThe main purpose of the lixelize_lines.mc() function is to improve the efficiency of the lixelization process by utilizing multiple CPU cores simultaneously. This is particularly beneficial when dealing with large datasets, as processing each line sequentially can be time-consuming.\n\nAfter a cut, if the length of the final lixel is shorter than the specified minimum distance, then it is added to the previous lixel. If it is null, then mindist=maxdist/10.\nNote that the segments that are shorter than the minimum distance are not modified."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#generating-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#generating-line-centre-points",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.2 Generating Line Centre Points",
    "text": "3.4.2 Generating Line Centre Points\nWe will now generate a SpatialPointsDataFrame with line centre points using the lines_center() function of spNetwork.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at the centre of the line based on the length of the line.\n\nThe function lines_center() from the spNetwork package in R is used to generate a SpatialPointsDataFrame where each point corresponds to the center of a line segment (or lixel) based on its length."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#performing-nkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#performing-nkde",
    "title": "Hands On Exercise 3- Network Constrained Spatial Point Patterns Analysis",
    "section": "3.4.3 Performing NKDE",
    "text": "3.4.3 Performing NKDE\nNow, we come to the main topic of this exercise- performing Network Kernel Density Estimation.\nWe use the nkde() function to carry it out. The code chunk below shows the implementation.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  method = \"simple\")\n\n[1] \"checking inputs ...\"\n[1] \"prior data preparation ...\"\n[1] \"Splitting the data with the spatial grid ...\"\n[1] \"start calculating the kernel values ...\"\n[1] \"    quadra 1/1\"\n[1] \"    build graph ...\"\n[1] \"        calculating NKDE values ...\"\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================| 100%[1] \"combining the results ...\"\n\n\n\n\nThe kernel_name argument specifies the type of kernel function used.\nPossible kernel methods supported by spNetwork include:\n\nQuartic\nTriangle\nGaussian\nScaled Gaussian\nTricube\nCosine\nTriweight\nEpanechnikov\nUniform\n\nThe method argument indicates the method used to calculate Network Kernel Density Estimation (NKDE).\nspNetwork supports three popular methods:\n\nSimple (method = \"simple\"):\n\nIntroduced by Xie et al. (2008).\nDistances between events and sampling points are replaced by network distances.\nThe kernel formula is adapted to calculate density over a linear unit instead of an areal unit.\n\nDiscontinuous (method = \"discontinuous\"):\n\nProposed by Okabe et al. (2008).\nDivides the mass density of an event at intersections of lixels.\nResults in a discontinuous kernel function.\n\nContinuous (method = \"continuous\"):\n\nAlso proposed by Okabe et al. (2008).\nAdjusts the density before intersections to create a continuous kernel function.\nStill divides the mass of the density at intersections but with a continuous adjustment.\n\n\n\n\n\n3.4.3.1 Visualizing NKDE\nWe must first insert the computed density values (i.e: densities) into samples and lixels objects as the density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nWe now convert the scale from number of events per meter (as data is projected using the SVY21 coordinate system) to number of events per kilometer, as the computed density values are very small if the unit is event per meter.\n\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nWe can now plot the map as the data is now prepared.\nWe will use the tmap package to produce a highly cartographic and interactive map.\n\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\nThe interactive map above effectively reveals road segments with relatively higher density of childcare centres than road segments with relatively lower density of childcare centres with the help of shading. The roads with darker shades have a relatively higher density."
  }
]