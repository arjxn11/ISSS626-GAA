[
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html",
    "title": "In Class Exercise 5",
    "section": "",
    "text": "This exercise will help reinforce our learning from Hands on exercise 5. Additionally, we explore the sfdep package and its uses."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#performing-relational-join",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#performing-relational-join",
    "title": "In Class Exercise 5",
    "section": "5.3.1 Performing relational join",
    "text": "5.3.1 Performing relational join\nWe will update the attribute table of Hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data-frame. We can do this by using the left_join() function of the dplyr package.\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n5.3.1.2 Plotting a Choropleth map\n\ntmap_mode('plot')\ntm_shape(hunan_GDPPC)+\n  tm_fill('GDPPC', style='quantile', palette = 'Blues', title= 'GDPPC')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#deriving-queens-contiguity-weights-sfdep-methods",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#deriving-queens-contiguity-weights-sfdep-methods",
    "title": "In Class Exercise 5",
    "section": "5.4.1 Deriving Queens Contiguity Weights: sfdep methods",
    "text": "5.4.1 Deriving Queens Contiguity Weights: sfdep methods\n\nwm_q=hunan_GDPPC%&gt;%\n  mutate(nb=st_contiguity(geometry),\n         wt=st_weights(nb,\n                       style='W'),\n         .before=1)\n\n\nnb: A neighbor list object as created by st_neighbor.\nstyle: Default ‘W’ for row standardized weights. This value can also be ‘B’, ‘C’, ‘U’, ‘minimax’, and ‘S’\nallow_zero: if TRUE, assigns zero as a lagged value to zone without neighbors."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#computing-global-morans-i",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#computing-global-morans-i",
    "title": "In Class Exercise 5",
    "section": "5.4.2 Computing Global Moran’s I",
    "text": "5.4.2 Computing Global Moran’s I\nWe use the global_moran() function to compute this.\n\nmoranI= global_moran(wm_q$GDPPC,\n                     wm_q$nb,\n                     wm_q$wt)\n\nThe below code chunk, using global_moran_test() helps us conduct the test easier.\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nSince p-value is less than 0.05, we infer that there is indeed a sign of positive autocorrelation."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#global-morans-permutation-test",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#global-morans-permutation-test",
    "title": "In Class Exercise 5",
    "section": "5.4.3 Global Moran’s Permutation Test",
    "text": "5.4.3 Global Moran’s Permutation Test\nIn practice, we generally use Monte Carlo simulation to conduct tests. This is where the global_moran_perm() function comes into play. The nsim argument is key.\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#computing-local-morans-i",
    "title": "In Class Exercise 5",
    "section": "5.4.4 Computing Local Moran’s I",
    "text": "5.4.4 Computing Local Moran’s I\nIn this section, we use the local_moran() function of the sfdep package.\n\nlisa=wm_q%&gt;%\n  mutate(local_moran=local_moran(\n    GDPPC, nb, wt, nsim=99),\n    .before=1)%&gt;%\n  unnest(local_moran)\n\nunnest() helps us combine the data into the intended data-frame."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#visualizing-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#visualizing-p-value-of-local-morans-i",
    "title": "In Class Exercise 5",
    "section": "5.4.5 Visualizing p-value of local Moran’s I",
    "text": "5.4.5 Visualizing p-value of local Moran’s I\n\ntmap_mode('plot')\ntm_shape(lisa)+\n  tm_fill('p_ii_sim')+\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title = 'p-value of Local Morans I',\n            main.title.size = 2)\n\n\n\n\n\n\n\n\n\n5.4.5.1 Visualizing Local Moran’s I\n\ntm_shape(lisa)+\n  tm_fill('ii')+\n  tm_borders(alpha=0.5)+\n  tm_view(set.zoom.limits = c(6,8))+\n  tm_layout(main.title='Local Morans I of GDPPC',\n            main.title.size = 2)\n\n\n\n\n\n\n\n\n\n\n5.4.5.2 Visualizing both\n\nmap1= tm_shape(lisa)+\n  tm_fill('p_ii_sim')+\n  tm_borders(alpha=0.5)+\n  tm_layout(main.title = 'p-value of Local Morans I',\n            main.title.size = 2)\n\nmap2= tm_shape(lisa)+\n  tm_fill('ii')+\n  tm_borders(alpha=0.5)+\n  tm_view(set.zoom.limits = c(6,8))+\n  tm_layout(main.title='Local Morans I of GDPPC',\n            main.title.size = 2)\n\ntmap_arrange(map1,map2, ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#visualizing-lisa-map",
    "href": "In-class_Ex/In-class_Ex5/In-class_Ex5.html#visualizing-lisa-map",
    "title": "In Class Exercise 5",
    "section": "5.4.6 Visualizing LISA map",
    "text": "5.4.6 Visualizing LISA map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers- high-low and low-high outliers. Likewise, there are two types of clusters namely High-High and Low-Low.\nIn fact, LISA map is an interpreted map by combining local Moran’s I of geographical areas and their respective p values.\n\nlisa_sig=lisa%&gt;%\n  filter(p_ii&lt;0.05)\ntmap_mode('plot')\ntm_shape(lisa)+\n  tm_polygons()+\n  tm_borders(alpha=0.5)+\n  tm_shape(lisa_sig)+\n  tm_fill('mean')+\n  tm_borders(alpha=0.4)\n\n\n\n\n\n\n\n\nWe see two outliers in the cluster on the North-East region of Hunan which contains mostly high-high regions. rm -f .git/index.lock"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "Introduction\nWelcome to my journey through ISSS626 Geospatial Analytics. This website contains my coursework that were completed through this course.\n\n\n\nAbout\nMy name is Arjun Singh and I am a student at Singapore Management University pursuing a Masters degree in Analytics. This website documents my journey of learning Geospatial Analytics under the guidance of Professor Tin Seong Kam.\nIf you have any inquiries, feel free to reach out to me at arjun.singh.2023@smu.edu.sg\n“It is a rough road that leads to the heights of greatness.”- Seneca\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 1-Part 2\n\n\n\n\n\n\nArjun Singh\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 8- Geographically Weighted Predictive Models\n\n\n\n\n\n\nArjun Singh\n\n\nOct 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 7\n\n\n\n\n\n\nArjun Singh\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 7- Geographically Weighted Explanatory Models\n\n\n\n\n\n\nArjun Singh\n\n\nOct 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 6\n\n\n\n\n\n\nArjun Singh\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics\n\n\n\n\n\n\nArjun Singh\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n\n\n\n\nArjun Singh\n\n\nSep 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 5\n\n\n\n\n\n\nArjun Singh\n\n\nSep 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 4\n\n\n\n\n\n\nArjun Singh\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 3\n\n\n\n\n\n\nArjun Singh\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 5- Global Measures of Spatial Autocorrelation\n\n\n\n\n\n\nArjun Singh\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\nArjun Singh\n\n\nSep 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 4- Spatial Weights and Applications\n\n\n\n\n\n\nArjun Singh\n\n\nSep 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Exercise 2\n\n\n\n\n\n\nArjun Singh\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 3- Network Constrained Spatial Point Patterns Analysis\n\n\n\n\n\n\nArjun Singh\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Exercise 1\n\n\n\n\n\n\nArjun Singh\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 2- Part 2: 2nd order Spatial Point Patterns\n\n\n\n\n\n\nArjun Singh\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Exercise 2- 1st Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nArjun Singh\n\n\nAug 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Exercise 1\n\n\n\n\n\n\nArjun Singh\n\n\nAug 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1\n\n\n\n\n\n\nArjun Singh\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Exercise 1-Part 2\n\n\n\n\n\n\nArjun Singh\n\n\nAug 22, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "According to the World Health Organisation (WHO), road traffic accidents cause approximately 1.19 million deaths annually and result in between 20 and 50 million people with being down with non-fatal injuries. Over half of all road traffic deaths occur among vulnerable road users, such as pedestrians, cyclists and motorcyclists.\nRoad traffic injuries are the leading cause of death for children and young adults aged 5–29 while two-thirds of road traffic fatalities occur among people of working age (18–59 years). 9 in 10 fatalities on the roads occur in low and middle-income countries, even though these countries have only around 60% of the world’s vehicles.\nIn addition to the human suffering caused by road traffic injuries, they also inflict a heavy economic burden on victims and their families, both through treatment costs for the injured and through loss of productivity of those killed or disabled. More broadly, road traffic injuries have a serious impact on national economies, costing countries 3% of their annual GDP.\nThailand’s roads are the deadliest in Southeast Asia and among the worst in the world, according to the World Health Organisation. About 20,000 people die in road accidents each year, or about 56 deaths a day (WHO).\nBetween 2014 and 2021, Thailand experienced a notable increase in accidents. Specifically, 19% of all accidents in Thailand occurred on the national highways, which constituted the primary public thoroughfares connecting various regions, provinces, districts, and significant locations within a comprehensive network.\nWithin the broader context of accidents across the country, there existed a considerable 66% likelihood of encountering accident-prone zones, often termed ‘black spots,’ distributed as follows: 66% on straight road segments, 13% at curves, 6% at median points of cross-shaped intersections, 5% at T-shaped intersections and Y-shaped intersections, 3% at cross-shaped intersections, 2% on bridges, and 2% on steep slopes, respectively."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#aspatial-data",
    "title": "Take Home Exercise 1",
    "section": "1.2.1 Aspatial Data",
    "text": "1.2.1 Aspatial Data\nWe first import in the data-frame contained data of all accidents in the Bangkok Metropolitan Region. For this, we implement the read_rds() function as shown in the code chunk below.\n\nrdacc_sf=read_rds(\"data/rds/acc_sf\")%&gt;% \n  mutate(hourofday= hour(incident_datetime))%&gt;%\n  mutate(traffic_period = case_when(\n    # Define peak hours: 7-9 AM and 4-7 PM (16-19 in 24-hour format)\n    hourofday &gt;= 7 & hourofday &lt;= 9 ~ \"Peak\",\n    hourofday &gt;= 16 & hourofday &lt;= 19 ~ \"Peak\",\n    TRUE ~ \"Off-Peak\"  # Everything else is off-peak\n  ))\nst_crs(rdacc_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#geospatial-data",
    "title": "Take Home Exercise 1",
    "section": "1.2.2 Geospatial Data",
    "text": "1.2.2 Geospatial Data\nWe import the OpenStreetMap export of Thailand into our environment using the st_read() function.\n\nroad_sf &lt;- st_read(dsn = \"data/rawdata\", layer=\"hotosm_tha_roads_lines_shp\")\n\n\nIt is important to note the details shown in the output above. Most important takeaway from the above output is that there is no CRS information. This information is crucial as it informs our data preparation steps. We must ensure that the right CRS information is set in order to carry out analysis.\n\nBelow, we import the boundary data. map_sf is the boundary data at the province level (ADM1), while map2_sf is the boundary data at the district level (ADM2). We will be using both over the course of our analysis.\n\nmap_sf &lt;- st_read(dsn = \"data/rawdata\", layer=\"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex1\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nmap2_sf &lt;- st_read(dsn = \"data/rawdata\", layer=\"tha_admbnda_adm2_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm2_rtsd_20220121' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex1\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 928 features and 19 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nAfter importing the boundary data, we notice immediately that the EPSG code isn’t accurate. The EPSG code of Thailand is 32647 while the data-frame has an EPSG code of 4326.\nWe use the st_transform() function to convert the EPSG code to the correct value of 32647.\n\nmap_sf=st_transform(map_sf,crs = 32647)\nmap2_sf=st_transform(map2_sf,crs = 32647)\n\nGiven that the OSM data-frame has no CRS information, we will first initialize it to WGS84 using the default EPSG code of 4326 by using the st_set_crs() function of the sf package.\n\nroad_sf=st_set_crs(road_sf, 4326)\n\nWe will then implement the st_crs() function to verify if the boundary data has the accurate CRS information after we transformed it above.\n\nst_crs(map_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-preparation-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#data-preparation-and-wrangling",
    "title": "Take Home Exercise 1",
    "section": "1.2.3 Data Preparation and Wrangling",
    "text": "1.2.3 Data Preparation and Wrangling\nGiven our area of interest is the Bangkok Metropolitan Region, we create a list of all provinces in this area in order to facilitate filtering for our analysis.\n\nbmr_province=c(\"Bangkok\", \"Samut Prakan\", \"Samut Sakhon\", \"Nonthaburi\", \"Nakhon Pathom\", \"Pathum Thani\")\n\nBelow, we implement the filter() function in order to filter the boundary data, at the province and district level, as well as the accident data, down to our region of interest- the Bangkok Metropolitan Region.\n\nbmr_boundary=map_sf %&gt;% \n  filter(ADM1_EN %in% bmr_province)\nbmr_boundary2=map2_sf %&gt;% \n  filter(ADM1_EN %in% bmr_province)\nbmr_accsf=rdacc_sf %&gt;% \n  filter(province_en %in% bmr_province)\n\n\nst_bbox(bmr_boundary)\n\n     xmin      ymin      xmax      ymax \n 587893.5 1484413.7  712440.5 1579076.3 \n\n\nWe now implement the st_crs() function in order to transform the EPSG code of the road_sf data-frame from 4326 to 32647. This allows us to have the accurate geometry values to facilitate future spatial joins, as well as analysis.\n\n# If road_sf was originally in EPSG:4326, reproject it properly\nroad_sf &lt;- st_transform(road_sf, crs = 32647)\n\nAfter ensuring that the CRS values are consistent, we can proceed with implementing the st_intersection() function and join the two data-frames based on their geometries.\nThe st_intersection() function is applied at the province level below.\n\nbmr_roads=st_intersection(map2_sf, road_sf)\n\nAs earlier, we will save this as an RDS file in order to improve computational efficiency.\n\nwrite_rds(bmr_roads, \"data/rds/bmrroads\")\n\n\nbmr_roads=read_rds(\"data/rds/bmrroads\")\n\nBelow, the st_intersection() function is applied at the district level and saved as an RDS file.\n\nbmr_districts=st_intersection(map2_sf, bmr_roads)\nwrite_rds(\"data/rds/bmr_districts_roads\")\n\n\nbmr_districts=read_rds(\"data/rds/bmr_districts_roads\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#kernel-density-estimation-kde",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#kernel-density-estimation-kde",
    "title": "Take Home Exercise 1",
    "section": "1.4.1 Kernel Density Estimation (KDE)",
    "text": "1.4.1 Kernel Density Estimation (KDE)\nKDE will allow us to better estimate the distribution of accidents acrosss the Bangkok Metropolitan Region. Using this, we can make more informed decisions on where to focus resources on to reduce the rate of accidents across the region.\nWe start off by preparing the data for KDE.\n\n# Step 3: Define the window (bounding box) from the boundary\nboundary_bbox &lt;- bbox(boundary_sp)  # Get bounding box of boundary\nwindow &lt;- owin(xrange = boundary_bbox[1, ], yrange = boundary_bbox[2, ])  # Define window\n\n# Step 4: Extract the coordinates from the SpatialPoints object\ncoordinates &lt;- coordinates(bmracc_sp)\n\n# Step 5: Convert the SpatialPoints into a ppp object using the window\nbmracc_ppp &lt;- ppp(x = coordinates[,1], y = coordinates[,2], window = window)\n\n# Step 6: Check the structure of the resulting point pattern object\nsummary(bmracc_ppp)\n\nPlanar point pattern:  12986 points\nAverage intensity 1.101448e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nWindow: rectangle = [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                    (124500 x 94660 units)\nWindow area = 11789900000 square units\n\n# You can now use the ppp object for spatial analysis with spatstat\n\n\nNote that you must ensure to convert the spatial objects into ppp (planar point pattern) form before proceeding with Kernel Density Estimation. The spatstat package requires data to be in this format before conducting point pattern analysis. This also improves computational efficiency.\n\n\n1.4.1.1 Dealing with Duplicates\nAfter creating the above PPP object, we check for duplicates by implementing the code chunk below.\n\nany(duplicated(bmracc_ppp))\n\n[1] TRUE\n\n\nWe check the number of duplicates in our data-frame using the code chunk below. The multiplicity() function creates a list of all duplicates after which the sum() function counts the total.\n\nsum(multiplicity(bmracc_ppp)&gt;1)\n\n[1] 2293\n\n\nThere are over 2293 duplicates. In this case, it means we have 2293 overlapping data points.\nUsing the rjitter() function, we deal with these data points by spacing them out slightly around the point. The function adds noise to the data and spreads these points out a little to facilitate visualization.\n\nbmr_ppp_jit &lt;- rjitter(bmracc_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\n\n1.4.1.2 Creating an owin object\nWhen analyzing Spatial Point patterns, it is a good practice to confine the boundaries of the analysis with a Geographical area, such as Singapore’s boundary. Using the spatstat package, we can create an owin object that is designed to represent such polygonal regions.\nWe use the as.owin() function as shown in the code chunk below.\n\nbmr_owin &lt;- as.owin(bmr_boundary)\n\nWe use the plot() function to verify if the owin object has been correctly created.\n\nplot(bmr_owin)\n\n\n\n\n\n\n\n\n\n\n1.4.1.3 Computing KDE using automatic bandwidth selection\nWe use the density() function of the spatstat package to compute the kernel density. These are the key configurations used in the computation:\n\nbw.diggle() automatic bandwidth selection method.\nThe smoothing kernel used in this instance is gaussian. Other smoothing methods include “epanechnikov”, “quartic”. or “disc”.\n\n\nkde_bmracc_bw &lt;- density(bmr_ppp_jit,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nThe other two methods aside from bw.diggle() are bw.scott() and bw.ppl(). While bw.diggle() focuses on minimizing error in spatial density estimation for point process data and is tailor-made for spatial applications, bw.scott() (Scott’s rule) provides a rule-of-thumb bandwidth and is used in several KDE applications across different types of data besides just spatial data. bw.ppl() uses a more complex and data-driven approach (plug-in) for selecting the bandwidth, aiming to minimize the error in KDE. Like bw.diggle(), It is also tailor-made for spatial point processes, however, it takes a slightly different approach to bw.diggle()\n\nWe will now plot the above using the plot() function.\n\nplot(kde_bmracc_bw)\n\n\n\n\n\n\n\n\nImmediately we notice that the density values are very small. This is because the unit of measurement is in meter, meaning that the density values are computed with a unit of ‘number of points per square meter.’\nWe now use the rescale.ppp() function of the spatstat package to convert the unit of measurement from meter to kilometer. This is done by implementing the code chunk below.\n\nbmracc_ppp.km &lt;- rescale.ppp(bmr_ppp_jit, 1000, \"km\")\n\nAfter this, we re-deploy the density() function using the re-scaled data and plot the KDE map.\n\nkde_bmracc.bw &lt;- density(bmracc_ppp.km, \n                         sigma=bw.diggle, \n                         edge=TRUE, \n                         kernel=\"gaussian\")\nplot(kde_bmracc.bw)\n\n\n\n\n\n\n\n\n\n\n1.4.1.4 Converting the KDE output into a grid object\n\n1.4.1.4.1 Gridded raster\nWe convert the gridded kernel density objects into RasterLayer object by using raster() of the raster package.\n\nkde_bmracc_bw_raster &lt;- raster(kde_bmracc.bw)\n\nThe CRS above is NA, so we now set the CRS to EPSG 32647 of Thailand.\nAfter that, we can implement the plot() function to plot the same.\n\nprojection(kde_bmracc_bw_raster) &lt;- CRS(\"+init=EPSG:32647\")\nplot(kde_bmracc_bw_raster)\n\n\n\n\n\n\n\n\nFrom the above, we infer that the South-East region, specifically districts around the Samut Prakan province seem to have a higher density of accidents.\n\n\n\n1.4.1.4.2 Peak vs Off-Peak Hours KDE [Spatio-Temporal Analysis)\nWe now want to check for the difference in accident density for off-peak and peak hours and see if there is any difference.\nWe go through the same data preparation steps as above.\n\n#First extract target values\npeak=bmr_accsf%&gt;%filter(traffic_period=='Peak')\noff_peak=bmr_accsf%&gt;%filter(traffic_period=='Off-Peak')\n\n#Convert to Spatial objects\npeak=as_Spatial(peak)\noff_peak=as_Spatial(off_peak)\n\n# Convert to SP object\npeak_sp &lt;- as(peak, \"SpatialPoints\")\noffpeak_sp &lt;- as(off_peak, \"SpatialPoints\")\n\n# Converting to Point Planar Patterns\ncoordinates_peak &lt;- coordinates(peak_sp)\ncoordinates_offpeak&lt;- coordinates(offpeak_sp)\npeak_ppp &lt;- ppp(x = coordinates_peak[,1], y = coordinates_peak[,2], window = window)\noffpeak_ppp&lt;- ppp(x= coordinates_offpeak[,1], y= coordinates_offpeak[,2], window=window)\n\n# Deal with Duplicates\npeak_ppp_jit &lt;- rjitter(peak_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\noffpeak_ppp_jit &lt;- rjitter(offpeak_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nWe can now carry out Kernel Density Estimation using the density() function. We will first rescale the values using the rescale.ppp() function as shown in the code chunk below.\n\n#Rescale PPP to facilitate understanding\npeak_ppp.km &lt;- rescale.ppp(peak_ppp_jit, 1000, \"km\")\noffpeak_ppp.km &lt;- rescale.ppp(offpeak_ppp_jit, 1000, \"km\")\n\nNow, we apply KDE.\n\nPeakOff Peak\n\n\n\nkde_peak.bw &lt;- density(peak_ppp.km, \n                         sigma=bw.diggle, \n                         edge=TRUE, \n                         kernel=\"gaussian\")\nplot(kde_peak.bw)\n\n\n\n\n\n\n\n\n\n\n\nkde_offpeak.bw &lt;- density(offpeak_ppp.km, \n                         sigma=bw.diggle, \n                         edge=TRUE, \n                         kernel=\"gaussian\")\nplot(kde_offpeak.bw)\n\n\n\n\n\n\n\n\n\n\n\nWe do a slight difference in densities especially across the highway leading from Samut Prakan into Bangkok then into Patum Thani, where there is a higher density of accidents in the off-peak hours. This can be further analyzed to determine exact hours of high volumes to develop policies."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#network-kernel-density-estimation-nkde",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#network-kernel-density-estimation-nkde",
    "title": "Take Home Exercise 1",
    "section": "1.4.1.5 Network Kernel Density Estimation (NKDE)",
    "text": "1.4.1.5 Network Kernel Density Estimation (NKDE)\nBy completing Kernel Density Estimation, we have identified two provinces of interest, Bangkok and Samut Prakan.\nWe will first extract our target regions using the code chunk below.\n\nsmt_prk_boundary= bmr_boundary2%&gt;%\n  filter(ADM1_EN=='Samut Prakan')\nsmt_prk_roads= bmr_roads%&gt;%\n  filter(ADM1_EN=='Samut Prakan')\n\n\n# We now extract the three districts with the highest number of accidents in Bangkok\nbkk_boundary= bmr_boundary2%&gt;%\n  filter(ADM2_EN %in% c(\"Lat Krabang\", \"Saphan Sung\", \"Khan Na Yao\"))\nbkk_roads= bmr_districts%&gt;%\n  filter(ADM2_EN %in% c(\"Lat Krabang\", \"Saphan Sung\", \"Khan Na Yao\"))\n\nWe will now join the OpenStreetMap data, smt_prk_roads and bkk_roads, using st_intersection function of the sf package.\n\n#Samut Prakan\nsmt_pkn_roads_intersection=st_intersection(smt_prk_roads, smt_prk_boundary)\n\n\n# Bangkok Districts\nbkk_roads_intersection=st_intersection(bkk_roads, bkk_boundary)\n\nWe will now filter down our accident data, bmr_accsf, down to our target regions.\n\n#Samut Prakan\nsmt_pkn_acc=bmr_accsf%&gt;%\n  filter(province_en=='Samut Prakan')\n\n\n#Bangkok Districts\nbkk_acc=bmr_accsf%&gt;%\n  filter(province_en=='Bangkok')\ndistrict_accidents=st_intersection(bkk_acc, bkk_boundary)\n\nWe can now start with Network Kernel Density Estimation.\nWe must first cut the SpatialLines object into Lixels by implementing the lixelize_lines() function with a specified minimal distance.\n\n# We first ensure that the geometries are in the right format for lixelization.\nsmt_pkn_roads_intersection=st_cast(smt_pkn_roads_intersection, 'LINESTRING', group_or_split= TRUE)\nsamut_prakan_lines=st_cast(smt_pkn_roads_intersection,'LINESTRING')\nlixels_smt_pkn &lt;- lixelize_lines(smt_pkn_roads_intersection, \n                         10000, \n                         mindist = 5000)\n\n\n# Filter out POINT geometries\nbkk_roads_lines &lt;- bkk_roads_intersection[st_is(bkk_roads_intersection, c(\"LINESTRING\", \"MULTILINESTRING\")), ]\n\n# Cast MULTILINESTRING to LINESTRING\nbkk_roads_linestring &lt;- st_cast(bkk_roads_lines, \"LINESTRING\", group_or_split = TRUE)\n\n# Create Lixels\nlixels_bkk &lt;- lixelize_lines(bkk_roads_linestring, \n                         10000, \n                         mindist = 5000)\n\n\nThere is another function, lixelize_lines.mc() that provides multicore support and is typically used in spatial analysis or geospatial data processing, specifically in contexts where large datasets of lines (such as roads, paths, or boundaries) need to be broken down into smaller, equally spaced segments or “lixels” (line pixels). This process is known as “lixelization.”\nThe main purpose of the lixelize_lines.mc() function is to improve the efficiency of the lixelization process by utilizing multiple CPU cores simultaneously. This is particularly beneficial when dealing with large datasets, as processing each line sequentially can be time-consuming.\n\nWe now proceed to generate a SpatialPointsDataFrame with line centre points using the lines_center() function of spNetwork.\n\nsamples_smt_pkn &lt;- lines_center(lixels_smt_pkn) \n\n\nsamples_bkk &lt;- lines_center(lixels_bkk)\n\nNow, we can perform NKDE. We use the nkde() function to carry it out.\n\n# Samut Prakan NKDE\ndensities_smt_prk &lt;- nkde(lixels_smt_pkn, \n                  events = smt_pkn_acc,\n                  w = rep(1, nrow(smt_pkn_acc)),\n                  samples = samples_smt_pkn,\n                  kernel_name = \"quartic\",\n                  bw = 1000, \n                  method = \"simple\")\n\n\nwrite_rds(densities_smt_prk, \"data/rds/density_samut\")\n\n\ndensities_smt_prk=read_rds('data/rds/density_samut')\n\n\n# Perform NKDE for Bangkok Districts\ndensities_bkk &lt;- nkde(\n  lines = lixels_bkk    ,               # Road network\n  events = district_accidents,      # Subset of accident data (for testing)\n  w = rep(1,nrow(district_accidents)),                # Weights (equal for all events)\n  samples = samples_bkk,           # Sample points along the road network\n  kernel_name = \"quartic\",         # Kernel type (quartic kernel)\n  bw = 500, # Bandwidth (smoothing parameter)\n  div = 'bw',\n  method = \"simple\",               # Simple method for NKDE,\n  verbose = TRUE\n  )          # Spatial grid resolution (lower for faster computation)                   \nwrite_rds(densities_bkk, 'data/rds/density_bkk')\n\n\ndensities_bkk=read_rds('data/rds/density_bkk')\n\n\n\nThe kernel_name argument specifies the type of kernel function used.\nPossible kernel methods supported by spNetwork include:\n\nQuartic\nTriangle\nGaussian\nScaled Gaussian\nTricube\nCosine\nTriweight\nEpanechnikov\nUniform\n\nThe method argument indicates the method used to calculate Network Kernel Density Estimation (NKDE).\nspNetwork supports three popular methods:\n\nSimple (method = \"simple\"):\n\nIntroduced by Xie et al. (2008).\nDistances between events and sampling points are replaced by network distances.\nThe kernel formula is adapted to calculate density over a linear unit instead of an areal unit.\n\nDiscontinuous (method = \"discontinuous\"):\n\nProposed by Okabe et al. (2008).\nDivides the mass density of an event at intersections of lixels.\nResults in a discontinuous kernel function.\n\nContinuous (method = \"continuous\"):\n\nAlso proposed by Okabe et al. (2008).\nAdjusts the density before intersections to create a continuous kernel function.\nStill divides the mass of the density at intersections but with a continuous adjustment.\n\n\n\n\nWe will now visualize NKDE.\nWe must first insert the computed density values into samples and lixels objects as the density field.\n\n#Samut Prakan\nsamples_smt_pkn$density&lt;- densities_smt_prk\nlixels_smt_pkn$density &lt;- densities_smt_prk\n\n\n#Bangkok Districts\nsamples_bkk$density&lt;- densities_bkk\nlixels_bkk$density &lt;- densities_bkk\n\nWe now upscale the density for both in the interest of easier understanding.\n\n#Samut Prakan\nsamples_smt_pkn$density &lt;- samples_smt_pkn$density*1000\nlixels_smt_pkn$density &lt;- lixels_smt_pkn$density*1000\n\n\n#Bangkok Districts\nsamples_bkk$density &lt;- samples_bkk$density*1000\nlixels_bkk$density &lt;- lixels_bkk$density*1000\n\nWe can now plot the map as the data is now prepared.\nWe will use the tmap package to produce a highly cartographic and interactive map.\n\n#Samut Prakan\ntmap_mode('plot')\ntm_shape(lixels_smt_pkn)+\n  tm_lines(col=\"density\")+\ntm_shape(smt_pkn_acc)+\n  tm_dots()\n\n\n\n\n\n\n\n\nThe interactive map above effectively reveals road segments with relatively higher density of accidents than road segments with relatively lower density of accidents with the help of shading. The roads with darker shades have a relatively higher density.\n\n#Bangkok Districts\ntmap_mode('plot')\ntm_shape(lixels_bkk)+\n  tm_lines(col=\"density\")\n\n\n\n\n\n\n\n\nWe see a highway on the North West side, across roads such as Kanchanapishek Road, of the three districts have a particularly high density of accidents on it after examining the plots above. This can be further investigated in order to develop policies and improve roads in those specific regions.\nFrom all our analysis, we take away that the south-eastern part of Bangkok Metropolitan Region was a hotspot, and this map above allows us to further understand the distribution of accidents across the region.\n\n1.4.1.5.1 Network Constrained G- and K-Function Analysis\nWe will now conduct a test for Complete Spatial Randomness by using the kfunctions() function of the spNetwork package.\nThe hypotheses are as follows:\n\nHo: The observed spatial point events (i.e distribution of accidents) are uniformly distributed over a street network in Samut Prakan.\nH1: The observed spatial point events (i.e: distribution of accidents) are not uniformly distributed over a street network in Samut Prakan.\n\n\n# Samut Prakan\nkfun_accidents &lt;- kfunctions(smt_pkn_roads_intersection, \n                             smt_pkn_acc,\n                             start = 0, \n                             end = 1000, \n                             step = 50, \n                             width = 50, \n                             nsim = 50, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05,\n                             agg = 1)  # Set aggregation to merge close points\n\n\nwrite_rds(kfun_accidents, \"data/rds/kfunction\")\n\n\nkfun_accidents=read_rds('data/rds/kfunction')\n\nWe now do the same for the selected Bangkok Districts.\n\n# Manually snap points with a larger tolerance\nsnapped_points &lt;- st_snap(district_accidents, bkk_roads_linestring, tolerance = 100)\n\n# Now run kfunctions on the snapped points\nkfun_accidents_bkk &lt;- kfunctions(\n  bkk_roads_linestring, \n  snapped_points,\n  start = 0, \n  end = 1000, \n  step = 50, \n  width = 50, \n  nsim = 50, \n  resolution = 50,\n  verbose = FALSE, \n  conf_int = 0.05,\n  agg = 500  # Reasonable aggregation value\n)\n\nwrite_rds(kfun_accidents_bkk, 'data/rds/kfunction_bkk')\n\n\nkfun_accidents_bkk=read_rds('data/rds/kfunction_bkk')\n\n\nBelow are the arguments of the function above:\n\nlines: A SpatialLinesDataFrame containing the sampling points. The geometries must be valid; using invalid geometries may cause the process to crash.\npoints: A SpatialPointsDataFrame representing the points on the network. These points will be snapped to the network for analysis.\nstart: A numeric value indicating the starting point for evaluating the k and g functions.\nend: A numeric value specifying the endpoint for evaluating the k and g functions.\nstep: A numeric value that determines the interval between evaluations of the k and g functions.\nwidth: The width of each “donut” or ring used in calculating the g-function.\nnsim: An integer representing the number of Monte Carlo simulations to perform. In the example above, 50 simulations were conducted; however, more simulations are often necessary for accurate inference.\nresolution: Specifies the resolution when simulating random points on the network. A higher resolution can significantly reduce calculation time. If set to NULL, random points can occur anywhere on the network. If a value is provided, the network’s edges are divided according to this resolution, and random points are selected from the vertices of the newly segmented network.\nconf_int: A numeric value indicating the confidence interval width, with the default set to 0.05.\n\n\nThe k-function will output the following:\n\nplotk, a ggplot2 object representing the values of the k-function.\nplotg, a ggplot2 object representing the values of the g-function.\nvalues, a DataFrame with the values used to build the plots.\n\nBelow, we visualize the plots generated.\nWe start with Samut Prakan.\n\nPlot KPlot G\n\n\n\nkfun_accidents$plotk\n\n\n\n\n\n\n\n\nBased on the plot above, we can see the the blue line are entirely above the envelope at the bottom, indicating that we do indeed have sufficient evidence to reject the null hypothesis and conclude that the distribution of accidents across Samut Prakan do exhibit spatial clustering tendencies.\n\n\n\nkfun_accidents$plotg\n\n\n\n\n\n\n\n\nBased on the plot above, we can see that the blue line is entirely above the envelope at the bottom, similar to the k plot, indicating that we do indeed have sufficient evidence to reject the null hypothesis and conclude that the distribution of accidents across Samut Prakan do exhibit Spatial Clustering tendencies.\n\n\n\nWe will now plot the K and G plot for the selected Bangkok Districts.\n\nK PlotG Function\n\n\n\nplot(kfun_accidents_bkk$plotk)\n\n\n\n\n\n\n\n\n\n\n\nplot(kfun_accidents_bkk$plotg)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#second-order-spatial-point-pattern-analysis.",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#second-order-spatial-point-pattern-analysis.",
    "title": "Take Home Exercise 1",
    "section": "1.4.2 Second-Order Spatial Point Pattern Analysis.",
    "text": "1.4.2 Second-Order Spatial Point Pattern Analysis.\nWe now focus on Second Order Spatial Point Patterns Analysis.\nWe first filter the data down to the regions of interest and create separate boundaries for each of them. Following this, we produce an owin object using the as.owin() function.\n\n# Filtering the data down to the regions of interest\nbkk = bmr_boundary %&gt;%\n  filter(ADM1_EN == \"Bangkok\")\nsmt_pkn = bmr_boundary %&gt;%\n  filter(ADM1_EN == \"Samut Prakan\")\nntbr = bmr_boundary %&gt;%\n  filter(ADM1_EN == \"Nonthaburi\")\nnkn_ptn= bmr_boundary %&gt;%\n  filter(ADM1_EN == \"Nakhon Pathom\")\nsmt_skn= bmr_boundary %&gt;%\n  filter(ADM1_EN == \"Samut Sakhon\")\nptm_thn= bmr_boundary%&gt;%\n  filter(ADM1_EN=='Pathum Thani')\n\n# Creating the owin object\nbkk_owin = as.owin(bkk)\nsmt_pkn_owin = as.owin(smt_pkn)\nntbr_owin = as.owin(ntbr)\nnkn_ptn_owin = as.owin(nkn_ptn)\nsmt_skn_owin = as.owin(smt_skn)\nptm_thn_owin= as.owin(ptm_thn)\n\n#Creating point planar patterns\nacc_bkk_ppp = bmr_ppp_jit[bkk_owin]\nacc_smt_pkn_ppp = bmr_ppp_jit[smt_pkn_owin]\nacc_ntbr_ppp = bmr_ppp_jit[ntbr_owin]\nacc_nkn_ptn_ppp = bmr_ppp_jit[nkn_ptn_owin]\nacc_smt_skn_ppp= bmr_ppp_jit[smt_skn_owin]\nacc_ptm_thn_ppp= bmr_ppp_jit[ptm_thn_owin]\n\n\n1.4.2.1 Calculating G-function estimates and testing for Complete Spatial Randomness\nWe now focus on computing G-function estimates.\nThe test below allows us to understand if accidents in the Bangkok Metropolitan Region exhibit Spatial Clustering or if they are Randomly Distributed.\nWe apply the test for Complete Spatial Randomness to each region individually. The tests are conducted at a 5% significance level.\nThe hypotheses are as follows.\n\nH0: There is no spatial clustering. The accidents are randomly distributed across the region.\nH1: There is spatial clustering. The accidents are NOT randomly distributed across the region.\n\n\nBangkokSamut PrakhanNonthaburiNakhon PathomSamut SakhonPatum Thani\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for Bangkok. Following that, we plot the result.\n\nG_bkk = Gest(acc_bkk_ppp, correction = \"border\")\nplot(G_bkk, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now carry out the monte carlo simulation test, using the envelope() function, for complete spatial randomness.\n\nG_bkk.csr &lt;- envelope(acc_bkk_ppp, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(G_bkk.csr)\n\n\n\n\n\n\n\n\nIt is clear that that there is clustering exhibited in this scenario as the black line, observed values, is far above the envelope. We have sufficient evidence to reject the null hypothesis.\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for Samut Prakhan. Following that, we plot the result.\n\nG_smt_pkn = Gest(acc_smt_pkn_ppp, correction = \"border\")\nplot(G_smt_pkn, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now implement a monte carlo simulation test, using the envelope() function, for Complete Spatial Random in Samut Prakan.\n\nG_smt_pkn.csr &lt;- envelope(acc_smt_pkn_ppp, Gest, nsim = 199)\n\nGenerating 199 simulations of CSR  ...\n1, 2, 3, 4.6.8.10.12.14.16.18.20.22.24.26.28.30.32.34\n.36.38.40.42.44.46.48.50.52.54.56.58.60.62.64.66.68.70.72.74\n.76.78.80.82.84.86.88.90.92.94.96.98.100.102.104.106.108.110.112.114\n.116.118.120.122.124.126.128.130.132.134.136.138.140.142.144.146.148.150.152.154\n.156.158.160.162.164.166.168.170.172.174.176.178.180.182.184.186.188.190.192.194\n.196.198\n199.\n\nDone.\n\n\n\nplot(G_smt_pkn.csr)\n\n\n\n\n\n\n\n\nWe once again have sufficient evidence to reject the null hypothesis and conclude that accidents in Samut Prakan do indeed exhibit clustering, more so than is expected in a region that is randomly distributed.\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for Nonthaburi. Following that, we plot the result.\n\nG_ntbr = Gest(acc_ntbr_ppp, correction = \"border\")\nplot(G_ntbr, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now implement a Monte-Carlo Simulation test, using the envelope() function, to check for complete spatial randomness of roads accidents in Nonthaburi.\n\nG_ntbr.csr &lt;- envelope(acc_ntbr_ppp, Gest, nsim = 199)\n\nGenerating 199 simulations of CSR  ...\n1, 2, 3, 4.6.8.10.12.14.16.18.20.22.24.26.28.30.32.34\n.36.38.40.42.44.46.48.50.52.54.56.58.60.62.64.66.68.70.72.74\n.76.78.80.82.84.86.88.90.92.94.96.98.100.102.104.106.108.110.112.114\n.116.118.120.122.124.126.128.130.132.134.136.138.140.142.144.146.148.150.152.154\n.156.158.160.162.164.166.168.170.172.174.176.178.180.182.184.186.188.190.192.194\n.196.198\n199.\n\nDone.\n\n\n\nplot(G_ntbr.csr)\n\n\n\n\n\n\n\n\nWe once again have sufficient evidence to reject the null hypothesis and conclude that accidents in Nonthaburi do indeed exhibit clustering, more than is expected in a region that is randomly distributed.\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for Nakhon Pathom. Following that, we plot the result.\n\nG_nkn_ptn = Gest(acc_nkn_ptn_ppp, correction = \"border\")\nplot(G_nkn_ptn, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now conduct the Monte-Carlo Simulation test, using the envelope() function, for complete spatial randomness for accidents in Nakhon Pathom.\n\nG_nkn_ptn.csr &lt;- envelope(acc_nkn_ptn_ppp, Gest, nsim = 199)\n\nGenerating 199 simulations of CSR  ...\n1, 2, 3, 4.6.8.10.12.14.16.18.20.22.24.26.28.30.32.34\n.36.38.40.42.44.46.48.50.52.54.56.58.60.62.64.66.68.70.72.74\n.76.78.80.82.84.86.88.90.92.94.96.98.100.102.104.106.108.110.112.114\n.116.118.120.122.124.126.128.130.132.134.136.138.140.142.144.146.148.150.152.154\n.156.158.160.162.164.166.168.170.172.174.176.178.180.182.184.186.188.190.192.194\n.196.198\n199.\n\nDone.\n\n\n\nplot(G_nkn_ptn.csr)\n\n\n\n\n\n\n\n\nWe once again have sufficient evidence to reject the null hypothesis and conclude that accidents in Nakhon Pathom do indeed exhibit clustering, more than is expected in a region that is randomly distributed.\n\n\nWe use the Gest() function of the spatstat package to compute a G-function estimation for Samut Sakhon. Following that, we plot the result.\n\nG_smt_skn = Gest(acc_smt_skn_ppp, correction = \"border\")\nplot(G_smt_skn, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now conduct the Monte-Carlo Simulation test, using the envelope() function, for complete spatial randomness for accidents in Samut Sakhon.\n\nG_smt_skn.csr &lt;- envelope(acc_smt_skn_ppp, Gest, nsim = 199)\n\nGenerating 199 simulations of CSR  ...\n1, 2, 3, 4.6.8.10.12.14.16.18.20.22.24.26.28.30.32.34\n.36.38.40.42.44.46.48.50.52.54.56.58.60.62.64.66.68.70.72.74\n.76.78.80.82.84.86.88.90.92.94.96.98.100.102.104.106.108.110.112.114\n.116.118.120.122.124.126.128.130.132.134.136.138.140.142.144.146.148.150.152.154\n.156.158.160.162.164.166.168.170.172.174.176.178.180.182.184.186.188.190.192.194\n.196.198\n199.\n\nDone.\n\n\n\nplot(G_smt_skn.csr)\n\n\n\n\n\n\n\n\nWe once again have sufficient evidence to reject the null hypothesis and conclude that accidents in Samut Sakhon do indeed exhibit clustering, more so than is expected in a region that is randomly distributed.\n\n\nWe use the Gest() function of the Spatstat package to compute a G-function estimation for Patum Thani\n\nG_ptm_thn = Gest(acc_ptm_thn_ppp, correction = \"border\")\nplot(G_nkn_ptn, xlim=c(0,500))\n\n\n\n\n\n\n\n\nWe now conduct the Monte Carlo Simulation Test for Complete Spatial Randomness by implementing the envelope() function.\n\nG_ptm_thn.csr &lt;- envelope(acc_ptm_thn_ppp, Gest, nsim = 199)\n\nGenerating 199 simulations of CSR  ...\n1, 2, 3, 4.6.8.10.12.14.16.18.20.22.24.26.28.30.32.34\n.36.38.40.42.44.46.48.50.52.54.56.58.60.62.64.66.68.70.72.74\n.76.78.80.82.84.86.88.90.92.94.96.98.100.102.104.106.108.110.112.114\n.116.118.120.122.124.126.128.130.132.134.136.138.140.142.144.146.148.150.152.154\n.156.158.160.162.164.166.168.170.172.174.176.178.180.182.184.186.188.190.192.194\n.196.198\n199.\n\nDone.\n\n\n\nplot(G_ptm_thn.csr)\n\n\n\n\n\n\n\n\nWe have sufficient Evidence to reject the null hypothesis and can conclude that accidents in Pathum Thani are not randomly distributed and do indeed exhibit spatial clustering.\n\n\n\n\n\nThe grey zone indicates the confidence envelop (In this case, we have set it as 95% as indicated by the critical value of 0.05)\nWhen an observed L value is greater than its corresponding L(theo) value for a particular distance and lower than the upper confidence envelop, spatial clustering for that distance is statistically NOT significant (e.g. distance between B and C).\nWhen an observed L value is smaller than its corresponding L(theo) value for a particular distance and beyond the lower confidence envelop, spatial dispersion for that distance is statistically significant. - When an observed L value is smaller than its corresponding L(theo) value for a particular distance and within the lower confidence envelop, spatial dispersion for that distance is statistically NOT significant (e.g. distance between A and B).\n\n\n\n1.4.2.2 Clark and Evans Test\nWe now perform the Clark-Evans test of Aggregation for a spatial point pattern by using the clarkevans.test() function of spatstat.\nThe Clark and Evans is a method used to analyze the spatial distribution of points in selected areas of interest. It allows us to understand whether a point pattern is Random, Clustered or Regularly Spaced by comparing the observed nearest-neighbor distances between points to the expected distances under a random distribution.\nThe hypotheses that we will be testing are as follows:\nHo = The distribution of accidents are randomly distributed.\nH1= The distribution of accidents are not randomly distributed.\nThe tests will be conducted at a 5% significance level.\n\nBangkokSamut PrakhanSamut SakhonNonthaburiNakhon PathomPatum Thani\n\n\n\nclarkevans.test(acc_bkk_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_bkk_ppp\nR = 0.17748, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(acc_smt_pkn_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_smt_pkn_ppp\nR = 0.19392, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(acc_smt_skn_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_smt_skn_ppp\nR = 0.27252, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(acc_ntbr_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_ntbr_ppp\nR = 0.41864, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(acc_nkn_ptn_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_nkn_ptn_ppp\nR = 0.30788, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nclarkevans.test(acc_ptm_thn_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  acc_ptm_thn_ppp\nR = 0.27399, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\n\n\n\nFrom the above outputs, we are able to reject the null hypothesis given the observed p-value is less than 0.05. We have sufficient evidence and can conclude that the distribution of accidents across the Bangkok Metropolitan Region are not randomly distributed and do indeed exhibit spatial clustering.\n\nThe R value is an important part of the output.\n\nWhen R=1, it means there is random spatial distribution.\nWhen R&gt;1 It means that there is Regularly Spaced Spatial Distribution\nWhen R&lt;1, it means that there is Clustered Spatial Distribution."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#spatial-weights",
    "title": "Take Home Exercise 1",
    "section": "1.4.3 Spatial Weights",
    "text": "1.4.3 Spatial Weights\nWe now create a data-frame, boundary_with_accident_count, in order to assign Spatial Weights and carry out further analysis.\nWe start off by conducting a spatial join with the help of the st_join() function of the sf package to join bmr_accsf, accident data of the Bangkok Metropolitan Region.\nWe then use the left_join() function of the dplyr package to join this with the boundary data in order to facilitate analysis.\nWe then save it as an RDS file.\n\naccidents_with_districts &lt;- st_join(bmr_accsf, bmr_boundary2, join = st_intersects)\n# Group by adm2_en and count the number of accidents per district\naccident_counts_by_adm2 &lt;- accidents_with_districts %&gt;%\n  group_by(ADM2_EN) %&gt;%\n  summarise(accident_count = n())\n\n# Perform a left join with the boundary data\nboundary_with_accident_count &lt;- bmr_boundary2 %&gt;%\n  st_join(accident_counts_by_adm2, by = \"ADM2_EN\")\nboundary_with_accident_count &lt;- boundary_with_accident_count %&gt;%\n  mutate(accident_count = ifelse(is.na(accident_count), 0, accident_count))\nwrite_rds(boundary_with_accident_count, \"data/rds/boundary_with_acc_count\")\n\n\nboundary_with_accident_count=read_rds(\"data/rds/boundary_with_acc_count\")\n\nAfter successfully completing the relational join, we can now plot a choropleth map to visualize the number of accidents in the Bangkok Metropolitan Region using various functions of the tmap package\n\nbasemap &lt;- tm_shape(boundary_with_accident_count) +\n  tm_polygons() +\n  tm_text(\"ADM2_EN.x\", size=0.5)\ngdppc &lt;- qtm(boundary_with_accident_count, \"accident_count\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThe above map reinforces our earlier finding that the Eastern/South-Eastern region of the Bangkok Metropolitan Region have the most accidents. One district in the bottom left, part of the Samut Sakhon province, also has a high volume of accidents.\n\n1.4.3.1 Computing Contiguity Spatial Weights\nWe now implement the poly2nb() function of the spdep package to compute contiguity weight matrices for the study area selected.\nUsing this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.\nIn this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.\nYou may refer to the spdep package documentation here to learn more about its functions and arguments.\n\n1.4.3.1.1 Computing (QUEEN) contiguity based neighbors\nThe poly2nb() function is implemented as shown in the code chunk below. Using this, we are able to compute a Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(boundary_with_accident_count, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 438 \nPercentage nonzero weights: 7.018106 \nAverage number of links: 5.544304 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 1  5 10 24 20 12  6  1 \n1 least connected region:\n66 with 2 links\n1 most connected region:\n30 with 9 links\n\n\nThe most connected area has 9 neighbors. In general, most districts have approximately 5 to 6 neighbors.\n\n\n1.4.3.1.2 Computing (ROOK) contiguity based neighbors\nFor this, we will set the queen argument of the poly2nb() function to false.\n\nwm_r &lt;- poly2nb(boundary_with_accident_count, queen=FALSE) \nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 422 \nPercentage nonzero weights: 6.761737 \nAverage number of links: 5.341772 \nLink number distribution:\n\n 2  3  4  5  6  7  8 \n 1  5 16 20 22 11  4 \n1 least connected region:\n66 with 2 links\n4 most connected regions:\n1 5 17 54 with 8 links\n\n\nThe most connected area has 8 neighbors. In general, most districts have approximately 5 to 6 neighbors.\n\n\n\n1.4.3.2 Visualizing contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons in this situation, so we need to ensure that our points are in order to produce our connectivity graphs.\nUsually, the method of choice will be polygon centroids. We calculate using the sf package before moving onto the graphs. Getting latitude and longitude of the Polygon Centroids.\nWe need points to associate with each polygon before we can make our connectivity graph. It won’t be as simple as applying the st_centroid() function of the sf sf object: us.bound. We need the coordinates in a separate data-frame for this to work.\nTo do this, we will use a mapping function which will apply a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\nThe function that we implement in this situation will be st_centroid().\nWe will be using the map_dbl variation of map from the purrr package.\n\n1.4.3.2.1 Obtaining Coordinate values\n\nLongitudeLatitudeCoords\n\n\n\nlongitude &lt;- map_dbl(boundary_with_accident_count$geometry, ~st_centroid(.x)[[1]])\n\n\n\n\nlatitude &lt;- map_dbl(boundary_with_accident_count$geometry, ~st_centroid(.x)[[2]])\n\n\n\nNow that we have the latitude and longitude values, we can use the cbind() function to put the longitude and latitude values into the same object, coords.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\nhead(coords)\n\n     longitude latitude\n[1,]  661951.4  1521172\n[2,]  664121.1  1523923\n[3,]  700735.2  1532207\n[4,]  664808.5  1518057\n[5,]  676193.5  1533602\n[6,]  677305.1  1522820\n\n\n\n\n\nWe can now plot the contiguity weights side by side for comparison.\n\npar(mfrow=c(1,2))\nplot(boundary_with_accident_count$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"purple\")\nplot(boundary_with_accident_count$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"darkgreen\")\n\n\n\n\n\n\n\n\n\n\nQueen Contiguity creates more connections as seen above, as it considers both shared vertices AND edges. This results in a more dense network.\nRook Contiguity results in fewer connections as it only considers shared borders as opposed to Queen Contiguity. This results in a simpler network.\n\n\nWe often use these in order to proceed with Spatial Autocorrelation Analysis to understand the neighbors taken into consideration amongst other factors.\n\n\n\n1.4.3.3 Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrices is that the more densely settled areas (usually urban areas) tend to have more neighbors and the less densely settled areas (usually rural areas) tend to have lesser neighbors.\nHaving many neighbors smoothens the neighbor relationship across more neighbors.\nIt is possible to control the numbers of neighbors directly using k-nearest neighbors by either accepting asymmetric neighbors or imposing symmetry\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 474 \nPercentage nonzero weights: 7.594937 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe immediately see a difference when comparing the above output to wm_q and wm_r. The number of non-zero links is higher.\nWe can create the plot for the same using the plot() function.\n\nplot(boundary_with_accident_count$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n1.4.3.4 Row standardized weights matrix\n\n1.4.3.4.1 Weights Based on Inversed Distance Weighting (IDW)\nWe first compute the distances between areas by implementing the nbdists() function of the spdep package.\n\ndist &lt;- nbdists(wm_q, coords, longlat = FALSE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.0002854535 0.0006582134 0.0004566217 0.0002167536 0.0003080119\n[6] 0.0002757322 0.0003371576 0.0002806965\n\n[[2]]\n[1] 0.0002854535 0.0002055287 0.0003012437 0.0003439200 0.0003703229\n[6] 0.0002193608 0.0001383976 0.0002982074\n\n[[3]]\n[1] 8.230456e-05 7.194802e-05 7.691011e-05 6.386761e-05\n\n[[4]]\n[1] 0.0005397094 0.0003348823 0.0004742967 0.0004145926 0.0006228750\n\n[[5]]\n[1] 1.466707e-04 1.197978e-04 1.317261e-04 1.901079e-04 1.449448e-04\n[6] 2.005737e-04 1.397857e-04 8.481219e-05\n\n[[6]]\n[1] 0.0001622765 0.0002212846 0.0002009303 0.0001431074 0.0001781389\n[6] 0.0002901167\n\n[[7]]\n[1] 0.0002055287 0.0005397094 0.0003428497 0.0003432013 0.0003504051\n[6] 0.0002113326 0.0005031250 0.0001878859\n\n[[8]]\n[1] 0.0006582134 0.0003012437 0.0003348823 0.0003428497 0.0007193454\n\n[[9]]\n[1] 0.0001452881 0.0001919620 0.0002478517 0.0001846853 0.0003608347\n[6] 0.0001275280\n\n[[10]]\n[1] 8.230456e-05 1.204212e-04 1.185473e-04 1.177461e-04 1.338999e-04\n\n[[11]]\n[1] 7.194802e-05 1.204212e-04 7.412539e-05 8.957108e-05 5.200876e-05\n[6] 6.530843e-05 8.333031e-05\n\n[[12]]\n[1] 0.0002120327 0.0003601503 0.0003033661 0.0002204848 0.0002299417\n\n[[13]]\n[1] 0.0004566217 0.0004742967 0.0003432013 0.0007193454 0.0005352046\n\n[[14]]\n[1] 0.0003439200 0.0004723701 0.0002181006 0.0001852359 0.0003556913\n\n[[15]]\n[1] 0.0002167536 0.0004178016 0.0005004725 0.0002059056 0.0002024628\n[6] 0.0002988328 0.0002534194\n\n[[16]]\n[1] 0.0003080119 0.0004178016 0.0001666057 0.0003222415 0.0002506523\n\n[[17]]\n[1] 0.0001622765 0.0004355978 0.0001468778 0.0001493430 0.0002022661\n[6] 0.0001455745 0.0002525101 0.0003209334\n\n[[18]]\n[1] 0.0002757322 0.0004145926 0.0005352046 0.0005004725 0.0003077165\n[6] 0.0003335152\n\n[[19]]\n[1] 0.0001666057 0.0002462888 0.0001860044 0.0001509068 0.0001330087\n[6] 0.0001378191 0.0002092546\n\n[[20]]\n[1] 0.0003371576 0.0003222415 0.0002462888 0.0001834292 0.0002732088\n\n[[21]]\n[1] 8.969997e-05 1.203769e-04 1.245294e-04 9.569804e-05 4.958860e-05\n\n[[22]]\n[1] 0.0002059056 0.0002506523 0.0001860044 0.0001834292 0.0002152303\n[6] 0.0001971194 0.0001095917\n\n[[23]]\n[1] 2.053579e-04 1.119769e-04 1.692192e-04 6.579843e-05 1.036058e-04\n\n[[24]]\n[1] 0.0002120327 0.0002024628 0.0003529966 0.0002347366 0.0001982741\n[6] 0.0001621175\n\n[[25]]\n[1] 0.0002806965 0.0003703229 0.0001509068 0.0002732088 0.0001935337\n[6] 0.0001208318\n\n[[26]]\n[1] 0.0004723701 0.0004355978 0.0001754699 0.0003013611\n\n[[27]]\n[1] 0.0001466707 0.0002212846 0.0002022599 0.0003179325 0.0001494025\n\n[[28]]\n[1] 0.0006228750 0.0003504051 0.0003601503 0.0003077165 0.0003330968\n[6] 0.0002241661\n\n[[29]]\n[1] 2.193608e-04 2.181006e-04 1.935337e-04 2.480081e-04 1.269610e-04\n[6] 1.731795e-04 8.705329e-05\n\n[[30]]\n[1] 0.0001383976 0.0001197978 0.0001852359 0.0001468778 0.0001754699\n[6] 0.0002480081 0.0002134931 0.0001692547 0.0001150417\n\n[[31]]\n[1] 0.0003033661 0.0002988328 0.0003335152 0.0003529966 0.0003330968\n\n[[32]]\n[1] 1.452881e-04 7.412539e-05 1.648225e-04 1.385556e-04 1.384360e-04\n[6] 9.877756e-05\n\n[[33]]\n[1] 0.0002113326 0.0001919620 0.0002204848 0.0002241661 0.0004631083\n[6] 0.0001381990\n\n[[34]]\n[1] 0.0002009303 0.0002478517 0.0001493430 0.0001648225 0.0002087434\n[6] 0.0001252900\n\n[[35]]\n[1] 2.534194e-04 8.969997e-05 2.152303e-04 2.347366e-04 1.338459e-04\n[6] 1.190158e-04\n\n[[36]]\n[1] 1.317261e-04 1.741388e-04 1.477787e-04 9.360890e-05 1.023839e-04\n[6] 4.522313e-05\n\n[[37]]\n[1] 0.0002982074 0.0005031250 0.0003556913 0.0002022661 0.0003013611\n[6] 0.0001760696\n\n[[38]]\n[1] 0.0001901079 0.0001431074 0.0001455745 0.0002022599 0.0002134931\n[6] 0.0001969405\n\n[[39]]\n[1] 0.0001878859 0.0001846853 0.0002525101 0.0004631083 0.0002087434\n[6] 0.0001760696\n\n[[40]]\n[1] 0.0001330087 0.0001971194 0.0002053579 0.0001396487 0.0001509543\n\n[[41]]\n[1] 0.0001449448 0.0001269610 0.0001692547 0.0001741388 0.0001155726\n[6] 0.0001062678\n\n[[42]]\n[1] 2.005737e-04 1.477787e-04 1.006357e-04 5.914874e-05\n\n[[43]]\n[1] 0.0001397857 0.0001185473 0.0003179325 0.0001503042 0.0001120205\n\n[[44]]\n[1] 1.781389e-04 1.177461e-04 8.957108e-05 1.494025e-04 1.385556e-04\n[6] 1.252900e-04 1.503042e-04\n\n[[45]]\n[1] 0.0002901167 0.0003209334 0.0001969405\n\n[[46]]\n[1] 7.691011e-05 8.481219e-05 1.338999e-04 1.006357e-04 1.120205e-04\n[6] 7.834800e-05\n\n[[47]]\n[1] 3.608347e-04 1.384360e-04 8.847607e-05 7.825942e-05 1.380165e-04\n\n[[48]]\n[1] 1.378191e-04 1.119769e-04 1.396487e-04 1.390484e-04 5.812114e-05\n[6] 9.420908e-05\n\n[[49]]\n[1] 0.0001203769 0.0001982741 0.0001338459 0.0001460302 0.0001218403\n\n[[50]]\n[1] 1.245294e-04 1.095917e-04 1.692192e-04 1.190158e-04 1.509543e-04\n[6] 4.881437e-05 7.827893e-05\n\n[[51]]\n[1] 8.847607e-05 4.260505e-05 9.775096e-05 7.211651e-05 6.976002e-05\n\n[[52]]\n[1] 5.200876e-05 4.260505e-05 6.461671e-05 1.208164e-04\n\n[[53]]\n[1] 6.530843e-05 9.877756e-05 7.825942e-05 9.775096e-05 6.461671e-05\n[6] 1.098016e-04\n\n[[54]]\n[1] 1.275280e-04 2.299417e-04 1.621175e-04 1.381990e-04 1.380165e-04\n[6] 1.460302e-04 7.211651e-05 8.749710e-05\n\n[[55]]\n[1] 9.569804e-05 1.218403e-04 6.976002e-05 8.749710e-05\n\n[[56]]\n[1] 8.333031e-05 1.208164e-04 1.098016e-04\n\n[[57]]\n[1] 0.0001731795 0.0001150417 0.0001155726 0.0001121332 0.0000764271\n[6] 0.0000755279 0.0001320269\n\n[[58]]\n[1] 2.092546e-04 1.208318e-04 8.705329e-05 1.390484e-04 1.121332e-04\n[6] 1.356813e-04 6.810787e-05\n\n[[59]]\n[1] 7.642710e-05 1.356813e-04 1.153320e-04 5.588948e-05 1.070876e-04\n\n[[60]]\n[1] 7.552790e-05 1.153320e-04 8.048614e-05 9.201600e-05 7.698649e-05\n\n[[61]]\n[1] 5.588948e-05 8.048614e-05 8.676092e-05 7.105006e-05 5.108714e-05\n\n[[62]]\n[1] 9.360890e-05 1.062678e-04 1.320269e-04 9.201600e-05 1.156307e-04\n[6] 6.087272e-05\n\n[[63]]\n[1] 1.023839e-04 1.156307e-04 5.287764e-05 4.047452e-05 6.619029e-05\n[6] 3.620195e-05 9.994772e-05\n\n[[64]]\n[1] 5.287764e-05 8.616137e-05 5.274538e-05 6.005288e-05\n\n[[65]]\n[1] 4.047452e-05 8.616137e-05 5.965942e-05 1.524056e-04\n\n[[66]]\n[1] 5.274538e-05 5.965942e-05\n\n[[67]]\n[1] 7.698649e-05 8.676092e-05 6.087272e-05 6.619029e-05 7.655740e-05\n\n[[68]]\n[1] 6.386761e-05 4.522313e-05 5.914874e-05 7.834800e-05 3.620195e-05\n[6] 1.524056e-04\n\n[[69]]\n[1] 9.994772e-05 6.005288e-05 7.655740e-05\n\n[[70]]\n[1] 4.117989e-05 5.885227e-05 6.155251e-05 4.225974e-05\n\n[[71]]\n[1] 4.117989e-05 5.953357e-05 4.110606e-05\n\n[[72]]\n[1] 5.885227e-05 5.899804e-05 4.000195e-05 8.692110e-05 8.457300e-05\n\n[[73]]\n[1] 6.155251e-05 5.953357e-05 5.899804e-05 6.741263e-05\n\n[[74]]\n[1] 7.105006e-05 4.110606e-05 4.000195e-05 6.741263e-05 3.789103e-05\n\n[[75]]\n[1] 6.579843e-05 5.812114e-05 4.225974e-05 8.692110e-05 7.172077e-05\n[6] 1.056880e-04 5.465069e-05\n\n[[76]]\n[1] 9.420908e-05 6.810787e-05 1.070876e-04 5.108714e-05 8.457300e-05\n[6] 3.789103e-05 7.172077e-05\n\n[[77]]\n[1] 4.958860e-05 4.881437e-05 7.004105e-05 6.324110e-05\n\n[[78]]\n[1] 1.036058e-04 7.827893e-05 1.056880e-04 7.004105e-05 5.420721e-05\n\n[[79]]\n[1] 5.465069e-05 6.324110e-05 5.420721e-05\n\n\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\n\nNote on style argument\n\n\nNote: For simplicity, we’ll use the style=“W” option in this example, but be aware that more robust options, such as style=“B”, are available.\n\n\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 438 \nPercentage nonzero weights: 7.018106 \nAverage number of links: 5.544304 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0      S1       S2\nW 79 6241 79 29.8143 321.0615\n\n\nSetting the argument zero.policy to TRUE allows for lists of non-neighbors. This should be used with caution as users may not be aware of missing neighbors in their data however setting zero,policy to FALSE would return an error.\nThe code chunk below is implemented to check the weights of the first polygons eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\nUsing the same method, we derive a row standardized distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 438 \nPercentage nonzero weights: 7.018106 \nAverage number of links: 5.544304 \n\nWeights style: B \nWeights constants summary:\n   n   nn         S0           S1           S2\nB 79 6241 0.07702966 4.057545e-05 0.0004441685\n\n\nWe now compute the average neighbor Accident count value for each polygon. We often refer to these values as Spatially Lagged Values.\n\nacc.lag &lt;- lag.listw(rswm_q, boundary_with_accident_count$accident_count)\nacc.lag\n\n [1]   3.375000  42.750000 440.750000  10.800000 141.000000 115.333333\n [7]  12.500000  10.600000 222.500000 400.600000 351.714286 123.000000\n[13]  10.800000  39.600000  30.714286  90.400000  58.375000   5.166667\n[19] 162.428571  94.400000 239.600000 144.857143 299.600000 136.333333\n[25]  84.333333  73.500000 206.400000  41.500000  72.142857  57.222222\n[31]  40.800000 350.000000 116.333333 163.333333  76.333333 203.333333\n[37]  27.833333  60.166667  53.833333 258.000000 119.166667 240.250000\n[43] 157.400000 311.428571  34.333333 241.000000 366.800000 190.666667\n[49] 212.000000 234.857143 324.200000 540.500000 444.500000  86.875000\n[55] 261.750000 626.333333 112.571429 223.857143 115.200000 124.600000\n[61] 120.200000 120.000000 290.428571 149.750000 348.000000 523.000000\n[67] 135.800000 165.500000 291.000000 121.500000 125.333333 140.600000\n[73] 133.250000  67.600000 190.285714 206.000000 138.250000 262.400000\n[79] 390.666667\n\n\nWe can retrieve the Accident count for each by using the code Chunk Below.\n\nnb1 &lt;- wm_q[[1]] #Shows the accident counts for the neighboring districts of region 1\nnb1 &lt;- boundary_with_accident_count$accident_count[nb1]\nnb1\n\n[1]  0  0  0  2  0  1  1 23\n\n\n\nA spatial lag with row-standardized weights means that each observation’s value is influenced by the average values of its neighboring observations. Specifically, the weights are standardized so that the sum of the weights for each observation equals one.\nThis approach ensures that the spatial lag is essentially the weighted average of the neighboring values.\n\nWe can append the spatially lagged Accident values onto the boundary_with_accident_count sf data-frame by using the code chunk shown below.\n\nlag.list &lt;- list(boundary_with_accident_count$ADM2_EN.x, lag.listw(rswm_q, boundary_with_accident_count$accident_count))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"ADM2_EN.x\", \"lag Accident Count\")\nboundary_with_accident_count &lt;- left_join(boundary_with_accident_count,lag.res)\n\nWe can gain further insight into this data-frame by implementing the head() function.\n\nhead(boundary_with_accident_count)\n\nSimple feature collection with 6 features and 22 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 660838.3 ymin: 1517063 xmax: 709544.6 ymax: 1542641\nProjected CRS: WGS 84 / UTM zone 47N\n  Shape_Leng   Shape_Area   ADM2_EN.x ADM2_TH ADM2_PCODE ADM2_REF ADM2ALT1EN\n1 0.08541733 0.0004504685 Phra Nakhon  พระนคร     TH1001     &lt;NA&gt;       &lt;NA&gt;\n2 0.13413177 0.0009501914       Dusit     ดุสิต     TH1002     &lt;NA&gt;       &lt;NA&gt;\n3 0.67634217 0.0198588627   Nong Chok หนองจอก     TH1003     &lt;NA&gt;       &lt;NA&gt;\n4 0.08588647 0.0003369561    Bang Rak   บางรัก     TH1004     &lt;NA&gt;       &lt;NA&gt;\n5 0.30172202 0.0034149298   Bang Khen  บางเขน     TH1005     &lt;NA&gt;       &lt;NA&gt;\n6 0.30869124 0.0023032680   Bang Kapi  บางกะปิ     TH1006     &lt;NA&gt;       &lt;NA&gt;\n  ADM2ALT2EN ADM2ALT1TH ADM2ALT2TH ADM1_EN      ADM1_TH ADM1_PCODE  ADM0_EN\n1       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n2       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n3       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n4       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n5       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n6       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Bangkok กรุงเทพมหานคร       TH10 Thailand\n    ADM0_TH ADM0_PCODE       date    validOn    validTo ADM2_EN.y\n1 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30      &lt;NA&gt;\n2 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30      &lt;NA&gt;\n3 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30 Nong Chok\n4 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30  Bang Rak\n5 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30 Bang Khen\n6 ประเทศไทย         TH 2019-02-18 2022-01-22 -001-11-30 Bang Kapi\n  accident_count lag Accident Count                       geometry\n1              0             3.3750 MULTIPOLYGON (((662263.2 15...\n2              0            42.7500 MULTIPOLYGON (((664304.4 15...\n3             60           440.7500 MULTIPOLYGON (((706774.6 15...\n4              8            10.8000 MULTIPOLYGON (((664040.2 15...\n5            126           141.0000 MULTIPOLYGON (((673966.4 15...\n6             10           115.3333 MULTIPOLYGON (((676080.6 15...\n\n\nWe now plot the observed Accident and Spatial Lag Accidents side by side for comparison.\n\nacc_qtm &lt;- qtm(boundary_with_accident_count, \"accident_count\")\nlag_acc &lt;- qtm(boundary_with_accident_count, \"lag Accident Count\")\ntmap_arrange(acc_qtm, lag_acc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nThe use of spatial weights are highly useful for a variety of reasons.\n\nThey allow us to better understand and analyze the dependence between neighboring regions.\nThe help us understand how accidents are not isolated incidents and are often a part of bigger spatial patterns. This allows us to make better decisions with regards to policy developments, resource allocation and more in order to reduce the number of accidents.\nThese help us identify clusters and are crucial in identifying ‘spillover’ effects.\n\n\n\n\n\n1.4.3.5 Spatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we use the include.self() function from the spdep package.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 517 \nPercentage nonzero weights: 8.283929 \nAverage number of links: 6.544304 \n\n\nThere is a difference in the key statistics shown above when compared to wm_q. The average number of links, the number of non-zero links as well as percentage of non-zero weights are all higher for wm_qs.\nWe look at the neighbor list of area [1] using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  8 13 15 16 18 20 25\n\n\nThis region has 9 neighbors.\nWe now implement the nb2listw() function in order to obtain weights.\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 517 \nPercentage nonzero weights: 8.283929 \nAverage number of links: 6.544304 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 79 6241 79 24.99173 318.4378\n\n\nWe now create the lag variable from our weight structure and accident_count variable.\n\nlag_w_avg_acc &lt;- lag.listw(wm_qs, \n                             boundary_with_accident_count$accident_count)\nlag_w_avg_acc\n\n [1]   3.000000  38.000000 364.600000  10.333333 139.333333 100.285714\n [7]  16.111111   8.833333 191.571429 345.833333 423.500000 125.500000\n[13]   9.000000  46.666667  27.125000  75.333333  55.000000   4.571429\n[19] 198.000000  78.833333 245.166667 127.000000 249.666667 124.714286\n[25]  75.571429  60.000000 174.833333  36.714286  64.125000  66.500000\n[31]  36.166667 377.714286 106.000000 163.714286  86.000000 184.285714\n[37]  28.714286  60.857143  47.000000 268.333333 106.571429 225.000000\n[43] 205.333333 320.750000  33.250000 233.142857 319.000000 269.285714\n[49] 181.000000 218.000000 312.333333 515.800000 457.571429 132.222222\n[55] 228.000000 581.500000 119.625000 202.125000 115.833333 143.500000\n[61] 110.000000 130.285714 270.125000 252.000000 355.400000 356.666667\n[67] 127.166667 224.571429 233.750000 146.200000 114.500000 134.833333\n[73] 112.800000  73.000000 199.875000 187.750000 277.600000 230.333333\n[79] 320.500000\n\n\nWe then proceed to convert the lag variable listwobject into a data-frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(boundary_with_accident_count$ADM2_EN.x, lag.listw(wm_qs, boundary_with_accident_count$accident_count))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"ADM2_EN.x\", \"lag_window_avg acc\")\n\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into accident_count and lag_window_avg acc respectively.\n\nWe now append the lag_window_avg acc values onto the boundary_with_accident_count sf data.frame by using left_join() of dplyr package.\n\nboundary_with_accident_count &lt;- left_join(boundary_with_accident_count, lag_wm_qs.res)\n\nTo compare the values of lag accident count and Spatial window average, The kable() function of the Knitr package is used to prepare a table.\n\nboundary_with_accident_count %&gt;%\n  dplyr::select(\"ADM2_EN.x\", \n         \"lag Accident Count\", \n         \"lag_window_avg acc\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nADM2_EN.x\nlag Accident Count\nlag_window_avg acc\ngeometry\n\n\n\n\nPhra Nakhon\n3.375000\n3.000000\nMULTIPOLYGON (((662263.2 15…\n\n\nDusit\n42.750000\n38.000000\nMULTIPOLYGON (((664304.4 15…\n\n\nNong Chok\n440.750000\n364.600000\nMULTIPOLYGON (((706774.6 15…\n\n\nBang Rak\n10.800000\n10.333333\nMULTIPOLYGON (((664040.2 15…\n\n\nBang Khen\n141.000000\n139.333333\nMULTIPOLYGON (((673966.4 15…\n\n\nBang Kapi\n115.333333\n100.285714\nMULTIPOLYGON (((676080.6 15…\n\n\nPathum Wan\n12.500000\n16.111111\nMULTIPOLYGON (((664236.5 15…\n\n\nPom Prap Sattru Phai\n10.600000\n8.833333\nMULTIPOLYGON (((663880.5 15…\n\n\nPhra Khanong\n222.500000\n191.571429\nMULTIPOLYGON (((674748.8 15…\n\n\nMin Buri\n400.600000\n345.833333\nMULTIPOLYGON (((694735.5 15…\n\n\nLat Krabang\n351.714286\n423.500000\nMULTIPOLYGON (((694497.3 15…\n\n\nYan Nawa\n123.000000\n125.500000\nMULTIPOLYGON (((667818.3 15…\n\n\nSamphanthawong\n10.800000\n9.000000\nMULTIPOLYGON (((663592.4 15…\n\n\nPhaya Thai\n39.600000\n46.666667\nMULTIPOLYGON (((667624 1525…\n\n\nThon Buri\n30.714286\n27.125000\nMULTIPOLYGON (((661364.9 15…\n\n\nBangkok Yai\n90.400000\n75.333333\nMULTIPOLYGON (((660991.6 15…\n\n\nHuai Khwang\n58.375000\n55.000000\nMULTIPOLYGON (((671695.6 15…\n\n\nKhlong San\n5.166667\n4.571429\nMULTIPOLYGON (((662113.2 15…\n\n\nTaling Chan\n162.428571\n198.000000\nMULTIPOLYGON (((654587 1526…\n\n\nBangkok Noi\n94.400000\n78.833333\nMULTIPOLYGON (((659654.1 15…\n\n\nBang Khun Thian\n239.600000\n245.166667\nMULTIPOLYGON (((656541 1512…\n\n\nPhasi Charoen\n144.857143\n127.000000\nMULTIPOLYGON (((654370 1519…\n\n\nNong Khaem\n299.600000\n249.666667\nMULTIPOLYGON (((647001.3 15…\n\n\nRat Burana\n136.333333\n124.714286\nMULTIPOLYGON (((661132.1 15…\n\n\nBang Phlat\n84.333333\n75.571429\nMULTIPOLYGON (((663052.9 15…\n\n\nDin Daeng\n73.500000\n60.000000\nMULTIPOLYGON (((670238.2 15…\n\n\nBueng Kum\n206.400000\n174.833333\nMULTIPOLYGON (((678184.5 15…\n\n\nSathon\n41.500000\n36.714286\nMULTIPOLYGON (((667917.7 15…\n\n\nBang Sue\n72.142857\n64.125000\nMULTIPOLYGON (((666275.4 15…\n\n\nChatuchak\n57.222222\n66.500000\nMULTIPOLYGON (((671471.4 15…\n\n\nBang Kho Laem\n40.800000\n36.166667\nMULTIPOLYGON (((664335.2 15…\n\n\nPrawet\n350.000000\n377.714286\nMULTIPOLYGON (((680695.6 15…\n\n\nKhlong Toei\n116.333333\n106.000000\nMULTIPOLYGON (((673075.4 15…\n\n\nSuan Luang\n163.333333\n163.714286\nMULTIPOLYGON (((677751.8 15…\n\n\nChom Thong\n76.333333\n86.000000\nMULTIPOLYGON (((658696.5 15…\n\n\nDon Mueang\n203.333333\n184.285714\nMULTIPOLYGON (((674339.8 15…\n\n\nRatchathewi\n27.833333\n28.714286\nMULTIPOLYGON (((667199.4 15…\n\n\nLat Phrao\n60.166667\n60.857143\nMULTIPOLYGON (((673842.9 15…\n\n\nVadhana\n53.833333\n47.000000\nMULTIPOLYGON (((668704.8 15…\n\n\nBang Khae\n258.000000\n268.333333\nMULTIPOLYGON (((647693 1520…\n\n\nLak Si\n119.166667\n106.571429\nMULTIPOLYGON (((671045.4 15…\n\n\nSai Mai\n240.250000\n225.000000\nMULTIPOLYGON (((679686.2 15…\n\n\nKhan Na Yao\n157.400000\n205.333333\nMULTIPOLYGON (((680806.2 15…\n\n\nSaphan Sung\n311.428571\n320.750000\nMULTIPOLYGON (((685556.9 15…\n\n\nWang Thonglang\n34.333333\n33.250000\nMULTIPOLYGON (((671782.5 15…\n\n\nKhlong Sam Wa\n241.000000\n233.142857\nMULTIPOLYGON (((693668.9 15…\n\n\nBang Na\n366.800000\n319.000000\nMULTIPOLYGON (((675501.8 15…\n\n\nThawi Watthana\n190.666667\n269.285714\nMULTIPOLYGON (((650687.8 15…\n\n\nThung Khru\n212.000000\n181.000000\nMULTIPOLYGON (((660699.8 15…\n\n\nBang Bon\n234.857143\n218.000000\nMULTIPOLYGON (((656343.6 15…\n\n\nMueang Samut Prakan\n324.200000\n312.333333\nMULTIPOLYGON (((673201.8 15…\n\n\nBang Bo\n540.500000\n515.800000\nMULTIPOLYGON (((712294.1 15…\n\n\nBang Phli\n444.500000\n457.571429\nMULTIPOLYGON (((687139.8 15…\n\n\nPhra Pradaeng\n86.875000\n132.222222\nMULTIPOLYGON (((670827.4 15…\n\n\nPhra Samut Chedi\n261.750000\n228.000000\nMULTIPOLYGON (((669191.5 15…\n\n\nBang Sao Thong\n626.333333\n581.500000\nMULTIPOLYGON (((695481.3 15…\n\n\nMueang Nonthaburi\n112.571429\n119.625000\nMULTIPOLYGON (((662112.2 15…\n\n\nBang Kruai\n223.857143\n202.125000\nMULTIPOLYGON (((654095.9 15…\n\n\nBang Yai\n115.200000\n115.833333\nMULTIPOLYGON (((649983.7 15…\n\n\nBang Bua Thong\n124.600000\n143.500000\nMULTIPOLYGON (((649993.4 15…\n\n\nSai Noi\n120.200000\n110.000000\nMULTIPOLYGON (((644817.9 15…\n\n\nPak Kret\n120.000000\n130.285714\nMULTIPOLYGON (((652378.8 15…\n\n\nMueang Pathum Thani\n290.428571\n270.125000\nMULTIPOLYGON (((672162.5 15…\n\n\nKhlong Luang\n149.750000\n252.000000\nMULTIPOLYGON (((689473.3 15…\n\n\nThanyaburi\n348.000000\n355.400000\nMULTIPOLYGON (((706757.7 15…\n\n\nNong Suea\n523.000000\n356.666667\nMULTIPOLYGON (((704086 1575…\n\n\nLat Lum Kaeo\n135.800000\n127.166667\nMULTIPOLYGON (((650538.8 15…\n\n\nLam Luk Ka\n165.500000\n224.571429\nMULTIPOLYGON (((706764.9 15…\n\n\nSam Khok\n291.000000\n233.750000\nMULTIPOLYGON (((665864.3 15…\n\n\nMueang Nakhon Pathom\n121.500000\n146.200000\nMULTIPOLYGON (((602747 1541…\n\n\nKamphaeng Saen\n125.333333\n114.500000\nMULTIPOLYGON (((612428.1 15…\n\n\nNakhon Chai Si\n140.600000\n134.833333\nMULTIPOLYGON (((627397.1 15…\n\n\nDon Tum\n133.250000\n112.800000\nMULTIPOLYGON (((620292.6 15…\n\n\nBang Len\n67.600000\n73.000000\nMULTIPOLYGON (((631987.6 15…\n\n\nSam Phran\n190.285714\n199.875000\nMULTIPOLYGON (((636176.3 15…\n\n\nPhutthamonthon\n206.000000\n187.750000\nMULTIPOLYGON (((637713.4 15…\n\n\nMueang Samut Sakhon\n138.250000\n277.600000\nMULTIPOLYGON (((646615.4 15…\n\n\nKrathum Baen\n262.400000\n230.333333\nMULTIPOLYGON (((641549.1 15…\n\n\nBan Phaeo\n390.666667\n320.500000\nMULTIPOLYGON (((625054.6 15…\n\n\n\n\n\nWe now plot the lag accident count and w_ave_acc maps next to each other for comparison using the qtm() function of the tmap package.\n\nw_avg_acc &lt;- qtm(boundary_with_accident_count, \"lag_window_avg acc\")\ntmap_arrange(lag_acc, w_avg_acc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nequal &lt;- tm_shape(boundary_with_accident_count) +\n  tm_fill(\"accident_count\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(boundary_with_accident_count) +\n  tm_fill(\"accident_count\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#spatial-autocorrelation-morans-i-test.",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#spatial-autocorrelation-morans-i-test.",
    "title": "Take Home Exercise 1",
    "section": "1.4.4 Spatial Autocorrelation: Morans I test.",
    "text": "1.4.4 Spatial Autocorrelation: Morans I test.\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar number of accidents are randomly distributed.\nH1: Regions with similar number of accidents are not randomly distributed and exhibit spatial clustering.\n\n\nmoran.test(boundary_with_accident_count$accident_count, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  boundary_with_accident_count$accident_count  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 3.7964, p-value = 7.34e-05\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.235764728      -0.012820513       0.004287482 \n\n\nFrom the output above, we can infer the following:\n\nThe p-value (7.34e-05)&lt;0.05, indicating that the observed spatial autocorrelation is statistically significant.\nMoran’s I statistic: The observed value of 0.236 indicates positive spatial autocorrelation, meaning that regions with similar number of accidents are more likely to be located near each other.\n\nSince Moran’s I Statistic is significantly greater than what we would expect in a randomly distributed region. There is significant evidence to reject H0 and conclude that there is indeed spatial clustering with regards to Accidents in the Bangkok Metropolitan Region.\n\n1.4.4.1 Monte Carlo Moran’s I\nWe now implement the moran.mc() function of the spdep package. In this scenario, we will run 1000 simulations.\n\nbperm= moran.mc(boundary_with_accident_count$accident_count, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  boundary_with_accident_count$accident_count \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.23576, observed rank = 999, p-value = 0.001\nalternative hypothesis: greater\n\n\nBased on the above output, p-value (0.001)&lt;0.05, thus we can reject the null hypothesis at a 5% significance level and conclude that there is indeed spatial clustering.\n\n\n1.4.4.2 Visualizing Monte Carlo Moran’s I\nWe can visualize the test statistics obtained from the simulation above by implementing the hist() and abline() functions of R graphics.\n\nSummary StatisticsThe plotggplot method\n\n\nWe first calculate the mean and variance, and obtain the summary statistics.\n\nmean(bperm$res[1:999])\n\n[1] -0.01744349\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004001047\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.19669 -0.06142 -0.02135 -0.01744  0.02088  0.30376 \n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\nFrom the above, we can infer that over half of all simulations indicate a negative value for Moran’s I statistic. Generally, a negative value indicates that dissimilar regions are located next to each other. (i.e: regions with dissimilar number of Accidents are located next to each other)\n\n\nWe can also make use of the ggplot2 R package to produce a plot.\n\ndata &lt;- data.frame(simulated_moran = bperm$res)\n\nggplot(data, aes(x = simulated_moran)) +\n  geom_histogram(binwidth = (max(data$simulated_moran) - min(data$simulated_moran)) / 20, \n                 fill = \"lightblue\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Simulated Moran's I\", \n       y = \"Frequency\",\n       title = \"Histogram of Simulated Moran's I\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.4.3 Local Morans I\nWe implement the localmoran() function of spdep compute the local Moran’s I statistic. This function helps us compute li values, given a set of zi values and a listw object providing neighbor weighting information for the polygon associated with the zi values.\nWe compute local Moran’s I of accident_count at the district level.\n\nfips &lt;- order(boundary_with_accident_count$accident_count)\nlocalMI &lt;- localmoran(boundary_with_accident_count$accident_count, rswm_q)\nhead(localMI)\n\n           Ii          E.Ii      Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.60429563 -0.0079097813 0.070446604  2.3065726    0.021078658\n2  0.45651029 -0.0079097813 0.070446604  1.7497699    0.080158019\n3 -0.65867321 -0.0031893365 0.060342196 -2.6684032    0.007621273\n4  0.54837408 -0.0071586128 0.106462820  1.7025922    0.088644413\n5  0.02048823 -0.0004311934 0.003869271  0.3363063    0.736639872\n6  0.17288609 -0.0069766753 0.085295392  0.6158550    0.537990224\n\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nWe now use the printCoefmat() to display the content of the local Moran matrix that we created above.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=boundary_with_accident_count$ADM2_EN.x[fips]),\n  check.names=FALSE)\n\n                              Ii        E.Ii      Var.Ii        Z.Ii\nPhra Nakhon           6.0430e-01 -7.9098e-03  7.0447e-02  2.3066e+00\nDusit                 4.5651e-01 -7.9098e-03  7.0447e-02  1.7498e+00\nPom Prap Sattru Phai  5.7718e-01 -7.9098e-03  1.1755e-01  1.7065e+00\nSamphanthawong        5.7643e-01 -7.9098e-03  1.1755e-01  1.7044e+00\nBangkok Yai           2.7767e-01 -7.9098e-03  1.1755e-01  8.3295e-01\nNong Khaem           -5.0752e-01 -7.9098e-03  1.1755e-01 -1.4572e+00\nKhlong San            5.9394e-01 -7.8138e-03  9.5450e-02  1.9477e+00\nBangkok Noi           2.6106e-01 -7.8138e-03  1.1613e-01  7.8898e-01\nThon Buri             4.9558e-01 -7.7185e-03  7.9701e-02  1.7828e+00\nPhasi Charoen         7.2382e-02 -7.7185e-03  7.9701e-02  2.8373e-01\nPhra Khanong         -2.1018e-01 -7.3429e-03  8.9740e-02 -6.7710e-01\nDin Daeng             3.2865e-01 -7.3429e-03  1.3835e-01  9.0331e-01\nVadhana               3.9977e-01 -7.3429e-03  8.9740e-02  1.3590e+00\nBang Rak              5.4837e-01 -7.1586e-03  1.0646e-01  1.7026e+00\nSathon                4.3876e-01 -7.1586e-03  8.7504e-02  1.5074e+00\nBang Sue              3.2934e-01 -7.1586e-03  7.3961e-02  1.2373e+00\nBang Kapi             1.7289e-01 -6.9767e-03  8.5295e-02  6.1586e-01\nBang Kho Laem         4.2715e-01 -6.7082e-03  9.9809e-02  1.3733e+00\nBueng Kum            -1.4140e-01 -6.3583e-03  9.4637e-02 -4.3898e-01\nBang Phlat            2.5840e-01 -5.8512e-03  7.1616e-02  9.8744e-01\nNong Suea            -1.1495e+00 -5.7687e-03  2.2361e-01 -2.4187e+00\nThung Khru           -1.5046e-01 -5.6055e-03  8.3495e-02 -5.0131e-01\nHuai Khwang           3.3009e-01 -5.4446e-03  4.8612e-02  1.5219e+00\nWang Thonglang        3.9902e-01 -5.2861e-03  1.3487e-01  1.1009e+00\nLak Si                1.3769e-01 -5.2077e-03  6.3782e-02  5.6584e-01\nDon Tum               9.4804e-02 -5.2077e-03  9.8330e-02  3.1894e-01\nRatchathewi           4.0649e-01 -4.9761e-03  6.0959e-02  1.6665e+00\nKhlong Toei           1.3206e-01 -4.2420e-03  5.2005e-02  5.9770e-01\nPathum Wan            4.1399e-01 -4.1719e-03  3.7296e-02  2.1653e+00\nBang Kruai           -1.5533e-01 -3.8297e-03  3.9701e-02 -7.6037e-01\nRat Burana            7.0045e-02 -3.5022e-03  4.2967e-02  3.5481e-01\nSai Noi               1.0630e-01 -3.2507e-03  4.8535e-02  4.9727e-01\nNong Chok            -6.5867e-01 -3.1893e-03  6.0342e-02 -2.6684e+00\nPhutthamonthon       -9.9194e-02 -3.1893e-03  3.3083e-02 -5.2782e-01\nSam Khok             -2.9599e-01 -3.0683e-03  7.8458e-02 -1.0458e+00\nLat Phrao             2.3647e-01 -2.8911e-03  3.5491e-02  1.2706e+00\nDon Mueang           -8.3944e-02 -2.6075e-03  3.2019e-02 -4.5455e-01\nKrathum Baen         -2.1123e-01 -2.6075e-03  3.8957e-02 -1.0570e+00\nMin Buri             -4.9826e-01 -2.4982e-03  3.7327e-02 -2.5660e+00\nBang Na              -3.8999e-01 -2.0842e-03  3.1155e-02 -2.1977e+00\nPhaya Thai            2.3471e-01 -1.9866e-03  2.9698e-02  1.3735e+00\nKamphaeng Saen        7.3445e-02 -1.9866e-03  5.0854e-02  3.3450e-01\nLat Lum Kaeo          5.2453e-02 -1.8913e-03  2.8277e-02  3.2317e-01\nPhra Samut Chedi     -1.5870e-01 -1.4915e-03  2.8267e-02 -9.3503e-01\nBang Bon             -1.0360e-01 -1.2133e-03  1.2611e-02 -9.1175e-01\nBang Len              1.4226e-01 -1.2133e-03  1.8152e-02  1.0649e+00\nNakhon Chai Si        3.1698e-02 -9.9768e-04  1.4930e-02  2.6759e-01\nBan Phaeo            -2.8097e-01 -8.6565e-04  2.2184e-02 -1.8806e+00\nBang Yai              5.0958e-02 -6.0283e-04  9.0244e-03  5.4276e-01\nBang Khen             2.0488e-02 -4.3119e-04  3.8693e-03  3.3631e-01\nMueang Pathum Thani  -1.0470e-01 -3.8742e-04  4.0301e-03 -1.6432e+00\nYan Nawa              2.4924e-02 -2.0371e-04  3.0508e-03  4.5494e-01\nChom Thong            4.0971e-02 -1.2158e-04  1.4967e-03  1.0622e+00\nChatuchak             3.5183e-02 -6.0530e-05  4.7609e-04  1.6152e+00\nSai Mai              -6.5785e-04 -4.2214e-08  8.0124e-07 -7.3488e-01\nSuan Luang           -3.8712e-05 -7.6848e-07  9.4613e-06 -1.2336e-02\nMueang Nonthaburi    -5.4655e-03 -6.2488e-06  6.5027e-05 -6.7699e-01\nKhlong Sam Wa         3.7824e-02 -1.3683e-04  1.6844e-03  9.2494e-01\nPak Kret             -2.7988e-02 -2.2332e-04  2.7488e-03 -5.2957e-01\nBang Bua Thong       -6.6869e-02 -1.5866e-03  2.3728e-02 -4.2380e-01\nMueang Nakhon Pathom -7.8933e-02 -1.9026e-03  3.6044e-02 -4.0574e-01\nMueang Samut Prakan   3.2339e-01 -2.2990e-03  3.4358e-02  1.7571e+00\nSam Phran             6.0701e-02 -3.0827e-03  3.1981e-02  3.5667e-01\nBang Khun Thian       1.8656e-01 -3.4537e-03  5.1556e-02  8.3683e-01\nBang Khae             3.3266e-01 -7.0892e-03  1.0544e-01  1.0463e+00\nThanyaburi            9.2497e-01 -1.4248e-02  2.6658e-01  1.8191e+00\nSaphan Sung           7.4410e-01 -1.4378e-02  1.4747e-01  1.9751e+00\nBang Bo               2.1695e+00 -1.8681e-02  3.4795e-01  3.7095e+00\nKhan Na Yao          -4.4722e-02 -2.3052e-02  3.3734e-01 -3.7310e-02\nTaling Chan          -1.2591e-02 -2.3382e-02  2.3763e-01  2.2136e-02\nBang Sao Thong        2.9810e+00 -2.3382e-02  5.8570e-01  3.9257e+00\nPhra Pradaeng        -5.8509e-01 -3.1998e-02  2.7807e-01 -1.0489e+00\nBang Phli             2.3769e+00 -4.0427e-02  4.7760e-01  3.4978e+00\nPrawet                1.6089e+00 -4.2186e-02  4.9747e-01  2.3410e+00\nLam Luk Ka            1.0605e-02 -5.0323e-02  5.8839e-01  7.9431e-02\nKhlong Luang         -1.6589e-01 -7.2197e-02  1.2714e+00 -8.3095e-02\nThawi Watthana        3.4609e-01 -9.7330e-02  1.0817e+00  4.2635e-01\nMueang Samut Sakhon  -4.0011e-01 -1.3165e-01  2.1698e+00 -1.8225e-01\nLat Krabang           3.2578e+00 -1.6980e-01  1.4670e+00  2.8299e+00\n                     Pr.z....E.Ii..\nPhra Nakhon                  0.0211\nDusit                        0.0802\nPom Prap Sattru Phai         0.0879\nSamphanthawong               0.0883\nBangkok Yai                  0.4049\nNong Khaem                   0.1451\nKhlong San                   0.0514\nBangkok Noi                  0.4301\nThon Buri                    0.0746\nPhasi Charoen                0.7766\nPhra Khanong                 0.4983\nDin Daeng                    0.3664\nVadhana                      0.1741\nBang Rak                     0.0886\nSathon                       0.1317\nBang Sue                     0.2160\nBang Kapi                    0.5380\nBang Kho Laem                0.1697\nBueng Kum                    0.6607\nBang Phlat                   0.3234\nNong Suea                    0.0156\nThung Khru                   0.6162\nHuai Khwang                  0.1280\nWang Thonglang               0.2709\nLak Si                       0.5715\nDon Tum                      0.7498\nRatchathewi                  0.0956\nKhlong Toei                  0.5500\nPathum Wan                   0.0304\nBang Kruai                   0.4470\nRat Burana                   0.7227\nSai Noi                      0.6190\nNong Chok                    0.0076\nPhutthamonthon               0.5976\nSam Khok                     0.2957\nLat Phrao                    0.2039\nDon Mueang                   0.6494\nKrathum Baen                 0.2905\nMin Buri                     0.0103\nBang Na                      0.0280\nPhaya Thai                   0.1696\nKamphaeng Saen               0.7380\nLat Lum Kaeo                 0.7466\nPhra Samut Chedi             0.3498\nBang Bon                     0.3619\nBang Len                     0.2869\nNakhon Chai Si               0.7890\nBan Phaeo                    0.0600\nBang Yai                     0.5873\nBang Khen                    0.7366\nMueang Pathum Thani          0.1003\nYan Nawa                     0.6492\nChom Thong                   0.2882\nChatuchak                    0.1063\nSai Mai                      0.4624\nSuan Luang                   0.9902\nMueang Nonthaburi            0.4984\nKhlong Sam Wa                0.3550\nPak Kret                     0.5964\nBang Bua Thong               0.6717\nMueang Nakhon Pathom         0.6849\nMueang Samut Prakan          0.0789\nSam Phran                    0.7213\nBang Khun Thian              0.4027\nBang Khae                    0.2954\nThanyaburi                   0.0689\nSaphan Sung                  0.0483\nBang Bo                      0.0002\nKhan Na Yao                  0.9702\nTaling Chan                  0.9823\nBang Sao Thong               0.0001\nPhra Pradaeng                0.2942\nBang Phli                    0.0005\nPrawet                       0.0192\nLam Luk Ka                   0.9367\nKhlong Luang                 0.9338\nThawi Watthana               0.6698\nMueang Samut Sakhon          0.8554\nLat Krabang                  0.0047\n\n\n\n\n1.4.4.4 Mapping the local Moran’s I\nBefore we map the local Moran’s I map, it is wise to append the local Moran’s data-frame (localMI) onto our SpatialPolygonDataFrame.\n\nbmr.localMI &lt;- cbind(boundary_with_accident_count,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nWe now make use of the tmap package and its choropleth mapping functions to plot the local Moran’s I values.\n\ntm_shape(bmr.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nInterpreting Moran Value:\n\nValues lesser than 0 indicate negative spatial autocorrelation. (i.e: high accident areas are near low accident areas.)\nValue equal to 0 indicates random spatial distribution (No spatial autocorrelation).\nValues greater than 0 indicate spatial autocorrelation.\n\n\n\n\n1.4.4.5 Mapping Local Moran’s I p-values\nThe Choropleth reveals the presence of both positive, as well as negative I values. This indicates that there are varying levels of spatial autocorrelation, however, we must examine the p-values for these I values to check for statistical significance.\nWe use the tmap package to draw a choropleth map of Moran’s I p-values.\n\ntm_shape(bmr.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFrom the above we can infer that generally the local moran value ranges from -1 to 1. The biggest stand outs are:\n\nNong Suea, at the top right corner of the above map, seems to be absolutely dissimilar to its neighbors as indicated by its local Moran Value being of the highest magnitude. From our earlier analysis, we infer that this region actually has significantly fewer accidents than its neighbors.\nThe South-East region of the Bangkok Metropolitan Region has very high local Moran Values, indicating that the districts all showcase similar characteristics. They exhibit spatial clustering.\n\n\n\n1.4.4.6 Mapping both local Moran’s I values and p-values\nIn the interest of easier analysis and interpretation, we plot the two maps next to each other.\n\nlocalMI.map &lt;- tm_shape(bmr.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(bmr.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#hot-and-cold-spot-areas",
    "href": "Take-home_Ex/Take-home_Ex1/Take-home_Ex01.html#hot-and-cold-spot-areas",
    "title": "Take Home Exercise 1",
    "section": "1.4.5 Hot and Cold Spot Areas",
    "text": "1.4.5 Hot and Cold Spot Areas\n\n1.4.5.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistic used to detect spatial anomalies is the Getis-Ord G-statistic (Getis and Ord, 1972; Ord and Getis, 1995). This method examines spatial relationships within a defined proximity to identify clusters of high or low values. Statistically significant hotspots are areas where high values are spatially clustered, meaning that not only do these areas have high values, but their neighboring areas also exhibit similarly high values.\nThe analysis involves three key steps:\n\nDeriving the spatial weight matrix: This defines the spatial relationships between areas, specifying which locations are considered neighbors based on proximity.\nComputing the Gi statistic: This step calculates the G-statistic for each location, identifying regions where values are significantly higher or lower than expected.\nMapping the Gi statistics: The results are visualized to reveal spatial patterns of high-value clusters (hotspots) and low-value clusters (cold spots).\n\nThis approach is useful for identifying localized patterns of spatial clustering and detecting significant anomalies in the data.\n\n\n1.4.5.2 Deriving Distance Based Weight Matrix\nWe start by defining a new set of neighbors. While the spatial autocorrelation considered units which shared borders, for Getis-Ord, we will define the neighbors based on distance.\n\nThere are two types of distance-based proximity matrices:\n\nFixed Distance Weight Matrix\nAdaptive Distance Weight Matrix\n\n\nBefore creating our connectivity graph, we need to assign a point to each polygon. This requires more than simply running st_centroid() on the us.bound spatial object. Specifically, we need to extract the coordinates into a separate data frame. We have already done this earlier and stored them under the name coords.\nMapping functions apply a specific operation to each element of a vector and return a vector of the same length. In our case, the input vector will be the geometry column from us.bound, and the function we’ll apply is st_centroid(). We’ll use the map_dbl variation from the purrr package, which is designed to return numeric (double) values.\nTo extract the longitude values, we’ll map the st_centroid() function over the geometry column and use double bracket notation [[]] with 1 to access the first element of each centroid, which corresponds to the longitude.\nFor more detailed information, you can refer to the map documentation here.\n\n1.4.5.2.1 Determine the Cut-off Distance\nTo determine the upper limit for the distance band, we follow these steps:\n\nFind the k-nearest neighbors: Use the knearneigh() function from the spdep package. This function returns a matrix that contains the indices of points corresponding to the k-nearest neighbors for each observation.\nConvert to a neighbors list: Take the k-nearest neighbors object returned by knearneigh() and convert it into a neighbors list (class nb) by using the knn2nb() function. This generates a list of integer vectors, where each vector contains the region numbers corresponding to its neighbors.\nCalculate neighbor distances: Use the nbdists() function from spdep to calculate the distances between neighbors. The function returns the lengths of neighbor relationship edges in the units of the coordinates (e.g., kilometers if the coordinates are geographic).\nFlatten the distance list: The distances returned by nbdists() are stored in a list. Use the unlist() function to remove the list structure and return a single vector of distances.\n\nThis process helps identify the upper limit for a distance band by analyzing the distances between neighboring regions.\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = FALSE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1390    2805    4986    6259    8476   16797 \n\n\nFrom the above output, we can infer that the largest first-nearest neighbor distance is just under 17000M.\nUsing this as the upper threshold gives certainty that all units will have at least one neighbor.\n\n\n1.4.5.2.2 Computing fixed distance weight matrix\nWe implement the dnearneigh() function of the spdep package to compute the distance weight matrix.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 17000, longlat = FALSE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 1766 \nPercentage nonzero weights: 28.29675 \nAverage number of links: 22.35443 \n\n\nAfter this, we implement the nb2listw() function to convert the nb object into spatial weights object.\nOn average, each region has approximately 22.3neighbors.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 79 \nNumber of nonzero links: 1766 \nPercentage nonzero weights: 28.29675 \nAverage number of links: 22.35443 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 19 20 21 22 23 25 26 27 29 31 32 \n 3  5  3  6  1  2  1  2  2  1  1  1  1  1  3  1  1  1  2  1  2  1  1  2  2  1 \n33 34 35 36 37 38 39 40 41 42 \n 1  1  5  1  4  4  8  4  1  2 \n3 least connected regions:\n66 71 79 with 1 link\n2 most connected regions:\n14 37 with 42 links\n\nWeights style: B \nWeights constants summary:\n   n   nn   S0   S1     S2\nB 79 6241 1766 3532 226656\n\n\n\n\n\n1.4.5.3 Computing Gi statistics using Fixed Distance\n\nfips &lt;- order(boundary_with_accident_count$accident_count)\ngi.fixed &lt;- localG(boundary_with_accident_count$accident_count, wm62_lw)\ngi.fixed\n\n [1] -3.35336397 -3.12912595  2.66840322 -3.40300611 -1.55553377 -1.60535680\n [7] -3.49157140 -3.33512452 -2.30441253  1.39585137  2.02857406 -3.14674976\n[13] -3.17369454 -3.11393349 -2.81776564 -2.72683627 -2.88374141 -3.09409303\n[19] -3.12869158 -2.97426998 -1.24486361 -2.45871841 -0.73868252 -3.41408938\n[25] -2.89311199 -3.10698762 -1.21501813 -3.40300611 -3.97875100 -3.49579305\n[31] -3.68769474  0.40369815 -2.86023380 -2.45892382 -2.82195856 -0.92940375\n[37] -3.00458192 -2.79839385 -3.02803442 -2.34863826 -2.70055541 -0.22060572\n[43] -0.64115983  0.20224677 -3.19200023  1.40767563 -2.13429423 -2.10096499\n[49] -2.78620527 -1.47043641  1.55439452  2.25397760  3.05249557 -3.47654632\n[55] -0.01782564  4.36180044 -2.68397915 -2.21092597  0.65770388 -0.78671988\n[61] -0.20919415 -1.51459191 -0.54373150  0.45951200  2.18029716  1.04197980\n[67] -0.32317456  0.39447801  1.04576806 -0.64165535 -0.63894290 -0.13934645\n[73] -0.31893930 -0.81293378 -1.00959192  0.67569728 -0.47712106  2.54803258\n[79]  3.18220373\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)       Z(Gi) Pr(z != E(Gi))\n [1,] 0.272139227 0.51282051 0.0051513761 -3.35336397   7.983565e-04\n [2,] 0.288233482 0.51282051 0.0051513761 -3.12912595   1.753271e-03\n [3,] 0.136391769 0.05128205 0.0010173148  2.66840322   7.621273e-03\n [4,] 0.255432270 0.50000000 0.0051650300 -3.40300611   6.664879e-04\n [5,] 0.180171073 0.28205128 0.0042896392 -1.55553377   1.198190e-01\n [6,] 0.333924168 0.44871795 0.0051132094 -1.60535680   1.084153e-01\n [7,] 0.247971563 0.50000000 0.0052102341 -3.49157140   4.801881e-04\n [8,] 0.273448329 0.51282051 0.0051513761 -3.33512452   8.526121e-04\n [9,] 0.296456086 0.46153846 0.0051319328 -2.30441253   2.119950e-02\n[10,] 0.241985442 0.16666667 0.0029115761  1.39585137   1.627593e-01\n[11,] 0.224129353 0.12820513 0.0022360158  2.02857406   4.250169e-02\n[12,] 0.258016812 0.48717949 0.0053035095 -3.14674976   1.650962e-03\n[13,] 0.272139227 0.50000000 0.0051547652 -3.17369454   1.505120e-03\n[14,] 0.313468692 0.53846154 0.0052205800 -3.11393349   1.846111e-03\n[15,] 0.284889094 0.48717949 0.0051539569 -2.81776564   4.835909e-03\n[16,] 0.278838749 0.47435897 0.0051412089 -2.72683627   6.394476e-03\n[17,] 0.292251891 0.50000000 0.0051899304 -2.88374141   3.929813e-03\n[18,] 0.290720062 0.51282051 0.0051526678 -3.09409303   1.974156e-03\n[19,] 0.183188452 0.41025641 0.0052672775 -3.12869158   1.755865e-03\n[20,] 0.261070466 0.47435897 0.0051424981 -2.97426998   2.936866e-03\n[21,] 0.109258240 0.17948718 0.0031826485 -1.24486361   2.131819e-01\n[22,] 0.260782502 0.43589744 0.0050725786 -2.45871841   1.394339e-02\n[23,] 0.198059449 0.24358974 0.0037991399 -0.73868252   4.600998e-01\n[24,] 0.203309875 0.44871795 0.0051668746 -3.41408938   6.399558e-04\n[25,] 0.278947774 0.48717949 0.0051803995 -2.89311199   3.814453e-03\n[26,] 0.302696456 0.52564103 0.0051489035 -3.10698762   1.890043e-03\n[27,] 0.287300486 0.37179487 0.0048360434 -1.21501813   2.243592e-01\n[28,] 0.255432270 0.50000000 0.0051650300 -3.40300611   6.664879e-04\n[29,] 0.214054554 0.50000000 0.0051650300 -3.97875100   6.927825e-05\n[30,] 0.219772515 0.47435897 0.0053037027 -3.49579305   4.726551e-04\n[31,] 0.222076621 0.48717949 0.0051679573 -3.68769474   2.262949e-04\n[32,] 0.348255907 0.32051282 0.0047227618  0.40369815   6.864347e-01\n[33,] 0.268196569 0.47435897 0.0051953627 -2.86023380   4.233288e-03\n[34,] 0.270124805 0.44871795 0.0052752059 -2.45892382   1.393542e-02\n[35,] 0.244120853 0.44871795 0.0052565120 -2.82195856   4.773134e-03\n[36,] 0.139284608 0.19230769 0.0032547762 -0.92940375   3.526799e-01\n[37,] 0.322498456 0.53846154 0.0051664346 -3.00458192   2.659461e-03\n[38,] 0.247349276 0.44871795 0.0051780488 -2.79839385   5.135745e-03\n[39,] 0.282434515 0.50000000 0.0051624800 -3.02803442   2.461500e-03\n[40,] 0.181588505 0.34615385 0.0049095816 -2.34863826   1.884220e-02\n[41,] 0.138865303 0.32051282 0.0045243141 -2.70055541   6.922381e-03\n[42,] 0.179613165 0.19230769 0.0033113077 -0.22060572   8.253994e-01\n[43,] 0.251734311 0.29487179 0.0045266509 -0.64115983   5.214188e-01\n[44,] 0.295476190 0.28205128 0.0044061520  0.20224677   8.397238e-01\n[45,] 0.269990738 0.50000000 0.0051923603 -3.19200023   1.412912e-03\n[46,] 0.228125000 0.15384615 0.0027843582  1.40767563   1.592271e-01\n[47,] 0.246087091 0.39743590 0.0050286269 -2.13429423   3.281870e-02\n[48,] 0.123152307 0.25641026 0.0040229869 -2.10096499   3.564404e-02\n[49,] 0.144135802 0.33333333 0.0046111018 -2.78620527   5.332909e-03\n[50,] 0.174530498 0.26923077 0.0041477249 -1.47043641   1.414436e-01\n[51,] 0.137752297 0.07692308 0.0015314471  1.55439452   1.200903e-01\n[52,] 0.078208290 0.02564103 0.0005439157  2.25397760   2.419758e-02\n[53,] 0.259036145 0.11538462 0.0022146771  3.05249557   2.269471e-03\n[54,] 0.169802258 0.42307692 0.0053074689 -3.47654632   5.079165e-04\n[55,] 0.114558287 0.11538462 0.0021488926 -0.01782564   9.857780e-01\n[56,] 0.193237100 0.05128205 0.0010591808  4.36180044   1.289965e-05\n[57,] 0.205586331 0.39743590 0.0051093231 -2.68397915   7.275164e-03\n[58,] 0.217455164 0.37179487 0.0048731182 -2.21092597   2.704096e-02\n[59,] 0.174321909 0.14102564 0.0025628920  0.65770388   5.107284e-01\n[60,] 0.067540006 0.10256410 0.0019819543 -0.78671988   4.314459e-01\n[61,] 0.032644852 0.03846154 0.0007731295 -0.20919415   8.342967e-01\n[62,] 0.104971080 0.19230769 0.0033250748 -1.51459191   1.298758e-01\n[63,] 0.078550319 0.10256410 0.0019505280 -0.54373150   5.866262e-01\n[64,] 0.036267748 0.02564103 0.0005348167  0.45951200   6.458665e-01\n[65,] 0.100309499 0.03846154 0.0008046729  2.18029716   2.923544e-02\n[66,] 0.029702206 0.01282051 0.0002624904  1.04197980   2.974210e-01\n[67,] 0.052627500 0.06410256 0.0012607702 -0.32317456   7.465630e-01\n[68,] 0.064076731 0.05128205 0.0010519939  0.39447801   6.932282e-01\n[69,] 0.067548747 0.03846154 0.0007736300  1.04576806   2.956681e-01\n[70,] 0.010752688 0.02564103 0.0005383798 -0.64165535   5.210970e-01\n[71,] 0.002402356 0.01282051 0.0002658629 -0.63894290   5.228601e-01\n[72,] 0.046816770 0.05128205 0.0010268471 -0.13934645   8.891764e-01\n[73,] 0.041142416 0.05128205 0.0010107147 -0.31893930   7.497725e-01\n[74,] 0.006984324 0.02564103 0.0005266952 -0.81293378   4.162560e-01\n[75,] 0.018554918 0.05128205 0.0010508100 -1.00959192   3.126908e-01\n[76,] 0.117669813 0.08974359 0.0017081266  0.67569728   4.992329e-01\n[77,] 0.014813596 0.02564103 0.0005149838 -0.47712106   6.332759e-01\n[78,] 0.175209043 0.07692308 0.0014878977  2.54803258   1.083324e-02\n[79,] 0.064849332 0.01282051 0.0002673203  3.18220373   1.461590e-03\nattr(,\"cluster\")\n [1] Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[16] Low  Low  Low  High Low  High Low  Low  Low  Low  Low  Low  Low  Low  Low \n[31] Low  High Low  High Low  Low  Low  Low  Low  High Low  Low  High High Low \n[46] High Low  High Low  Low  High High High High Low  High High Low  Low  High\n[61] Low  High Low  High High Low  Low  High Low  High Low  Low  Low  Low  High\n[76] Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = boundary_with_accident_count$accident_count, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of the localG() function is a vector containing G or G* values, with the following attributes: - \"gstari\": Indicates whether the G* version of the statistic was used (TRUE or FALSE). - \"call\": Stores the function call. - \"class\": Set to \"localG\", identifying the object type.\nThe Gi statistic is represented as a Z-score, where larger values signify stronger clustering. The sign of the value indicates the type of cluster: positive values point to high-value clusters (hotspots), while negative values indicate low-value clusters (cold spots).\nTo merge the Gi values with their corresponding geographic data in the BMR spatial dataframe, use the following code to join the results to the boundary_with_accident_count sf object. This allows for the spatial visualization of clusters within the geographic data.\n\nbmr.gi &lt;- cbind(boundary_with_accident_count, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nthe code chunk above actually performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join bmr@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called bmr.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\nWe can now map the Gi values derived using the fixed-distance weight matrix.\n\nacc_count &lt;- qtm(boundary_with_accident_count, \"accident_count\")\n\nGimap &lt;-tm_shape(bmr.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(acc_count, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nFrom the above plot, we can infer that ‘hot spots’ tend to be neighboring regions and likewise for the cold spots too. We see more high value (hot) clusters in the South East region of the Bangkok Metropolitan Region- Near Samut Prakan. The Central Area, near Bangkok and Nonthaburi showcase more ‘cold spots’.\nDistricts Bang Phli, Bang Sao Thong, Bang Bo, Sinakharin, and Suwinthawong seem to be highly linked to each other based on accidents, all in the South-East region of the Bangkok Metropolitan Region."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "We now focus on Global Measures of Spatial Autocorrelation (GMSA) with the help of the spdep package. Through this exercise we:\n\ncompute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of spdep package,\n\nplot Moran scatterplot,\ncompute and plot spatial correlogram using appropriate function of spdep package.\n\nprovide statistically correct interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#performing-relational-join",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.3.1 Performing relational join",
    "text": "5.3.1 Performing relational join\nWe will update the attribute table of Hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data-frame. We can do this by using the left_join() function of the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.5.1 Computing Contiguity Spatial Weights",
    "text": "5.5.1 Computing Contiguity Spatial Weights\nBefore computing the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area, the spatial weights are used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe now implement the poly2nb() function of the spdep package to compute contiguity weight matrices for the study area selected.\nUsing this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.\nIn this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.\nYou may refer to the spdep package documentation here to learn more about its functions and arguments.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the output above, we can infer that there are 88 area units in total in Hunan. The most connected area unit has 11 neighbors. There are two area units with just 1 neighbor, while 24 area units have 5 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#row-standardized-weights-matrix",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.5.2 Row-Standardized Weights Matrix",
    "text": "5.5.2 Row-Standardized Weights Matrix\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nThe nb2listw() function requires an input of class nb, representing a neighborhood object. The function’s two key arguments are style and zero.policy.\n\nThe style argument defines how the weights are calculated. It can take several values:\n\n\"B\": Binary coding, where weights are either 0 or 1.\n\"W\": Row-standardized, where the sum of weights across all neighbors equals 1.\n\"C\": Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.\n\"U\": A variation of \"C\", where weights are normalized by the number of neighbors.\n\"S\": A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.\n\nThe zero.policy argument, when set to TRUE, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector x, effectively setting the lagged value to zero for those regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#marons-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#marons-i-test",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.1 Maron’s I test",
    "text": "5.6.1 Maron’s I test\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar GDP Per Capita are randomly distributed.\nH1: Regions with similar GDP Per Capita are not randomly distributed and exhibit spatial clustering.\n\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nFrom the output above, we can infer the following:\n\nThe p-value (1.095e-06)&lt;0.05, indicating that the observed spatial autocorrelation is statistically significant.\nMoran’s I statistic: The observed value of 0.3007 indicates positive spatial autocorrelation, meaning that regions with similar GDP Per Capita are more likely to be located near each other.\n\nSince Moran’s I Statistic is significantly greater than what we would expect in a randomly distributed region. There is significant evidence to reject H0 and conclude that there is indeed spatial clustering with regards to GDP Per Capita in Hunan."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-morans-i",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.2 Computing Monte Carlo Moran’s I",
    "text": "5.6.2 Computing Monte Carlo Moran’s I\nWe now implement the moran.mc() function of the spdep package. In this scenario, we will run 1000 simulations.\n\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nBased on the above output, p-value (0.001)&lt;0.05, thus we can reject the null hypothesis at a 5% significance level and conclude that there is indeed spatial clustering."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-morans-i",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.6.3 Visualizing Monte Carlo Moran’s I",
    "text": "5.6.3 Visualizing Monte Carlo Moran’s I\nWe can visualize the test statistics obtained from the simulation above by implementing the hist() and abline() functions of R graphics.\n\nSummary StatisticsThe Plotggplot2 method\n\n\nWe first calculate the mean and variance, and obtain the summary statistics.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\nFrom the above, we can infer that over half of all simulations indicate a negative value for Moran’s I statistic. Generally, a negative value indicates that dissimilar regions are located next to each other. (i.e: regions with dissimilar GDP Per Capita are located next to each other)\n\n\nWe can also use ggplot2 package to plot the above.\n\ndata &lt;- data.frame(simulated_moran = bperm$res)\n\nggplot(data, aes(x = simulated_moran)) +\n  geom_histogram(binwidth = (max(data$simulated_moran) - min(data$simulated_moran)) / 20, \n                 fill = \"lightblue\", color = \"black\") +\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Simulated Moran's I\", \n       y = \"Frequency\",\n       title = \"Histogram of Simulated Moran's I\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nIf Morans I Statistic is = 0, there is Random Spatial Distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#computing-monte-carlo-gearys-c",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.7.1 Computing Monte Carlo Geary’s C",
    "text": "5.7.1 Computing Monte Carlo Geary’s C\nWe implement the the geary.mc() function of the spdep package to conduct 1000 simulations.\n\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nWe can infer that there is sufficient evidence to reject the null hypothesis (as p-value (0.001)&lt;0.05) and conclude that there is indeed Positive Spatial Autocorrelation (as statistic= 0.691.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05a.html#visualizing-monte-carlo-gearys-c",
    "title": "Hands On Exercise 5- Global Measures of Spatial Autocorrelation",
    "section": "5.7.2 Visualizing Monte Carlo Geary’s C",
    "text": "5.7.2 Visualizing Monte Carlo Geary’s C\n\nSummary StatisticsThe plot\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.003309\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.006955922\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7645  0.9435  1.0044  1.0033  1.0565  1.2883 \n\n\n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\nFrom the plot, we infer that out of the 1000 simulations the value of the statistic is distributed approximately normally, however generally values are close to 1 indicating a lack of spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) focus on the spatial relationships between individual observations and their neighboring areas, rather than summarizing these relationships across an entire map. Unlike global summary statistics, LMSA provides localized scores that reveal the spatial structure within the data. Despite this difference, the underlying intuition behind these local metrics is similar to that of global ones. In fact, some global measures can be broken down into their local counterparts. For example, Local Indicators of Spatial Association (LISA) are derived from global measures of spatial autocorrelation.\nIn addition to LISA, another important LMSA is the Getis-Ord Gi-statistic, which offers complementary insights. Both LISA and Getis-Ord’s Gi-statistics help us understand spatial patterns in geographically referenced data, providing valuable tools for localized spatial analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#performing-relational-join",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.10.1 Performing relational join",
    "text": "5.10.1 Performing relational join\nWe will update the attribute table of Hunan’s SpatialPolygonsDataFrame with the attribute fields of the hunan2012 data-frame. We can do this by using the left_join() function of the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-contiguity-spatial-weights",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.1 Computing Contiguity Spatial Weights",
    "text": "5.12.1 Computing Contiguity Spatial Weights\nBefore computing the local spatial autocorrelation statistics, we need to construct a spatial weights of the study area, the spatial weights are used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe now implement the poly2nb() function of the spdep package to compute contiguity weight matrices for the study area selected.\nUsing this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.\nIn this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.\nYou may refer to the spdep package documentation here to learn more about its functions and arguments.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nFrom the output above, we can infer that there are 88 area units in total in Hunan. The most connected area unit has 11 neighbors. There are two area units with just 1 neighbor, while 24 area units have 5 neighbors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#row-standardized-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#row-standardized-weights-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.2 Row-Standardized Weights Matrix",
    "text": "5.12.2 Row-Standardized Weights Matrix\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nThe nb2listw() function requires an input of class nb, representing a neighborhood object. The function’s two key arguments are style and zero.policy.\n\nThe style argument defines how the weights are calculated. It can take several values:\n\n\"B\": Binary coding, where weights are either 0 or 1.\n\"W\": Row-standardized, where the sum of weights across all neighbors equals 1.\n\"C\": Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.\n\"U\": A variation of \"C\", where weights are normalized by the number of neighbors.\n\"S\": A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.\n\nThe zero.policy argument, when set to TRUE, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector x, effectively setting the lagged value to zero for those regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-local-morans-i",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.3 Computing local Moran’s I",
    "text": "5.12.3 Computing local Moran’s I\nWe implement the localmoran() function of spdep compute the local Moran’s I statistic. This function helps us compute li values, given a set of zi values and a listw object providing neighbor weighting information for the polygon associated with the zi values.\nWe compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nWe now use the printCoefmat() to display the content of the local Moran matrix that we created.\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n5.12.3.1 Mapping the local Moran’s I\nBefore we map the local Moran’s I map, it is wise to append the local Moran’s data-frame (localMI) onto the Hunan SpatialPolygonDataFrame.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n5.12.3.2 Mapping Local Moran’s I values\nWe now make use of the tmap package and its choropleth mapping functions to plot the local Moran’s I values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n5.12.3.3 Mapping Local Moran’s I p-values.\nThe Choropleth reveals the presence of both positive, as well as negative I values. This indicates that there are varying levels of spatial autocorrelation, however, we must examine the p-values for these I values to check for statistical significance.\nWe use the tmap package to draw a choropleth map of Moran’s I p-values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n5.12.3.4 Mapping both local Moran’s I values and p-values.\nIn the interest of easier analysis and interpretation, we plot the two maps next to each other.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.1 Plotting Moran Scatterplot",
    "text": "5.12.1 Plotting Moran Scatterplot\nThe Moran Scatterplot depicts the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will implement the moran.plot() function of the spdep package to create the plot.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants.\nThe top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.2 Plotting Moran Scatterplot with Standardised variable",
    "text": "5.12.2 Plotting Moran Scatterplot with Standardised variable\nWe first implement the scale() function to center and scale the variable. Here, centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\n\nNote that the as.vector() function is added so that we get a vector as the output. This allows us to map it neatly into our data-frame.\n\nWe can now plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#preparing-lisa-map-classes",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.3 Preparing LISA map classes",
    "text": "5.12.3 Preparing LISA map classes\nWe now prepare the data in order to facilitate plotting a LISA Cluster Map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNow, we will derive the spatially lagged variable of interest (i.e: GDPPC) and center the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nNow, we work on centering the local Moran around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nWe set the significance level for the Local Moran in the code chunk below.\n\nsignif &lt;- 0.05       \n\nThe following code chunk defines the four categories (low-low (1), low-high (2), high-low (3), high-high (4))\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nFinally, we place the non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\nYou can simply write all of this in one code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#plotting-lisa-map",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.12.4 Plotting LISA Map",
    "text": "5.12.4 Plotting LISA Map\nWe now use the tmap package to plot the LISA Map.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nIn the interest of easier visualization and interpretation, we plot the GDPPC and their corresponding quadrants next to each other.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nFrom the LISA map, we can see that the regions in the top 2 quadrants are next to each others, indicating positive spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#getis-and-ords-g-statistics",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.1 Getis and Ord’s G-Statistics",
    "text": "5.13.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistic used to detect spatial anomalies is the Getis-Ord G-statistic (Getis and Ord, 1972; Ord and Getis, 1995). This method examines spatial relationships within a defined proximity to identify clusters of high or low values. Statistically significant hotspots are areas where high values are spatially clustered, meaning that not only do these areas have high values, but their neighboring areas also exhibit similarly high values.\nThe analysis involves three key steps:\n\nDeriving the spatial weight matrix: This defines the spatial relationships between areas, specifying which locations are considered neighbors based on proximity.\nComputing the Gi statistic: This step calculates the G-statistic for each location, identifying regions where values are significantly higher or lower than expected.\nMapping the Gi statistics: The results are visualized to reveal spatial patterns of high-value clusters (hotspots) and low-value clusters (cold spots).\n\nThis approach is useful for identifying localized patterns of spatial clustering and detecting significant anomalies in the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#deriving-distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#deriving-distance-based-weight-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.2 Deriving Distance Based Weight Matrix",
    "text": "5.13.2 Deriving Distance Based Weight Matrix\nWe start by defining a new set of neighbors. While the spatial autocorrelation considered units which shared borders, for Getis-Ord, we will define the neighbors based on distance.\n\nThere are two types of distance-based proximity matrices:\n\nFixed Distance Weight Matrix\nAdaptive Distance Weight Matrix\n\n\n\n5.13.2.1 Deriving distance-based weight matrix\nBefore creating our connectivity graph, we need to assign a point to each polygon. This requires more than simply running st_centroid() on the us.bound spatial object. Specifically, we need to extract the coordinates into a separate data frame. To achieve this, we’ll use a mapping function.\nMapping functions apply a specific operation to each element of a vector and return a vector of the same length. In our case, the input vector will be the geometry column from us.bound, and the function we’ll apply is st_centroid(). We’ll use the map_dbl variation from the purrr package, which is designed to return numeric (double) values.\nTo extract the longitude values, we’ll map the st_centroid() function over the geometry column and use double bracket notation [[]] with 1 to access the first element of each centroid, which corresponds to the longitude.\nFor more detailed information, you can refer to the map documentation here.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude, but with one key difference- we access the second value per centroid with [[2]] instead of [[1]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have obtained both latitude and longitude, we will put them into the same object using the cbind() function.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n5.13.2.2 Determine the cut-off distance\nTo determine the upper limit for the distance band, we follow these steps:\n\nFind the k-nearest neighbors: Use the knearneigh() function from the spdep package. This function returns a matrix that contains the indices of points corresponding to the k-nearest neighbors for each observation.\nConvert to a neighbors list: Take the k-nearest neighbors object returned by knearneigh() and convert it into a neighbors list (class nb) by using the knn2nb() function. This generates a list of integer vectors, where each vector contains the region numbers corresponding to its neighbors.\nCalculate neighbor distances: Use the nbdists() function from spdep to calculate the distances between neighbors. The function returns the lengths of neighbor relationship edges in the units of the coordinates (e.g., kilometers if the coordinates are geographic).\nFlatten the distance list: The distances returned by nbdists() are stored in a list. Use the unlist() function to remove the list structure and return a single vector of distances.\n\nThis process helps identify the upper limit for a distance band by analyzing the distances between neighboring regions.\n\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nFrom the output above, we can infer that the largest first-nearest neighbor distance is 61.79KM- using this as the upper threshold gives certainty that all units will have at least one neighbor.\n\n\n5.13.2.3 Computing fixed distance weight matrix\nWe implement the dnearneigh() function of the spdep package to compute the distance weight matrix.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nAfter this, we implement the nb2listw() function to convert the nb object into spatial weights object.\nOn average, each region has approximately 3.68 neighbors.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05b.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands On Exercise 5- Part 2- Local Measures of Spatial Autocorrelation",
    "section": "5.13.3 Computing Adaptive Distance Weight Matrix",
    "text": "5.13.3 Computing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually urban areas) tend to have more neighbours and the less densely settled areas (usually the rural areas) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either by accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nAfter this, we implement the nb2list2() function to convert the nb object into a spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, we will delineate homogeneous regions by using geographically referenced multivariate data.\nThere are two analytical techniques that we will focus on for this:\n\nHierarchical Cluster Analysis\nSpatially Constrained Cluster Analysis"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-geospatial-data",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2.1 Importing the Geospatial Data",
    "text": "6.2.1 Importing the Geospatial Data\nWe will first import the Myanmar Township Boundary GIS data-set and its attribute table into our environment. We implement the st_read() function of the sf package for this.\nThe data is in ESRI Shapefile format.\n\nImporting the dataStructure of the data-frameglimpse\n\n\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nFrom the output above, we infer that shan_sf is a simple-feature data-frame.\n\n\nWe get an overview of the contents of shan_sf by implementing the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nWe infer that the data-frame conforms to Hadley Wickham’s Tidy Framework.\n\n\nAfter understanding that it conforms to the tidy framework, we can implement the glimpse() function to reveal the fields and data types.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n\n\nHadley Wickham’s tidy framework refers to a consistent and coherent approach to data science in R. It emphasizes organizing data in a ‘tidy’ format where:\n\nEach variable is a column.\nEach observation is a row.\nEach type of observational unit forms a table.\n\nThis tidy data structure allows for easier manipulation, analysis, and visualization, and is supported by core packages like dplyr (data manipulation), tidyr (data tidying), and ggplot2 (data visualization) within the tidyverse collection."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#importing-the-aspatial-data",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2.2 Importing the Aspatial Data",
    "text": "6.2.2 Importing the Aspatial Data\nWe now import the aspatial data-set using the read_csv() function of the readr package.\n\nImporting the DataSummary of the data-frame\n\n\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\n\n\nWe implement the summary() function to discover the summary statistics of the data-set.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#deriving-new-variables-using-dplyr",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#deriving-new-variables-using-dplyr",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2.3 Deriving new variables using dplyr",
    "text": "6.2.3 Deriving new variables using dplyr\nIn our study, the unit of measurement of the values are number of households.\nUsing these values directly will be biased by the underlying numbers such as the total number of households. For example, the townships with relatively higher number of households will also have more households that own a TV.\nIn order to negate the effect of this bias, we derive a new variable, penetration rate, for each ICT variable.\n\nDeriving the new variableSummary Statistics\n\n\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\n\n\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-statistical-graphics",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.3.1 EDA using statistical graphics",
    "text": "6.3.1 EDA using statistical graphics\nWe now gain a better understanding of the distribution of the variables in the dataset by using appropriate EDA techniques, such as plotting histograms.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nUsing the box-plot allows us the gain a better understanding of the range and to detect the presence of outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNow, we plot the distribution of the newly derived variables in ict_derived (penetration rate).\n\nHistogramBoxplot\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\nWe see immediately that the skewness of the data is significantly lesser with our derived variables and there are also fewer outliers.\nWe now proceed to plot a few selected variables for to facilitate visualization.\nWe will first initialize plots as shown in the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNow, we implement the ggarrange() function of the ggpubr package to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#eda-using-choropleth-maps",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.3.2 EDA using Choropleth Maps",
    "text": "6.3.2 EDA using Choropleth Maps\n\n6.3.2.1 Joining the Geospatial and Aspatial data\nWe combine shan_sf and ict_derived. For this, we use the left_join() function of the dplyr package.\nshan_sf is used as the base data object and ict_derived is used as the join table.\nThe common key, necessary for a relational join, is TS_PCODE. We will then save this as an rds file.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \n# write_rds(shan_sf, \"chap12/data/rds/shan_sf.rds\")\n\nWe now use the read_rds() function as shown below.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n6.3.2.2 Preparing a Choropleth Map\nTo have a brief overview of the distribution of the Radio Penetration rate of Shan State at the township level, we plot a choropleth map.\nWe implement the qtm() function of the tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nTo account for potential bias in the distribution shown in the choropleth map due to the varying total number of households across townships, we will create two separate choropleth maps. The first map will depict the total number of households (i.e., TT_HOUSEHOLDS.map), while the second will show the total number of households with radios (i.e., RADIO.map). The following code chunk demonstrates this process.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nThe choropleth maps above clearly show that townships with a relatively larger number of households are also have a relatively higher radio ownership.\nWe now plot the choropleth maps showing the dsitribution of total number of households and Radio penetration rate.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\nImmediately we see a difference to the previous maps, showing us the magnitude of the bias."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-the-target-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extracting-the-target-variables",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.1 Extracting the target variables",
    "text": "6.5.1 Extracting the target variables\nWe will start off by extracting the necessary variables from shan_sf. Do remember to select only one variable out of the highly correlated variables as determined above. We select COMPUTER_PR.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nWe now change the index to be by township name instead of by row numbers.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nWe now delete the TS.x field.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardization",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-standardization",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.2 Data Standardization",
    "text": "6.5.2 Data Standardization\nMultiple variables are used in cluster analysis and it is common for these variables to have different value ranges. In order to prevent the results from being skewed towards variables that have larger values, it is necessary to standardize the input variables before conducting clustering analysis. This will ensure that all variables equally contribute to the clustering process.\n\n6.5.2.1 Min-Max Standardization\nWe implement the normalize() function of the heatmaply package to standardize variables by using the Min-Max method.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\n\n\n6.5.2.2 Z-score Standardization\nWe implement the scale() function of Base R to standardize variables using the Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\n\nIn the output above, we notice that the mean and standard deviation of the Z-score standardized clustering variables are 0 and 1 respectively.\n\nZ-score standardization should only be used if we can assume that all variables come from some Normal Distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-the-standardized-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-the-standardized-clustering-variables",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.3 Visualizing the Standardized Clustering Variables",
    "text": "6.5.3 Visualizing the Standardized Clustering Variables\nWe now produce some plots using the ggplot package to gain a better understanding of the distribution of the variables.\n\nHistogramsDensity\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\nWe see the effectiveness of standardization by minimizing the range and reducing the impact of bias significantly, making it easier to compare to other variables with different units or scales."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-proximity-matrix",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.4 Computing Proximity Matrix",
    "text": "6.5.4 Computing Proximity Matrix\nWe implement the dist() function of Base R to compute the proximity matrix.\nDist() supports six distance proximity calculations. The six are as follows:\n\nEuclidean (Default method): Measures the straight-line distance between two points in multi-dimensional space.\nMaximum (Chebyshev): Measures the greatest difference along any one dimension between two points.\nManhattan (City Block): Calculates the sum of absolute differences along each dimension, like navigating a grid.\nCanberra: A weighted version of the Manhattan distance, giving more emphasis to smaller differences.\nBinary: Computes distance based on the number of mismatches between binary variables.\nMinkowski: A generalized distance metric that includes Euclidean (p=2) and Manhattan (p=1) as special cases, depending on the power parameter ( p )."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#calculating-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#calculating-proximity-matrix",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Calculating Proximity Matrix",
    "text": "Calculating Proximity Matrix\nWe calculate the proximity matrix below.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Overview",
    "text": "Overview\nWe now check the contents of the matrix below.\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-hierarchical-clustering",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.5 Computing Hierarchical Clustering",
    "text": "6.5.5 Computing Hierarchical Clustering\nWe implement the hclust() function of R stats to compute it.\nThis functions employs the agglomeration method to compute the cluster.\nThe following 8 clustering algorithms are supported:\n\nward.D: Minimizes the total variance within clusters, merging pairs of clusters that result in the smallest increase in total variance.\nward.D2: A variant of Ward’s method that uses squared distances, producing slightly different results than ward.D.\nsingle: Uses the minimum distance (or nearest neighbor) between clusters, often leading to elongated, chain-like clusters (also called “connected clustering”).\ncomplete: Uses the maximum distance (or farthest neighbor) between clusters, resulting in more compact clusters.\naverage (UPGMA): Merges clusters based on the average distance between all members of the two clusters, balancing between single and complete linkage.\nmcquitty (WPGMA): A weighted average method where the distance between a new cluster and an existing cluster is based on the average of distances with equal weighting.\nmedian (WPGMC): Merges clusters based on the median distance, which can reduce the impact of outliers.\ncentroid (UPGMC): Uses the centroid of clusters (the mean position of all points) for calculating distances, which may result in reversals where clusters can split again during merging.\n\n\nComputationPlot\n\n\nWe now perform hierarchical cluster analysis using the ward.D method. The hierarchical output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\n\n\nWe now implement the plot() of R graphics to create a tree.\n\nplot(hclust_ward, cex=0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#selecting-the-optimal-clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#selecting-the-optimal-clustering-algorithm",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.6 Selecting the optimal clustering algorithm",
    "text": "6.5.6 Selecting the optimal clustering algorithm\nA big challenge when conducting hierarchical clustering is to identify stronger clustering structures.\nThis issue can be solved by using the agnes() function of the cluster package. It functions like hclust(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structures found.\nWe implement the code chunk below to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nFrom the output above, we infer that the Ward method does in fact provide the strongest clustering structure out of the 4 selected methods. We proceed to use the Ward’s method in subsequent analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-optimal-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determining-optimal-clusters",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.7 Determining Optimal Clusters",
    "text": "6.5.7 Determining Optimal Clusters\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method: A technique to determine the optimal number of clusters by plotting the explained variance (within-cluster sum of squares) against the number of clusters, and identifying the “elbow” point where adding more clusters provides diminishing returns in reducing variance.\nAverage Silhouette Method: Evaluates the quality of clustering by measuring how similar each point is to its own cluster compared to other clusters. The optimal number of clusters maximizes the average silhouette width, which reflects well-separated and cohesive clusters.\nGap Statistic Method: Compares the total within-cluster variance for different numbers of clusters to that of a reference dataset with no obvious clustering structure. The optimal number of clusters is where the gap between the observed data and reference data is largest, indicating a meaningful clustering structure.\n\n\n6.5.7.1 Gap Statistic Method\nThe Gap Statistic compares the total within-cluster variation for different values of k with the expected variation under a null reference distribution of the data. The optimal number of clusters is the value of k that maximizes the gap statistic, indicating the largest difference between the observed clustering structure and a random uniform distribution of points. A higher gap statistic suggests a more distinct and meaningful clustering pattern compared to random noise.\nWe implement the clusGap() function of the cluster package.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\n\nNote that the hcut function used in the FUN argument above is from the factoextra package.\n\nWe now visualize the plot by implementing the fviz_gap_stat() function of the factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nFrom the above, we infer that the recommended number of clusters to retain is 1. However, it isn’t logical to retain just one. By continuing to examine the graph, we see that the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\n\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interpreting-the-dendrograms",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#interpreting-the-dendrograms",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.8 Interpreting the dendrograms",
    "text": "6.5.8 Interpreting the dendrograms\nIn the above dendrogram, each leaf corresponds to one observation.\nAs we move up the tree, similar observations are grouped into branches, which are fused at a higher height. The height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are.\n\nNote that conclusions about the proximity of two observations can be drawn only based on the height where the branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\n\nWe can also plot the dendrogram with a border around the selected clusters by implementing the rect.hclust() function of R stats. The border argument is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visually-driven-hierarchical-clustering-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visually-driven-hierarchical-clustering-analysis",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.7 Visually-driven hierarchical clustering analysis",
    "text": "6.5.7 Visually-driven hierarchical clustering analysis\nWe now implement functions of the heatmaply package to conduct visually driven hierarchical clustering analysis.\nHeatmaply allows us to build both highly interactive cluster heatmaps or static cluster heatmaps.\n\n6.5.7.1 Transforming the data-frame into a matrix\nThough we have a data-frame, the data has to be in matrix form to make a heatmap.\nWe use the code chunk below to transform the shan_ct data-frame into a data matrix. The data.matrix() function is implemented.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n6.5.7.2 Plotting an Interactive Cluster Heatmap using heatmaply()\nWe implement the heatmaply() function of the heatmaply package to create an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#mapping-the-clusters-formed",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#mapping-the-clusters-formed",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5.8 Mapping the clusters formed",
    "text": "6.5.8 Mapping the clusters formed\nAs decided earlier, we have retained 6 clusters (k=6).\nThe cutree() function of Base R is used to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe above output, groups, is a list object.\nWe now need to append this object onto the shan_sf simple-feature object.\n\nThe code chunk below forms the join in three steps:\n\nthe groups list object will be converted into a matrix\ncbind() is used to append the groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename() of the dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nWe now implement the qtm() function of the tmap package to plot the choropleth map to visualize these clusters.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nFrom the above map, we infer that the clusters are relatively fragmented. This is a major limitation of using non-spatial clustering algorithms such as hierarchical clustering analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#converting-into-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#converting-into-spatialpolygonsdataframe",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6.1 Converting into SpatialPolygonsDataFrame",
    "text": "6.6.1 Converting into SpatialPolygonsDataFrame\nWe start by converting shan_sf into a SpatialPolygonsDataFrame. This is becausse the SKATER function only supports sp objects.\nWe implement the as_Spatial() function of the sf package to do the conversion.\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-neighbor-list",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-neighbor-list",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6.2 Computing Neighbor List",
    "text": "6.6.2 Computing Neighbor List\nNow, we apply the poly2nb() function of the spdep package to compute the neighbours list from the polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe now plot the neighbours list on shan_sp by using the code chunk below.\nSince we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\n# Obtaining coordinates\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n# Plots\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-the-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-the-minimum-spanning-tree",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6.3 Computing the minimum spanning tree",
    "text": "6.6.3 Computing the minimum spanning tree\n\n6.6.3.1 Calculating Edge Costs\nWe now implement the nbcosts() function of the spdep package is used to compute the cost of each edge. It is the distance between the nodes.\nThis function computes this distance by using a data.frame with observations vector in each node.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observations (from the neighbour list).\nThis is basically the notion of a generalised weight for a spatial weights matrix.\nNext, we incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() function of the spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\nThe minimum spanning tree is computed by implementing the mstree() function of the spdep package.\n\nObtaining TreeClass of the treeDimensions\n\n\n\nshan.mst &lt;- mstree(shan.w)\n\n\n\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\n\n\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\n\nWe can now display the content of shan.mst by using the head() function.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the MST includes a way to show the observation numbers of the nodes in addition to the edge.\nAs before, we plot this together with the township boundaries. We can see how the initial neighbor list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-spatially-constrained-clusters-using-the-skater-method",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6.5 Computing spatially constrained clusters using the SKATER method",
    "text": "6.6.5 Computing spatially constrained clusters using the SKATER method\nWe implement the skater() function of the spdep package to compute the clusters.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() function takes three mandatory arguments:\n\nThe first two columns of the MST matrix (i.e. not the cost),\nThe data matrix (to update the costs as units are being grouped)\nThe number of cuts.\n\n\n\nNote: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\n\n\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary).\nThis is followed by a detailed summary for each of the clusters in the edges.groups list.\nSum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nWe can find out how many observations are in each cluster by using the table() function.\nWe can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nWe can also plot the pruned tree that shows the 5 clusters on top of the township area, similar to what we did earlier.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-the-clusters-in-a-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-the-clusters-in-a-choropleth-map",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6.6 Visualizing the clusters in a Choropleth Map",
    "text": "6.6.6 Visualizing the clusters in a Choropleth Map\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nTo facilitate comparison, we plot the hierarchical clustering map as well as the spatially constrained hierarchical clustering maps next to one another.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nWe immediately see the difference between the two methods, in how clusters are fragmented. The spatially constrained cluster is has no fragmentation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#ward-like-hierarchical-clustering-clustgeo",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.7.1 Ward-like Hierarchical Clustering: ClustGeo",
    "text": "6.7.1 Ward-like Hierarchical Clustering: ClustGeo\nClustGeo provides a function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like the hclust() function.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist().\n\n\n6.7.1.1 Mapping the clusters formed\nWe plot the clusters on map using similar steps to what we did earlier.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.7.2 Spatially Constrained Hierarchical Clustering",
    "text": "6.7.2 Spatially Constrained Hierarchical Clustering\nBefore we can perform spatially constrained hierarchical clustering, a spatial distance matrix mustbe derived. For this, we implement the st_distance() function of the sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\nNote that the as.dist() function is used to convert the data-frame into a matrix.\n\nWe now implement the choicealpha() function to determine a suitable value for the mixing parameter, alpha.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the above, we infer that an alpha value of 0.3 would be suitable.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNow, we implement the cutree() function to derive the cluster object. This is similar to the steps we used above to plot the maps.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe now implement the qtm() function to plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualizing-individual-clustering-variable",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.8.1 Visualizing individual clustering variable",
    "text": "6.8.1 Visualizing individual clustering variable\nWe implement the code chunk below the reveal the distribution of a variable, such as RADIO_PR, by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals that Cluster 3 displays the highest mean Radio Ownership Per Thousand Households. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multivariate-visualization",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#multivariate-visualization",
    "title": "Hands On Exercise 6- Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.8.2 Multivariate Visualization",
    "text": "6.8.2 Multivariate Visualization\nPast studies have shown that parallel coordinate plots can be used in order to reveal clustering variables by cluster effectively.\nWe implement the ggparcoord() function of the GGally package for this.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TVs and mobile-phones., while households in Cluster 5 tend to own the lowest of all the five ICTs.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no best scaling method to use. The method selected must be done based on the specific requirements of your analysis.\nFinally, we also compute the summary statistics to complement the plots created above.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html",
    "title": "In Class Exercise 6",
    "section": "",
    "text": "In this in-class exercise, we will reinforce our learning from Hands-on Exercise 6 and conduct Emerging Hot/Cold Spot Analysis.\nFor this exercise we will use Hunan GDPPC data.\n\nEmerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#deriving-the-spatial-weights",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#deriving-the-spatial-weights",
    "title": "In Class Exercise 6",
    "section": "6.3.1 Deriving the Spatial Weights",
    "text": "6.3.1 Deriving the Spatial Weights\nWe implement the below code chunk to identify neighbors and calculate the inverse-distance weights.\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts()."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#computing-gi",
    "title": "In Class Exercise 6",
    "section": "6.3.2 Computing Gi",
    "text": "6.3.2 Computing Gi\nWe can use these new columns to manually calculate the local Gi for each location. We do this by grouping by Year and using the local_gstar_perm() function of the sfdep package. After this, we use the unnest() function to unnest the gi_star column of the newly created gi_starts data.frame.\n\ngi_stars &lt;- GDPPC_nb %&gt;% \n  group_by(Year) %&gt;% \n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;% \n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#mann-kendall-test",
    "title": "In Class Exercise 6",
    "section": "6.3.3 Mann-Kendall Test",
    "text": "6.3.3 Mann-Kendall Test\nWe the above Gi calculations, we can now conduct the Mann-Kendall test to evaluate each location for a trend.\nIn the code chunk below, we use Changsha,\n\ncbg &lt;- gi_stars %&gt;% \n  ungroup() %&gt;% \n  filter(County == \"Changsha\") %&gt;% \n  select(County, Year, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\nAlternatively, we can also create an interactive plot using the ggplotly() function of the plotly package.\n\np &lt;- ggplot(data = cbg, \n       aes(x = Year, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\n6.3.3.1 Mann-Kendall Test Report\nA Monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\n\nH0: No monotic trend.\nH1: Monotonic trend is present\n\n\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series.\n1 is a perfectly increasing series.\n\n\nWe implement the below code chunk to obtain the required report.\n\ncbg %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\n\nNote that slin the output above is the p-value in this situation.\n\nFrom the above output, we can infer that there is a slight upward but insignificant trend.\n\n\n6.3.3.2 Mann-Kendall Test Data-Frame\nWe can perform the above steps for every location by using the group_by() function of the dplyr package.\n\nehsa &lt;- gi_stars %&gt;%\n  group_by(County) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\nWe can sort the data-frame to highlight emerging hot/cold spots by implementing the below code chunk.\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#visualizing-the-distribution-of-ehsa-classes",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#visualizing-the-distribution-of-ehsa-classes",
    "title": "In Class Exercise 6",
    "section": "6.4.1 Visualizing the distribution of EHSA Classes",
    "text": "6.4.1 Visualizing the distribution of EHSA Classes\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe figure above shows that the ‘sporadic coldspot’ class has a high number of county’s."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#visualizing-ehsa",
    "href": "In-class_Ex/In-class_Ex6/In-class_Ex6.html#visualizing-ehsa",
    "title": "In Class Exercise 6",
    "section": "6.4.2 Visualizing EHSA",
    "text": "6.4.2 Visualizing EHSA\nBefore we can proceed with visualization, we need to join both hunan and ehsa together by using the code chunk below.\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig &lt;- hunan_ehsa  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nWe can further look at this in greater detail by each location as well if required."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Tourism is one of Thailand’s largest industries, accounting for some 20% of the gross domestic product (GDP). In 2019, Thailand earned 90 billion US$ from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to 24 billion US$ in 2020.\nThe figure below shows the total revenue for the tourism sector from January 2019 until Feb 2023. The figure reveals that the revenue for the industry have been recovering gradually since September 2021.\n\nHowever, it is important to note that the tourism economy of Thailand is not evenly distributed- not all provinces make a lot of revenue.\nThailand has 77 provinces in total as shown on the map below. This map was sourced from Wikipedia.\n\nThe figure below reveals that the tourism economy of Thailand is carried by five provinces, namely Bangkok, Phuket, Chiang Mai, Sukhothai and Phetchaburi."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#importing-the-data",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "2.1 Importing the data",
    "text": "2.1 Importing the data\n\n2.1.1 Importing the aspatial data\nWe will now import the aspatial data by implementing the read_csv() function of the readr package as shown in the code chunk below.\nWe create three separate data frames using the same data-set to facilitate our analysis.\n\ntourists=read_csv('data/aspatial/thailand_domestic_tourism_2019_2023_ver2.csv')\ntourists_temporal= tourists%&gt;%\n  mutate(month=month(date))%&gt;%\n  mutate(year=year(date))\n# Summing the 'value' based on 'province_eng' and 'variable'\nsummed_data &lt;- tourists %&gt;%\n  group_by(region_eng, province_eng, variable) %&gt;%\n  summarize(total_value = sum(value, na.rm = TRUE), .groups = 'drop')\n\n\n# View the result\nhead(summed_data)\n\n# A tibble: 6 × 4\n  region_eng province_eng variable           total_value\n  &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;                    &lt;dbl&gt;\n1 central    Ang Thong    no_tourist_all        2293450 \n2 central    Ang Thong    no_tourist_foreign      42073 \n3 central    Ang Thong    no_tourist_stay        391465 \n4 central    Ang Thong    no_tourist_thai       2251377 \n5 central    Ang Thong    ratio_tourist_stay       1622.\n6 central    Ang Thong    revenue_all        2556650000 \n\n\n\n\n2.1.2 Importing the geospatial data\nWe now import the geospatial data using the st_read() function of the sf package.\n\nprovince=st_read(dsn = \"data/geospatial\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\")%&gt;%\n  select(1:5, 17)\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nWe now check the CRS information using the st_crs() function of the sf package and transform the EPSG code using the st_transform() function if it is not 32647, the EPSG code of Thailand.\n\nCheck CRSTransform CRS\n\n\n\nst_crs(province)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\n\n\nst_transform(province, 32647)\n\nSimple feature collection with 77 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 325178.8 ymin: 620860.6 xmax: 1213656 ymax: 2263241\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n   Shape_Leng Shape_Area                  ADM1_EN       ADM1_TH ADM1_PCODE\n1    2.417227 0.13133873                  Bangkok  กรุงเทพมหานคร       TH10\n2    1.695100 0.07926199             Samut Prakan    สมุทรปราการ       TH11\n3    1.251111 0.05323766               Nonthaburi         นนทบุรี       TH12\n4    1.884945 0.12698345             Pathum Thani        ปทุมธานี       TH13\n5    3.041716 0.21393797 Phra Nakhon Si Ayutthaya พระนครศรีอยุธยา       TH14\n6    1.739908 0.07920961                Ang Thong        อ่างทอง       TH15\n7    5.693342 0.54578838                 Lop Buri          ลพบุรี       TH16\n8    1.778326 0.06872655                Sing Buri         สิงห์บุรี       TH17\n9    2.896316 0.20907828                 Chai Nat         ชัยนาท       TH18\n10   4.766446 0.29208711                 Saraburi         สระบุรี       TH19\n                         geometry\n1  MULTIPOLYGON (((674339.8 15...\n2  MULTIPOLYGON (((687139.8 15...\n3  MULTIPOLYGON (((644817.9 15...\n4  MULTIPOLYGON (((704086 1575...\n5  MULTIPOLYGON (((662941.6 16...\n6  MULTIPOLYGON (((643472.8 16...\n7  MULTIPOLYGON (((751293.3 17...\n8  MULTIPOLYGON (((647136.1 16...\n9  MULTIPOLYGON (((620165.4 17...\n10 MULTIPOLYGON (((757935.1 16...\n\n\n\n\n\n\n\n2.1.3 Performing relational join\nAfter performing consistency checks, we notice that the provinces aren’t named correctly in our tourist data-set. We correct the names below.\n\nsummed_data$province_eng &lt;- gsub(\"Nong Bua Lamphu\", \"Nong Bua Lam Phu\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Sisaket\", \"Si Sa Ket\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Phang Nga\", \"Phangnga\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Lopburi\", \"Lop Buri\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Chonburi\", \"Chon Buri\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Chainat\", \"Chai Nat\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Buriram\", \"Buri Ram\", summed_data$province_eng)\nsummed_data$province_eng &lt;- gsub(\"Prachinburi\", \"Prachin Buri\", summed_data$province_eng)\n\nWe will now join the aspatial and geospatial data by using the left_join() function of the package as showing in the code chunk below.\n\npro_tourism=left_join(summed_data, province, by= c(\"province_eng\"=\"ADM1_EN\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualizing-regional-indicators",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#visualizing-regional-indicators",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "2.3.1 Visualizing regional indicators",
    "text": "2.3.1 Visualizing regional indicators\nAfter successfully completing the relational join, we can now plot a choropleth map to visualize the tourism in each province in Thailand using various functions of the tmap package.\n\n2.3.1.1 Number of tourists\n\nNumber of Foreign TouristsNumber of Domestic TouristsAll tourists\n\n\nWe first take a look at the number of tourists, both foreign and domestic, across all provinces in Thailand. Do note that these data-frames must be converted to sf data-frames before they can be mapped. This can be done using the st_as_sf() function as shown below.\nIf the data-frames are not in the correct format, conducting analysis will not be possible.\n\ntourist_foreign=pro_tourism%&gt;%\n  filter(variable=='no_tourist_foreign')\ntourist_foreign=st_as_sf(tourist_foreign)\n\ntourist_foreign=st_as_sf(tourist_foreign)\n\n\n# Create the interactive basemap\nbasemap01 &lt;- tm_shape(tourist_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style= 'quantile')+\n  tm_text(\"province_eng\", size = 0.3) \n\n\n# Display the interactive map\nbasemap01\n\n\n\n\n\n\n\n\n\n\n\ntourist_domestic=pro_tourism%&gt;%\n  filter(variable=='no_tourist_thai')\n\ntourist_domestic=st_as_sf(tourist_domestic)\n\n\n# Create the interactive basemap\nbasemap02 &lt;- tm_shape(tourist_domestic) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile')+\n  tm_text(\"province_eng\", size = 0.3) \n\n# Display the interactive map\nbasemap02\n\n\n\n\n\n\n\n\n\n\n\ntourist_all=pro_tourism%&gt;%\n  filter(variable=='no_tourist_all')\n\ntourist_all=st_as_sf(tourist_all)\n\n\n# Create the interactive basemap\nbasemap03 &lt;- tm_shape(tourist_all) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile')+\n  tm_text(\"province_eng\", size = 0.3) \n\n# Display the interactive map\nbasemap03\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.1.2 Revenue\nWe now take a look at the revenue generated by foreign and domestic tourists in Thailand\n\nRevenue generated by ForeignersRevenue generated by Domestic TouristsOverall Profit\n\n\n\nprofit_foreigners=pro_tourism%&gt;%\n  filter(variable=='revenue_foreign')\nprofit_foreigners=st_as_sf(profit_foreigners)\n  \n\n\n# Create the interactive basemap\nbasemap &lt;- tm_shape(profit_foreigners) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style= 'quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n# Display the interactive map\nbasemap\n\n\n\n\n\n\n\n\n\n\n\nprofit_domestic=pro_tourism%&gt;%\n  filter(variable=='revenue_thai')\n\nprofit_domestic=st_as_sf(profit_domestic)\n\n\n# Create the interactive basemap\nbasemap2 &lt;- tm_shape(profit_domestic) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n# Display the interactive map\nbasemap2\n\n\n\n\n\n\n\n\n\n\n\nprofit_all=pro_tourism%&gt;%\n  filter(variable=='revenue_all')\nprofit_all=st_as_sf(profit_all)\n  \n\n\n# Create the interactive basemap\nbasemap3 &lt;- tm_shape(profit_all) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style= 'quantile')+\n  tm_text(\"province_eng\", size = 0.5)     \n\n# Display the interactive map\nbasemap3\n\n\n\n\n\n\n\n\n\n\n\nBangkok seems to be the most lucrative province overall.\n\n\n2.3.1.3 Occupancy Rate by Year. The impact of Covid.\nWe will now look at the occupancy rates, namely the ratio_tourist_stay variable. This is derived by the following formula:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#spatial-weights",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "2.4.1 Spatial Weights",
    "text": "2.4.1 Spatial Weights\n\n2.4.1.1 Computing Contiguity Spatial Weights\nWe use the poly2nb() function as shown in the code chunk below. Using this, we are able to compute a Queen contiguity weight matrix.\n\nProfit from ForeignersDomestic Tourists (Profit)Tourists (all)\n\n\n\n# Rook contiguity\nwm_r &lt;- poly2nb(profit_foreigners, queen=FALSE)\nwrite_rds(wm_r, 'data/rds/wm_r_pro_foreign')\n\n# Queen Contiguity\nwm_q &lt;- poly2nb(profit_foreigners, queen=TRUE)\nwrite_rds(wm_q, 'data/rds/wm_q_pro_foreign')\n\n\nRook ContiguityQueen Contiguity\n\n\n\nwm_r_pro_foreign=read_rds(\"data/rds/wm_r_pro_foreign\")\nsummary(wm_r_pro_foreign)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\nwm_q_pro_foreign=read_rds(\"data/rds/wm_q_pro_foreign\")\nsummary(wm_q_pro_foreign)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\n\n\nWe now repeat the same steps for Domestic tourists.\n\n# Rook contiguity \nwm_r &lt;- poly2nb(profit_domestic, queen=FALSE)\nwrite_rds(wm_r, 'data/rds/wm_r_pro_dom')\n\n# Queen Contiguity\nwm_q &lt;- poly2nb(profit_domestic, queen=TRUE)\nwrite_rds(wm_q, 'data/rds/wm_q_pro_dom')\n\nWe now look at a summary of both using the code chunks below.\n\nRook ContiguityQueen Contiguity\n\n\n\nwm_r_pro_dom=read_rds(\"data/rds/wm_r_pro_dom\")\nsummary(wm_r_pro_dom)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\nwm_q_pro_dom=read_rds(\"data/rds/wm_q_pro_dom\")\nsummary(wm_q_pro_dom)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\n\n\nWe now check all tourists.\n\n# Rook contiguity\nwm_r &lt;- poly2nb(profit_all, queen=FALSE)\nwrite_rds(wm_r, 'data/rds/wm_r_pro_all')\n\n# Queen Contiguity\nwm_q &lt;- poly2nb(profit_all, queen=TRUE)\nwrite_rds(wm_q, 'data/rds/wm_q_pro_all')\n\n\nRook ContiguityQueen Contiguity\n\n\n\nwm_r_pro_all=read_rds(\"data/rds/wm_r_pro_all\")\nsummary(wm_r_pro_all)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\nwm_q_pro_all=read_rds(\"data/rds/wm_q_pro_all\")\nsummary(wm_q_pro_all)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n71 with 1 link\n2 most connected regions:\n17 69 with 9 links\n\n\n\n\n\n\n\n\nWe generate the Queen Contiguity data for Number of tourists.\n\nwm_q_tour= poly2nb(tourist_all, queen=TRUE)\n\nWe now generate the Queen Contiguity data for each individual year.\n\nQueen Contiguity ComputationReading RDS files\n\n\n\nwm_q_2019=poly2nb(occupancy_2019_avg, queen=TRUE)\n\nwm_q_2020=poly2nb(occupancy_2020_avg, queen=TRUE)\n\nwm_q_2020=poly2nb(occupancy_2021_avg, queen=TRUE)\n\nwm_q_2021=poly2nb(occupancy_2022_avg, queen=TRUE)\n\n\n\nWe created an RDS file using the write_rds() function for the above and load them into our environment using the read_rds() function as shown in the code chunk below.\n\n## 2019\nwm_q_2019=read_rds('data/rds/wm_q_2019')\n\n## 2020\nwm_q_2020=read_rds('data/rds/wm_q_2020')\n\n\n## 2021\nwm_q_2021=read_rds('data/rds/wm_q_2021')\n\n## 2022\nwm_q_2022=read_rds('data/rds/wm_q_2022')\n\n\n\n\n\n\n2.4.1.2 Visualizing Contiguity Spatial Weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons in this situation, so we need to ensure that our points are in order to produce our connectivity graphs.\nUsually, the method of choice will be polygon centroids. We calculate using the sf package before moving onto the graphs. Getting latitude and longitude of the Polygon Centroids.\nWe need points to associate with each polygon before we can make our connectivity graph. It won’t be as simple as applying the st_centroid() function of the sf sf object: us.bound. We need the coordinates in a separate data-frame for this to work.\nTo do this, we will use a mapping function which will apply a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound.\nThe function that we implement in this situation will be st_centroid().\nWe will be using the map_dbl variation of map from the purrr package.\n\nCoordinates of Foreign TravellersCoordinates of Domestic TravellersCoordinates for all travellers\n\n\nWe start by extracting the longitude and latitude values for foreign travellers.\n\nlongitude_profit_foreign= map_dbl(profit_foreigners$geometry, ~st_centroid(.x)[[1]])\nlatitude_profit_foreign= map_dbl(profit_foreigners$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have the latitude and longitude values, we can use the cbind() function to put the longitude and latitude values into the same object, coords.\n\ncoords_profit_foreign &lt;- cbind(longitude_profit_foreign, latitude_profit_foreign)\n\nWe use the head() function to verify if coords is in the correct format.\n\nhead(coords_profit_foreign)\n\n     longitude_profit_foreign latitude_profit_foreign\n[1,]                100.34851                14.62354\n[2,]                100.62353                13.77183\n[3,]                100.02748                15.13390\n[4,]                 99.04668                14.58513\n[5,]                100.90713                15.10760\n[6,]                100.10312                13.92502\n\n\n\n\n\nlongitude_profit_domestic= map_dbl(profit_domestic$geometry, ~st_centroid(.x)[[1]])\nlatitude_profit_domestic= map_dbl(profit_domestic$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have the latitude and longitude values, we can use the cbind() function to put the longitude and latitude values into the same object, coords. We now create the coords object.\n\ncoords_profit_domestic=cbind(longitude_profit_domestic, latitude_profit_domestic)\n\nWe use the head() function to verify if coords is in the correct format.\n\nhead(coords_profit_domestic)\n\n     longitude_profit_domestic latitude_profit_domestic\n[1,]                 100.34851                 14.62354\n[2,]                 100.62353                 13.77183\n[3,]                 100.02748                 15.13390\n[4,]                  99.04668                 14.58513\n[5,]                 100.90713                 15.10760\n[6,]                 100.10312                 13.92502\n\n\n\n\n\nlongitude_profit_all= map_dbl(profit_all$geometry, ~st_centroid(.x)[[1]])\nlatitude_profit_all= map_dbl(profit_all$geometry, ~st_centroid(.x)[[2]])\n\nWe now create the coords object.\n\ncoords_profit_all &lt;- cbind(longitude_profit_all, latitude_profit_all)\nhead(coords_profit_all)\n\n     longitude_profit_all latitude_profit_all\n[1,]            100.34851            14.62354\n[2,]            100.62353            13.77183\n[3,]            100.02748            15.13390\n[4,]             99.04668            14.58513\n[5,]            100.90713            15.10760\n[6,]            100.10312            13.92502\n\n\n\n\n\nWe can now visualize it using the plot() function as shown in the following code chunks.\n\nProfits from foreign travellersProfits from domestic travellersProfits from all travellers\n\n\n\nplot(profit_foreigners$geometry, border=\"lightgrey\")\nplot(wm_r_pro_foreign, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\nplot(profit_foreigners$geometry, border=\"lightgrey\")\nplot(wm_q_pro_foreign, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\n\n\nplot(profit_domestic$geometry, border=\"lightgrey\")\nplot(wm_r_pro_dom, coords_profit_domestic, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\nplot(profit_domestic$geometry, border=\"lightgrey\")\nplot(wm_q_pro_dom, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\n\n\nplot(profit_all$geometry, border=\"lightgrey\")\nplot(wm_r_pro_all, coords_profit_all, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\nplot(profit_all$geometry, border=\"lightgrey\")\nplot(wm_q_pro_all, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = \"purple\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.1.3 Computing Distance Based Neighbors\nIn order to derive distance-based weight matrices, we will implement the dnearneigh() function of the spdep package.\nThis function identifies neighbors of region points by Euclidean Distance with a distance band with lower d1 and upper d2 bounds controlled by the bounds= argument.\nIf un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n2.4.1.3.1 Determining cut-off distance\nWe must first determine the upper limit for the distance band by using the steps shown below:\n\nFind k Nearest Neighbours: Use knearneigh() from the spdep package to get a matrix of indices for the k nearest neighbours of each point.\nConvert to Neighbours List: Convert the knn object returned by knearneigh() into a neighbours list of class nb using knn2nb(). This list contains integer vectors with neighbour region number IDs.\nCalculate Edge Lengths: Use nbdists() from spdep to return the lengths of neighbour relationship edges. The function returns distances in the units of the coordinates if projected, otherwise in kilometers.\nFlatten the List: Remove the list structure of the returned object using unlist()\n\nWe focus on ALL travellers as opposed to singling out Foreign and/or Domestic travellers for the following.\n\nk1_pro_all &lt;- knn2nb(knearneigh(coords_profit_all))\nk1dists_pro_all &lt;- unlist(nbdists(k1_pro_all, coords_profit_all, longlat = TRUE))\nsummary(k1dists_pro_all)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.55   51.92   64.33   63.24   76.77  110.94 \n\n\n\nYou could also do the below if you are interested in singling them out based on foreign and domestic travellers.\n\n\nProfits from foreign travellersProfits from domestic travellers\n\n\n\nk1_pro_foreign &lt;- knn2nb(knearneigh(coords_profit_foreign))\nk1dists_pro_foreign &lt;- unlist(nbdists(k1_pro_foreign, coords_profit_foreign, longlat = TRUE))\nsummary(k1dists_pro_foreign)\n\nFrom the output above, we can infer that the largest first nearest neighbor distance is just under 125KM. Using this value, 125KM, as the upper threshold gives certainty that all units will have at least one neighbor.\n\n\n\nk1_pro_domestic &lt;- knn2nb(knearneigh(coords_profit_domestic))\nk1dists_pro_domestic &lt;- unlist(nbdists(k1_pro_domestic, coords_profit_domestic, longlat = TRUE))\nsummary(k1dists_pro_domestic)\n\n\n\n\n\n\n2.4.1.3.2 Computing Distance Based Weight Matrix\nWe now implement the dnearneigh() function to compute the distance weight matrix.\n\nwm_d62_pro_all &lt;- dnearneigh(coords_profit_all, 0, 111, longlat = TRUE)\nwm_d62_pro_all\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 350 \nPercentage nonzero weights: 5.903188 \nAverage number of links: 4.545455 \n2 disjoint connected subgraphs\n\n\n\nFrom the output above, we infer that there are 69 distinct regions, as we identified earlier. There are 368 connections between regions where the distance is within the threshold that we have set. 7.73% of all possible region pairs have a connection. On average, each region is connected to approximately 5.3 other regions.\n\nWe now use the combination of table() and card() functions from the spdep package to display the structure of the weight matrix.\n\ntable(profit_all$province_eng, card(wm_d62_pro_all))\n\n                          \n                           1 2 3 4 5 6 7 8 9 10 11 12 13 14\n  Amnat Charoen            0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Ang Thong                0 0 0 0 0 0 0 0 0  0  1  0  0  0\n  Bangkok                  0 0 0 0 0 0 0 0 0  0  0  1  0  0\n  Bueng Kan                0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Buri Ram                 0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Chachoengsao             0 0 0 0 0 0 0 0 1  0  0  0  0  0\n  Chai Nat                 0 0 0 0 0 0 1 0 0  0  0  0  0  0\n  Chaiyaphum               0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Chanthaburi              0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Chiang Mai               0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Chiang Rai               1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Chon Buri                0 0 0 0 0 1 0 0 0  0  0  0  0  0\n  Chumphon                 1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Kalasin                  0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Kamphaeng Phet           0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Kanchanaburi             0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Khon Kaen                0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Krabi                    0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Lampang                  0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Lamphun                  0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Loei                     1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Lop Buri                 0 0 0 0 0 0 1 0 0  0  0  0  0  0\n  Mae Hong Son             1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Maha Sarakham            0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Mukdahan                 0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Nakhon Nayok             0 0 0 0 0 0 0 0 0  1  0  0  0  0\n  Nakhon Pathom            0 0 0 0 0 0 0 0 0  1  0  0  0  0\n  Nakhon Phanom            0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Nakhon Ratchasima        1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Nakhon Sawan             0 0 0 0 0 1 0 0 0  0  0  0  0  0\n  Nakhon Si Thammarat      0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Nan                      0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Narathiwat               0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Nong Bua Lam Phu         0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Nong Khai                0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Nonthaburi               0 0 0 0 0 0 0 0 0  0  0  0  1  0\n  Pathum Thani             0 0 0 0 0 0 0 0 0  0  0  0  0  1\n  Pattani                  0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Phangnga                 0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Phatthalung              0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Phayao                   0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Phetchabun               0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Phetchaburi              0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Phichit                  0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Phitsanulok              0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Phra Nakhon Si Ayutthaya 0 0 0 0 0 0 0 0 0  0  0  0  1  0\n  Phrae                    0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Phuket                   0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Prachin Buri             0 0 0 0 0 1 0 0 0  0  0  0  0  0\n  Prachuap Khiri Khan      1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Ranong                   0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Ratchaburi               0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Rayong                   0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Roi Et                   0 0 0 0 1 0 0 0 0  0  0  0  0  0\n  Sa Kaeo                  0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Sakon Nakhon             0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Samut Prakan             0 0 0 0 0 0 0 0 0  1  0  0  0  0\n  Samut Sakhon             0 0 0 0 0 0 0 0 1  0  0  0  0  0\n  Samut Songkhram          0 0 0 0 0 0 0 1 0  0  0  0  0  0\n  Saraburi                 0 0 0 0 0 0 0 0 1  0  0  0  0  0\n  Satun                    0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Si Sa Ket                0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Sing Buri                0 0 0 0 0 0 0 0 0  1  0  0  0  0\n  Songkhla                 0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Sukhothai                0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Suphan Buri              0 0 0 0 0 0 0 0 1  0  0  0  0  0\n  Surat Thani              0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Surin                    0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Tak                      1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Trang                    0 0 0 1 0 0 0 0 0  0  0  0  0  0\n  Trat                     1 0 0 0 0 0 0 0 0  0  0  0  0  0\n  Ubon Ratchathani         0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Udon Thani               0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Uthai Thani              0 0 0 0 0 1 0 0 0  0  0  0  0  0\n  Uttaradit                0 0 1 0 0 0 0 0 0  0  0  0  0  0\n  Yala                     0 1 0 0 0 0 0 0 0  0  0  0  0  0\n  Yasothon                 0 0 1 0 0 0 0 0 0  0  0  0  0  0\n\n\nNext, we implement the n.comp.nb() function to identify the number of connected components in a neighbor list object of class nb.\n\nNote: A connected component is a subset of regions where each region is reachable from any other region within the same subset. The function returns an object that includes the number of connected components (nc) and a vector indicating the component membership for each region.\n\n\nn_comp_pro_all&lt;- n.comp.nb(wm_d62_pro_all)\nn_comp_pro_all$nc\n\n[1] 2\n\n\n\ntable(n_comp_pro_all$comp.id)\n\n\n 1  2 \n63 14 \n\n\n\n\n2.4.1.3.3 Plotting fixed distance weight matrix\nWe now plot the distance weight matrix using the plot() function.\n\nplot(profit_all$geometry, border=\"lightgrey\")\nplot(wm_d62_pro_all, coords_profit_all, add=TRUE)\nplot(k1_pro_all, coords_profit_all, add=TRUE, col=\"purple\", length=0.08)\n\n\n\n\n\n\n\n\nAs identified earlier, we see two distinct groups. The upper 63 and the bottom 14.\n\npar(mfrow=c(1,2))\nplot(profit_all$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1_pro_all, coords_profit_foreign, add=TRUE, col=\"red\", length=0.08)\nplot(profit_all$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62_pro_all, coords_profit_foreign, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n2.4.1.4 Weights based on Inversed Distance Weighting (IDW)\nWe first compute the distances between areas by implementing the nbdists() function of the spdep package.\n\ndist_pro_all &lt;- nbdists(wm_q_pro_all, coords_profit_all, longlat = TRUE)\nids_pro_all &lt;- lapply(dist_pro_all, function(x) 1/(x))\nids_pro_all\n\n[[1]]\n[1] 0.004304527 0.001160634 0.001066433\n\n[[2]]\n[1] 0.012985433 0.001690876 0.002273629 0.001178524\n\n[[3]]\n[1] 0.007462489 0.001950621 0.001878392 0.004449595 0.004722243 0.002947391\n\n[[4]]\n[1] 0.001573833 0.001596968 0.004315842\n\n[[5]]\n[1] 0.015632633 0.003912968 0.004489280 0.007575615 0.001312962\n\n[[6]]\n[1] 0.007462489 0.008317161 0.014028638 0.003155141 0.004087449 0.002035937\n[7] 0.003527405 0.002928580\n\n[[7]]\n[1] 0.003581885 0.002363964 0.001150661 0.001293117\n\n[[8]]\n[1] 0.009952248 0.018047546 0.003860230 0.003001429\n\n[[9]]\n[1] 0.008317161 0.015334899 0.001501404 0.002477496 0.002901933\n\n[[10]]\n[1] 0.003537334 0.007878212 0.004212708 0.007957349 0.001320848\n\n[[11]]\n[1] 0.003537334 0.003736228 0.001328590\n\n[[12]]\n[1] 0.014028638 0.015334899 0.001657611\n\n[[13]]\n[1] 0.001870586 0.001552262 0.001311196\n\n[[14]]\n[1] 0.006701583 0.006503928 0.004354774 0.001595340 0.003356687 0.002124330\n\n[[15]]\n[1] 0.002823347 0.001837465 0.001826891 0.001801133 0.001537177\n\n[[16]]\n[1] 0.002359220 0.006697566 0.001066427 0.001260504 0.001173126\n\n[[17]]\n[1] 0.015632633 0.009952248 0.006701583 0.004725908 0.003907719 0.003558587\n[7] 0.003072110 0.002808776 0.002310335\n\n[[18]]\n[1] 0.002183596 0.002065176 0.001128192 0.001325482\n\n[[19]]\n[1] 0.007878212 0.003736228 0.009026604 0.002035029 0.001407667 0.001652236\n[7] 0.001449637\n\n[[20]]\n[1] 0.004212708 0.009026604 0.001575009\n\n[[21]]\n[1] 0.004725908 0.002660170 0.001937480 0.003080049 0.002215115 0.002573408\n\n[[22]]\n[1] 0.012985433 0.018047546 0.004910079 0.004704466 0.003599849 0.001755660\n[7] 0.002656938 0.002520896\n\n[[23]]\n[1] 0.007957349 0.001346034\n\n[[24]]\n[1] 0.003912968 0.006503928 0.003907719 0.001392161 0.001761791\n\n[[25]]\n[1] 0.004304527 0.004354774 0.001980272 0.001552070 0.002884652 0.001178221\n\n[[26]]\n[1] 0.003155141 0.003558711 0.003382780 0.001352479 0.001584017\n\n[[27]]\n[1] 0.0019506208 0.0023592196 0.0059364663 0.0013983663 0.0020314658\n[6] 0.0017873918 0.0008895808\n\n[[28]]\n[1] 0.001573833 0.001980272 0.002410879\n\n[[29]]\n[1] 0.004489280 0.003860230 0.003558587 0.004910079 0.003558711 0.001870923\n[7] 0.003963653 0.002028040\n\n[[30]]\n[1] 0.0035818850 0.0028233466 0.0047044657 0.0042667164 0.0052617025\n[6] 0.0042537796 0.0010404155 0.0009843316\n\n[[31]]\n[1] 0.0021835958 0.0123436755 0.0009408462 0.0008908885 0.0008955000\n\n[[32]]\n[1] 0.005831318 0.002097865 0.001114347\n\n[[33]]\n[1] 0.0133013891 0.0008980288\n\n[[34]]\n[1] 0.003072110 0.002660170 0.005531089\n\n[[35]]\n[1] 0.001596968 0.001937480 0.002236446 0.005277973\n\n[[36]]\n[1] 0.001878392 0.005936466 0.002734973 0.001604487\n\n[[37]]\n[1] 0.004449595 0.004087449 0.003382780 0.002734973 0.001796205 0.002468228\n\n[[38]]\n[1] 0.0133013891 0.0009426671 0.0009042085\n\n[[39]]\n[1] 0.0020651761 0.0019354986 0.0007996429\n\n[[40]]\n[1] 0.0123436755 0.0021315468 0.0009945834 0.0009414076\n\n[[41]]\n[1] 0.001328590 0.002035029 0.005831318 0.002006311\n\n[[42]]\n[1] 0.003001429 0.002808776 0.003080049 0.003599849 0.004266716 0.003407656\n[7] 0.007482348\n\n[[43]]\n[1] 0.001364908 0.001868686 0.001609008\n\n[[44]]\n[1] 0.001837465 0.005261703 0.003407656 0.004327631\n\n[[45]]\n[1] 0.001826891 0.002215115 0.007482348 0.004327631 0.001033418 0.001055321\n\n[[46]]\n[1] 0.0016908763 0.0017556598 0.0013983663 0.0016044867 0.0017962051\n[6] 0.0043493723 0.0006979124\n\n[[47]]\n[1] 0.0014076669 0.0020978649 0.0020063106 0.0007880819 0.0008352345\n\n[[48]]\nnumeric(0)\n\n[[49]]\n[1] 0.002035937 0.001352479 0.001870923 0.003499025\n\n[[50]]\n[1] 0.001870586 0.001364908\n\n[[51]]\n[1] 0.001552262 0.001935499 0.000722524\n\n[[52]]\n[1] 0.006697566 0.002031466 0.001868686 0.003588130 0.005521926\n\n[[53]]\n[1] 0.001501404 0.001657611\n\n[[54]]\n[1] 0.0015953402 0.0013921607 0.0015520704 0.0010089184 0.0008445359\n[6] 0.0006908864\n\n[[55]]\n[1] 0.007575615 0.003527405 0.002477496 0.003963653 0.003499025\n\n[[56]]\n[1] 0.004315842 0.003356687 0.002884652 0.002410879 0.002236446 0.002178883\n\n[[57]]\n[1] 0.004722243 0.002928580\n\n[[58]]\n[1] 0.002947391 0.001787392 0.003588130 0.009069811\n\n[[59]]\n[1] 0.001609008 0.005521926 0.009069811\n\n[[60]]\n[1] 0.002656938 0.001584017 0.002028040 0.002468228 0.004349372\n\n[[61]]\n[1] 0.002131547 0.001252905 0.001210392\n\n[[62]]\n[1] 0.0022736286 0.0023639641 0.0025208956 0.0042537796 0.0007773996\n\n[[63]]\n[1] 0.001008918 0.005053451 0.002509349 0.001931811\n\n[[64]]\n[1] 0.0009408462 0.0009426671 0.0009945834 0.0012529046 0.0108592161\n\n[[65]]\n[1] 0.0018011331 0.0016522358 0.0010334178 0.0007880819 0.0099562188\n[6] 0.0093594811\n\n[[66]]\n[1] 0.0011785245 0.0011506607 0.0010664269 0.0008895808 0.0006979124\n[6] 0.0007773996 0.0064754571\n\n[[67]]\n[1] 0.0013111958 0.0011281918 0.0008908885 0.0007996429 0.0007225240\n\n[[68]]\n[1] 0.0013129618 0.0017617908 0.0008445359 0.0050534505\n\n[[69]]\n[1] 0.001320848 0.001537177 0.001260504 0.001449637 0.001575009 0.001346034\n[7] 0.001040416 0.009956219 0.012040582\n\n[[70]]\n[1] 0.0013254821 0.0008955000 0.0009414076 0.0012103921\n\n[[71]]\n[1] 0.002901933\n\n[[72]]\n[1] 0.001160634 0.002509349 0.006205971\n\n[[73]]\n[1] 0.002124330 0.002310335 0.002573408 0.005531089 0.005277973 0.002178883\n\n[[74]]\n[1] 0.0012931171 0.0011731257 0.0009843316 0.0064754571 0.0120405815\n\n[[75]]\n[1] 0.0011143468 0.0010553209 0.0008352345 0.0093594811\n\n[[76]]\n[1] 0.0008980288 0.0009042085 0.0108592161\n\n[[77]]\n[1] 0.0010664325 0.0011782214 0.0006908864 0.0019318111 0.0062059708\n\n\n\n\n2.4.1.5 Row-Standardized Weights Matrix\nWe now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.\nThis means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.\nWhile this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.\n\nNote: For simplicity, we’ll use the style=“W” option in this example, but be aware that more robust options, such as style=“B”, are available.\n\n\nProfitsNumber of touristsOccupancy\n\n\n\nrswm_q_pro_all &lt;- nb2listw(wm_q_pro_all, style=\"W\", zero.policy = TRUE)\nrswm_q_pro_all\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\nrswm_q_tour &lt;- nb2listw(wm_q_tour, style=\"W\", zero.policy = TRUE)\nrswm_q_tour\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n70\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\n2019202020212022\n\n\n\nrswm_q_2019 &lt;- nb2listw(wm_q_2019, style=\"W\", zero.policy = TRUE)\nrswm_q_2019\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\nrswm_q_2020 &lt;- nb2listw(wm_q_2020, style=\"W\", zero.policy = TRUE)\nrswm_q_2020\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\nrswm_q_2021 &lt;- nb2listw(wm_q_2021, style=\"W\", zero.policy = TRUE)\nrswm_q_2021\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\nrswm_q_2022 &lt;- nb2listw(wm_q_2022, style=\"W\", zero.policy = TRUE)\nrswm_q_2022\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1      S2\nW 76 5776 76 36.26113 315.652\n\n\n\n\n\n\n\n\nSetting the argument zero.policy to TRUE allows for lists of non-neighbors. This should be used with caution as users may not be aware of missing neighbors in their data however setting zero,policy to FALSE would return an error.\n\nThe nb2listw() function requires an input of class nb, representing a neighborhood object. The function’s two key arguments are style and zero.policy.\n\nThe style argument defines how the weights are calculated. It can take several values:\n\n\"B\": Binary coding, where weights are either 0 or 1.\n\"W\": Row-standardized, where the sum of weights across all neighbors equals 1.\n\"C\": Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.\n\"U\": A variation of \"C\", where weights are normalized by the number of neighbors.\n\"S\": A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.\n\nThe zero.policy argument, when set to TRUE, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector x, effectively setting the lagged value to zero for those regions.\n\n\nThe code chunk below is implemented to check the weights of the first polygons three neighbors type:\n\nrswm_q_pro_all$weights[10]\n\n[[1]]\n[1] 0.2 0.2 0.2 0.2 0.2\n\n\n\nEach neighbor is assigned a 0.33 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\n\nUsing the same method, we derive a row standardized distance weight matrix by using the code chunk below.\n\nrswm_ids_pro_all &lt;- nb2listw(wm_q_pro_all, glist=ids_pro_all, style=\"B\", zero.policy=TRUE)\nrswm_ids_pro_all\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n48\n2 disjoint connected subgraphs\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0         S1        S2\nB 76 5776 1.213098 0.01552322 0.1106777\n\n\n\n\n2.4.1.6 Application of Spatial Weight Matrix\nWe now create two different spatial lagged variables:\n\nspatial lag with row-standardized weights\nspatial window sum\n\n\n2.4.1.6.1 Spatial Lag With Row-Standardized Weights\nWe now compute the average neighbor profit value for each polygon. We often refer to these values as Spatially Lagged Values.\n\npro_all.lag &lt;- lag.listw(rswm_q_pro_all, profit_all$total_value)\npro_all.lag\n\n [1]  15248910000  71904305000  17782063583   5178840000  36013064000\n [6]  31745038750  32105155000  10405027500  12712836300  33305844000\n[11]  22020000000  35697183833   7173613333  16223873333  14814766000\n[16]  27425816000  67352080889 212310945000  45577798571  21752636667\n[21]   4584020000 270772546000  24977540000  20078698000   4460971667\n[26]  23296622300  44589101714  32263766667  17276292250  24668200588\n[31] 203675776000  86141040000  10075095000 163646976667 142613772500\n[36]  80010247500  57489828583  65740183333  10838346667 250877220000\n[41]  65822225000  77822444000   8713083333   6442295000 119772565000\n[46] 278672914286  50654714000            0  23475485375  15365575000\n[51]   9887916667  10243580400  46938295000  30342651667  28203860300\n[56]  18890338333   8793150750   6465472500  11795120000  77961440000\n[61] 333411596667 377157446940  27488695000   6144732000  47679541667\n[66] 322168826671  12065114000  25180272500  30452323556   6594607500\n[71]  83774300000   8448340000  84276121667   9224755340  43124960000\n[76]  59620853333  12093334000\n\n\nWe can append the spatially lagged profit values onto our profit_foreigners sf data-frame by using the code chunk shown below.\n\nlag.list_pro_all &lt;- list(profit_all$province_eng, lag.listw(rswm_q_pro_all, profit_all$total_value))\nlag.res_pro_all &lt;- as.data.frame(lag.list_pro_all)\ncolnames(lag.res_pro_all) &lt;- c(\"province_eng\", \"lag Profit\")\nprofit_all &lt;- left_join(profit_all,lag.res_pro_all)\n\nWe now plot the actual profit and spatial lag profits side by side to facilitate comparison.\n\npro_all &lt;- qtm(profit_all, \"total_value\")\nlag_pro_all &lt;- qtm(profit_all, \"lag Profit\")\ntmap_arrange(pro_all, lag_pro_all, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe see a difference in the surrounding regions of Bangkok as well as Mae Hong Son, all of which are in a higher band as compared to the non-spatially lagged values.\n\n\n2.4.1.6.2 Spatial Window Sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs_profit &lt;- include.self(wm_q_pro_all)\nwm_qs_profit\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 429 \nPercentage nonzero weights: 7.235622 \nAverage number of links: 5.571429 \n2 disjoint connected subgraphs\n\n\nWe now assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs_profit, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1\n\n\nNotice that now [1] has four neighbours instead of three.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs_profit, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 429 \nPercentage nonzero weights: 7.235622 \nAverage number of links: 5.571429 \n2 disjoint connected subgraphs\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 77 5929 429 858 10572\n\n\nWith our newly obtained weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_profit &lt;- list(profit_all$province_eng, lag.listw(b_weights2, profit_all$total_value))\nw_sum_profit\n\n[[1]]\n [1] \"Ang Thong\"                \"Bangkok\"                 \n [3] \"Chai Nat\"                 \"Kanchanaburi\"            \n [5] \"Lop Buri\"                 \"Nakhon Pathom\"           \n [7] \"Nonthaburi\"               \"Pathum Thani\"            \n [9] \"Phetchaburi\"              \"Phra Nakhon Si Ayutthaya\"\n[11] \"Prachuap Khiri Khan\"      \"Ratchaburi\"              \n[13] \"Samut Prakan\"             \"Samut Sakhon\"            \n[15] \"Samut Songkhram\"          \"Saraburi\"                \n[17] \"Sing Buri\"                \"Suphan Buri\"             \n[19] \"Chachoengsao\"             \"Chanthaburi\"             \n[21] \"Chon Buri\"                \"Nakhon Nayok\"            \n[23] \"Prachin Buri\"             \"Rayong\"                  \n[25] \"Sa Kaeo\"                  \"Trat\"                    \n[27] \"Amnat Charoen\"            \"Bueng Kan\"               \n[29] \"Buri Ram\"                 \"Chaiyaphum\"              \n[31] \"Kalasin\"                  \"Khon Kaen\"               \n[33] \"Loei\"                     \"Maha Sarakham\"           \n[35] \"Mukdahan\"                 \"Nakhon Phanom\"           \n[37] \"Nakhon Ratchasima\"        \"Nong Bua Lam Phu\"        \n[39] \"Nong Khai\"                \"Roi Et\"                  \n[41] \"Sakon Nakhon\"             \"Surin\"                   \n[43] \"Ubon Ratchathani\"         \"Udon Thani\"              \n[45] \"Yasothon\"                 \"Chiang Mai\"              \n[47] \"Chiang Rai\"               \"Kamphaeng Phet\"          \n[49] \"Lampang\"                  \"Lamphun\"                 \n[51] \"Mae Hong Son\"             \"Nakhon Sawan\"            \n[53] \"Nan\"                      \"Phayao\"                  \n[55] \"Phetchabun\"               \"Phichit\"                 \n[57] \"Phitsanulok\"              \"Phrae\"                   \n[59] \"Sukhothai\"                \"Tak\"                     \n[61] \"Uthai Thani\"              \"Uttaradit\"               \n[63] \"Chumphon\"                 \"Krabi\"                   \n[65] \"Nakhon Si Thammarat\"      \"Narathiwat\"              \n[67] \"Pattani\"                  \"Phangnga\"                \n[69] \"Phatthalung\"              \"Phuket\"                  \n[71] \"Ranong\"                   \"Satun\"                   \n[73] \"Si Sa Ket\"                \"Songkhla\"                \n[75] \"Surat Thani\"              \"Trang\"                   \n[77] \"Yala\"                    \n\n[[2]]\n [1] 4.830338e+10 2.134585e+12 1.101507e+11 9.340557e+10 1.946905e+11\n [6] 2.680883e+11 1.396260e+11 4.928399e+10 1.473385e+11 2.103152e+11\n[11] 1.772473e+11 1.171938e+11 3.554698e+10 1.016263e+11 8.539054e+10\n[16] 1.552375e+11 6.085889e+11 8.650487e+11 3.343474e+11 8.676681e+10\n[21] 5.111633e+11 2.183154e+12 6.231617e+10 1.664943e+11 4.162284e+10\n[26] 1.587393e+11 3.131988e+11 9.978200e+10 1.532802e+11 2.028048e+11\n[31] 1.021204e+12 2.996642e+11 3.231268e+10 4.936895e+11 5.789357e+11\n[36] 3.266903e+11 4.004009e+11 1.981167e+11 4.581352e+10 1.007159e+12\n[41] 2.702601e+11 5.519137e+11 4.284426e+10 5.251363e+10 7.204721e+11\n[46] 2.210756e+12 3.488313e+11 4.543780e+09 1.073239e+11 3.554191e+10\n[51] 4.403470e+10 6.355763e+10 1.030658e+11 1.870943e+11 1.634672e+11\n[56] 1.174073e+11 4.062376e+10 3.220251e+10 4.437412e+10 4.082087e+11\n[61] 1.004334e+12 1.891204e+12 1.249114e+11 1.965276e+11 3.199416e+11\n[66] 2.260363e+12 6.266470e+10 1.747477e+11 2.802401e+11 8.571596e+11\n[71] 9.147103e+10 4.840299e+10 5.105184e+11 1.584872e+11 3.283940e+11\n[76] 1.981167e+11 6.829842e+10\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_profit.res &lt;- as.data.frame(w_sum_profit)\ncolnames(w_sum_profit.res) &lt;- c(\"province_eng\", \"w_sum Profit\")\n\n\nDo note that the second command line on the code chunk above renames the field names of w_sum_profit.res object into province_eng and w_sum Profit respectively.\n\nNext, the code chunk below will be used to append w_sum Profit values onto our profit sf data.frame by using left_join() of dplyr package.\n\nprofit_all &lt;- left_join(profit_all, w_sum_profit.res)\n\nTo compare the values of lag Profit and Spatial window average, the kable() function of the Knitr package is used to prepare a table using the code chunk below.\n\nprofit_all %&gt;%\n  select(\"province_eng\", \"total_value\", \"w_sum Profit\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nprovince_eng\ntotal_value\nw_sum Profit\ngeometry\n\n\n\n\nAng Thong\n2.556650e+09\n4.830338e+10\nMULTIPOLYGON (((100.3332 14…\n\n\nBangkok\n1.846967e+12\n2.134585e+12\nMULTIPOLYGON (((100.6139 13…\n\n\nChai Nat\n3.458300e+09\n1.101507e+11\nMULTIPOLYGON (((100.1199 15…\n\n\nKanchanaburi\n7.786905e+10\n9.340557e+10\nMULTIPOLYGON (((98.58631 15…\n\n\nLop Buri\n1.462523e+10\n1.946905e+11\nMULTIPOLYGON (((101.3453 15…\n\n\nNakhon Pathom\n1.412800e+10\n2.680883e+11\nMULTIPOLYGON (((100.2231 14…\n\n\nNonthaburi\n1.120537e+10\n1.396260e+11\nMULTIPOLYGON (((100.3415 14…\n\n\nPathum Thani\n7.663878e+09\n4.928399e+10\nMULTIPOLYGON (((100.8916 14…\n\n\nPhetchaburi\n8.377430e+10\n1.473385e+11\nMULTIPOLYGON (((99.75869 13…\n\n\nPhra Nakhon Si Ayutthaya\n4.378594e+10\n2.103152e+11\nMULTIPOLYGON (((100.5131 14…\n\n\nPrachuap Khiri Khan\n1.111873e+11\n1.772473e+11\nMULTIPOLYGON (((99.56326 11…\n\n\nRatchaburi\n1.010229e+10\n1.171938e+11\nMULTIPOLYGON (((99.8821 13….\n\n\nSamut Prakan\n1.402614e+10\n3.554698e+10\nMULTIPOLYGON (((100.7306 13…\n\n\nSamut Sakhon\n4.283070e+09\n1.016263e+11\nMULTIPOLYGON (((100.3091 13…\n\n\nSamut Songkhram\n1.131671e+10\n8.539054e+10\nMULTIPOLYGON (((100.0116 13…\n\n\nSaraburi\n1.810841e+10\n1.552375e+11\nMULTIPOLYGON (((101.3994 15…\n\n\nSing Buri\n2.420130e+09\n6.085889e+11\nMULTIPOLYGON (((100.3691 15…\n\n\nSuphan Buri\n1.580496e+10\n8.650487e+11\nMULTIPOLYGON (((99.37118 15…\n\n\nChachoengsao\n1.530283e+10\n3.343474e+11\nMULTIPOLYGON (((101.0612 13…\n\n\nChanthaburi\n2.150890e+10\n8.676681e+10\nMULTIPOLYGON (((102.2517 12…\n\n\nChon Buri\n4.836592e+11\n5.111633e+11\nMULTIPOLYGON (((100.9719 12…\n\n\nNakhon Nayok\n1.697358e+10\n2.183154e+12\nMULTIPOLYGON (((101.2827 14…\n\n\nPrachin Buri\n1.236109e+10\n6.231617e+10\nMULTIPOLYGON (((101.4881 14…\n\n\nRayong\n6.610082e+10\n1.664943e+11\nMULTIPOLYGON (((101.4421 12…\n\n\nSa Kaeo\n1.485701e+10\n4.162284e+10\nMULTIPOLYGON (((102.1877 14…\n\n\nTrat\n4.225621e+10\n1.587393e+11\nMULTIPOLYGON (((102.5216 11…\n\n\nAmnat Charoen\n1.075100e+09\n3.131988e+11\nMULTIPOLYGON (((104.9598 16…\n\n\nBueng Kan\n2.990700e+09\n9.978200e+10\nMULTIPOLYGON (((103.405 18….\n\n\nBuri Ram\n1.506982e+10\n1.532802e+11\nMULTIPOLYGON (((102.9303 15…\n\n\nChaiyaphum\n5.459210e+09\n2.028048e+11\nMULTIPOLYGON (((101.5603 16…\n\n\nKalasin\n2.825040e+09\n1.021204e+12\nMULTIPOLYGON (((103.584 17….\n\n\nKhon Kaen\n4.124104e+10\n2.996642e+11\nMULTIPOLYGON (((102.7072 17…\n\n\nLoei\n1.216249e+10\n3.231268e+10\nMULTIPOLYGON (((102.095 18….\n\n\nMaha Sarakham\n2.748530e+09\n4.936895e+11\nMULTIPOLYGON (((103.1562 16…\n\n\nMukdahan\n8.480580e+09\n5.789357e+11\nMULTIPOLYGON (((104.2527 16…\n\n\nNakhon Phanom\n6.649310e+09\n3.266903e+11\nMULTIPOLYGON (((104.192 18….\n\n\nNakhon Ratchasima\n5.546189e+10\n4.004009e+11\nMULTIPOLYGON (((102.3144 15…\n\n\nNong Bua Lam Phu\n8.961000e+08\n1.981167e+11\nMULTIPOLYGON (((102.2866 17…\n\n\nNong Khai\n1.329848e+10\n4.581352e+10\nMULTIPOLYGON (((103.2985 18…\n\n\nRoi Et\n3.649690e+09\n1.007159e+12\nMULTIPOLYGON (((104.314 16….\n\n\nSakon Nakhon\n6.971230e+09\n2.702601e+11\nMULTIPOLYGON (((103.5404 18…\n\n\nSurin\n7.156580e+09\n5.519137e+11\nMULTIPOLYGON (((103.1336 15…\n\n\nUbon Ratchathani\n1.670501e+10\n4.284426e+10\nMULTIPOLYGON (((105.0633 16…\n\n\nUdon Thani\n2.674445e+10\n5.251363e+10\nMULTIPOLYGON (((102.0581 18…\n\n\nYasothon\n1.836680e+09\n7.204721e+11\nMULTIPOLYGON (((104.3952 16…\n\n\nChiang Mai\n2.600457e+11\n2.210756e+12\nMULTIPOLYGON (((99.52512 20…\n\n\nChiang Rai\n9.555777e+10\n3.488313e+11\nMULTIPOLYGON (((99.96093 20…\n\n\nKamphaeng Phet\n4.543780e+09\n4.543780e+09\nMULTIPOLYGON (((99.48875 16…\n\n\nLampang\n1.342195e+10\n1.073239e+11\nMULTIPOLYGON (((99.58445 19…\n\n\nLamphun\n4.810760e+09\n3.554191e+10\nMULTIPOLYGON (((99.18821 18…\n\n\nMae Hong Son\n1.437095e+10\n4.403470e+10\nMULTIPOLYGON (((98.0591 19….\n\n\nNakhon Sawan\n1.233973e+10\n6.355763e+10\nMULTIPOLYGON (((100.0266 16…\n\n\nNan\n9.189250e+09\n1.030658e+11\nMULTIPOLYGON (((100.8948 19…\n\n\nPhayao\n5.038420e+09\n1.870943e+11\nMULTIPOLYGON (((100.4195 19…\n\n\nPhetchabun\n2.244791e+10\n1.634672e+11\nMULTIPOLYGON (((101.3987 17…\n\n\nPhichit\n4.065240e+09\n1.174073e+11\nMULTIPOLYGON (((100.2165 16…\n\n\nPhitsanulok\n2.303746e+10\n4.062376e+10\nMULTIPOLYGON (((101.0033 17…\n\n\nPhrae\n6.340620e+09\n3.220251e+10\nMULTIPOLYGON (((100.1597 18…\n\n\nSukhothai\n8.988760e+09\n4.437412e+10\nMULTIPOLYGON (((99.60051 17…\n\n\nTak\n1.840145e+10\n4.082087e+11\nMULTIPOLYGON (((97.97318 17…\n\n\nUthai Thani\n4.098740e+09\n1.004334e+12\nMULTIPOLYGON (((99.13905 15…\n\n\nUttaradit\n5.416300e+09\n1.891204e+12\nMULTIPOLYGON (((101.0924 18…\n\n\nChumphon\n1.495662e+10\n1.249114e+11\nMULTIPOLYGON (((99.19067 10…\n\n\nKrabi\n1.658040e+11\n1.965276e+11\nMULTIPOLYGON (((99.11329 7….\n\n\nNakhon Si Thammarat\n3.386435e+10\n3.199416e+11\nMULTIPOLYGON (((99.77467 9….\n\n\nNarathiwat\n5.181640e+09\n2.260363e+12\nMULTIPOLYGON (((101.6323 6….\n\n\nPattani\n2.339130e+09\n6.266470e+10\nMULTIPOLYGON (((101.2827 6….\n\n\nPhangnga\n7.402664e+10\n1.747477e+11\nMULTIPOLYGON (((98.61471 7….\n\n\nPhatthalung\n6.169140e+09\n2.802401e+11\nMULTIPOLYGON (((99.96416 7….\n\n\nPhuket\n8.307811e+11\n8.571596e+11\nMULTIPOLYGON (((98.31437 7….\n\n\nRanong\n7.696730e+09\n9.147103e+10\nMULTIPOLYGON (((98.35294 9….\n\n\nSatun\n2.305797e+10\n4.840299e+10\nMULTIPOLYGON (((100.0903 6….\n\n\nSi Sa Ket\n4.861620e+09\n5.105184e+11\nMULTIPOLYGON (((104.1052 15…\n\n\nSongkhla\n1.123635e+11\n1.584872e+11\nMULTIPOLYGON (((100.5973 7….\n\n\nSurat Thani\n1.558941e+11\n3.283940e+11\nMULTIPOLYGON (((99.96396 9….\n\n\nTrang\n1.925409e+10\n1.981167e+11\nMULTIPOLYGON (((99.47579 6….\n\n\nYala\n7.831750e+09\n6.829842e+10\nMULTIPOLYGON (((101.2927 6….\n\n\n\n\n\nWe now plot the actual profit and w_sum_profit maps next to each other using the qtm() function of the tmap package.\n\n# Create the first map for 'total_value' using Jenks classification\nprofit_map &lt;- tm_shape(profit_all) +\n              tm_polygons(\"total_value\", style = \"jenks\", palette = \"Blues\", title = \"Total Value\") +\n              tm_layout(legend.outside = TRUE)\n\n# Create the second map for 'w_sum Profit' using Jenks classification\nw_sum_profit_map &lt;- tm_shape(profit_all) +\n                    tm_polygons(\"w_sum Profit\", style = \"jenks\", palette = \"Reds\", title = \"W Sum Profit\") +\n                    tm_layout(legend.outside = TRUE)\ntmap_arrange(profit_map, w_sum_profit_map, ncol = 2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "2.4.2 Global Measures of Spatial Autocorrelation",
    "text": "2.4.2 Global Measures of Spatial Autocorrelation\n\n2.4.2.1 Moran’s I test2.4.2.2 Geary’s C2.4.2.3 Spatial Correlogram\n\n\nWe now conduct Moran’s I statistics testing by using the moran.test() function of the spdep package.\n\nStatistical tests are conducted at a 5% significance level.\n\n\nProfitNumber of TouristsOccupancy Rate\n\n\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar levels of profit from tourism are randomly distributed.\nH1: Regions with similar levels of profit from tourism are not randomly distributed and exhibit spatial clustering.\n\n\nmoran.test(profit_all$total_value, \n           listw=rswm_q_pro_all, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  profit_all$total_value  \nweights: rswm_q_pro_all  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 0.065612, p-value = 0.4738\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     -0.010147395      -0.013333333       0.002357817 \n\n\nWe do not have sufficient evidence to reject H0, the observed p-value&gt;0.05.\n\n\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar numbers of tourists from tourism are randomly distributed.\nH1: Regions with similar tourists from tourism are not randomly distributed and exhibit spatial clustering.\n\n\nmoran.test(tourist_all$total_value, \n           listw=rswm_q_tour, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  tourist_all$total_value  \nweights: rswm_q_tour  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 0.24853, p-value = 0.4019\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     -0.001276884      -0.013333333       0.002353354 \n\n\n\n\nThe hypotheses for the test are as follows:\n\nH0: Regions with similar levels of occupancy are randomly distributed.\nH1: Regions with similar levels of occupancy are not randomly distributed and exhibit spatial clustering.\n\n\n2019202020212022\n\n\n\nmoran.test(occupancy_2019_avg$avg_occupancy, \n           listw=rswm_q_2019, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  occupancy_2019_avg$avg_occupancy  \nweights: rswm_q_2019  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 1.078, p-value = 0.1405\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.069367921      -0.013333333       0.005885618 \n\n\n\n\n\nmoran.test(occupancy_2020_avg$avg_occupancy, \n           listw=rswm_q_2020, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  occupancy_2020_avg$avg_occupancy  \nweights: rswm_q_2020  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 4.9018, p-value = 4.748e-07\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.365225001      -0.013333333       0.005964181 \n\n\n\n\n\nmoran.test(occupancy_2021_avg$avg_occupancy, \n           listw=rswm_q_2021, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  occupancy_2021_avg$avg_occupancy  \nweights: rswm_q_2021  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 3.5428, p-value = 0.000198\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.259295540      -0.013333333       0.005921797 \n\n\n\n\n\nmoran.test(occupancy_2022_avg$avg_occupancy, \n           listw=rswm_q_2022, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  occupancy_2022_avg$avg_occupancy  \nweights: rswm_q_2022  \nn reduced by no-neighbour observations  \n\nMoran I statistic standard deviate = 3.0146, p-value = 0.001287\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.218650983      -0.013333333       0.005921784 \n\n\n\n\n\nBesides 2019, there does appear to be spatial clustering with regards to occupancy rates through the years. We have sufficienct evidence to reject the null hypothesis.\n\n\n\n\nIf Morans I Statistic is = 0, there is Complete Random Spatial Distribution.\n\n\n2.4.2.1.1 Monte Carlo Moran’s I\nWe now implement the moran.mc() function of the spdep package. In this scenario, we will run 1000 simulations.\n\nProfitNumber of touristsOccupancy\n\n\n\nbperm= moran.mc(profit_all$total_value, \n           listw=rswm_q_pro_all, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  profit_all$total_value \nweights: rswm_q_pro_all  \nnumber of simulations + 1: 1000 \n\nstatistic = -0.010147, observed rank = 697, p-value = 0.303\nalternative hypothesis: greater\n\n\n\n\n\nbperm= moran.mc(tourist_all$total_value, \n           listw=rswm_q_tour, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  tourist_all$total_value \nweights: rswm_q_tour  \nnumber of simulations + 1: 1000 \n\nstatistic = -0.0012769, observed rank = 655, p-value = 0.345\nalternative hypothesis: greater\n\n\n\n\n\n2019202020212022\n\n\n\nbperm= moran.mc(occupancy_2019_avg$avg_occupancy, \n           listw=rswm_q_pro_all, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  occupancy_2019_avg$avg_occupancy \nweights: rswm_q_pro_all  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.065701, observed rank = 856, p-value = 0.144\nalternative hypothesis: greater\n\n\n\n\n\nbperm2020= moran.mc(occupancy_2020_avg$avg_occupancy, \n           listw=rswm_q_2020, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm2020\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  occupancy_2020_avg$avg_occupancy \nweights: rswm_q_2020  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.36523, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nbperm2021= moran.mc(occupancy_2021_avg$avg_occupancy, \n           listw=rswm_q_2021, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm2021\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  occupancy_2021_avg$avg_occupancy \nweights: rswm_q_2021  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.2593, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nbperm2022= moran.mc(occupancy_2022_avg$avg_occupancy, \n           listw=rswm_q_2022, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  occupancy_2019_avg$avg_occupancy \nweights: rswm_q_pro_all  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.065701, observed rank = 856, p-value = 0.144\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\n\nGenerally, you’ll see that the monte carlo simulations reinforce our findings from the initial Moran’s test. However do note important output values of the monte-carlo simulation such as the observed rank which can indicate to you how low/high that specific test statistic value is compared to all others in the simulation\n\nWe visualize the test statistics obtained from the above simulation by implementing the below code chunk.\n\nSummary StatisticsThe plot\n\n\n\n# Mean\nmean(bperm$res[1:999])\n\n[1] -0.01371676\n\n# Variance\nvar(bperm$res[1:999])\n\n[1] 0.005616186\n\n# Summary\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.22415 -0.06916 -0.01685 -0.01372  0.03682  0.23088 \n\n\n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe now implement a further test to verify if our findings from the above test are indeed correct.\nThe Geary’s C test for spatial autocorrelation is implemented by using the geary.test() function of the spdep package.\nOften, these results reinforce the Moran’s test.\n\nProfitNumber of touristsOccupancy Rate\n\n\n\ngeary.test(profit_all$total_value, listw=rswm_q_pro_all)\n\n\n    Geary C test under randomisation\n\ndata:  profit_all$total_value \nweights: rswm_q_pro_all  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = 0.89723, p-value = 0.1848\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       0.85789622        1.00000000        0.02508438 \n\n\n\n\n\ngeary.test(tourist_all$total_value, listw=rswm_q_tour)\n\n\n    Geary C test under randomisation\n\ndata:  tourist_all$total_value \nweights: rswm_q_tour  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = -0.86246, p-value = 0.8058\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       1.13666038        1.00000000        0.02510762 \n\n\n\n\n\n2019202020212022\n\n\n\ngeary.test(occupancy_2019_avg$avg_occupancy, listw=rswm_q_2019)\n\n\n    Geary C test under randomisation\n\ndata:  occupancy_2019_avg$avg_occupancy \nweights: rswm_q_2019  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = 1.3731, p-value = 0.08486\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.887473023       1.000000000       0.006715942 \n\n\n\n\n\ngeary.test(occupancy_2020_avg$avg_occupancy, listw=rswm_q_2020)\n\n\n    Geary C test under randomisation\n\ndata:  occupancy_2020_avg$avg_occupancy \nweights: rswm_q_2020  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = 4.977, p-value = 3.228e-07\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.604743349       1.000000000       0.006306885 \n\n\n\n\n\ngeary.test(occupancy_2021_avg$avg_occupancy, listw=rswm_q_2021)\n\n\n    Geary C test under randomisation\n\ndata:  occupancy_2021_avg$avg_occupancy \nweights: rswm_q_2021  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = 3.5783, p-value = 0.0001729\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.710899976       1.000000000       0.006527571 \n\n\n\n\n\ngeary.test(occupancy_2022_avg$avg_occupancy, listw=rswm_q_2022)\n\n\n    Geary C test under randomisation\n\ndata:  occupancy_2022_avg$avg_occupancy \nweights: rswm_q_2022  \nn reduced by no-neighbour observations \n\nGeary C statistic standard deviate = 3.5359, p-value = 0.0002032\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.714319646       1.000000000       0.006527638 \n\n\n\n\n\n\n\n\n\n2.4.2.2.1 Monte Carlo Geary’s C\nWe implement the the geary.mc() function of the spdep package to conduct 1000 simulations.\n\nProfitOccupancy RateOccupancy Rate\n\n\n\nbperm=geary.mc(profit_all$total_value, listw=rswm_q_pro_all, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  profit_all$total_value \nweights: rswm_q_pro_all  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.8579, observed rank = 168, p-value = 0.168\nalternative hypothesis: greater\n\n\nThe simulations above reinforce our earlier conclusion.\n\n\n\nbperm_tour=geary.mc(tourist_all$total_value, listw=rswm_q_tour, \n               nsim=999)\nbperm_tour\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  tourist_all$total_value \nweights: rswm_q_tour  \nnumber of simulations + 1: 1000 \n\nstatistic = 1.1367, observed rank = 837, p-value = 0.837\nalternative hypothesis: greater\n\n\n\n\n\n2019202020212022\n\n\n\nbperm2019_geary=geary.mc(occupancy_2019_avg$avg_occupancy, listw=rswm_q_2019, \n               nsim=999)\nbperm2019_geary\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  occupancy_2019_avg$avg_occupancy \nweights: rswm_q_2019  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.88747, observed rank = 120, p-value = 0.12\nalternative hypothesis: greater\n\n\n\n\n\nbperm2020_geary=geary.mc(occupancy_2020_avg$avg_occupancy, listw=rswm_q_2020, \n               nsim=999)\nbperm2020_geary\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  occupancy_2020_avg$avg_occupancy \nweights: rswm_q_2020  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.60474, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\nbperm2021_geary=geary.mc(occupancy_2021_avg$avg_occupancy, listw=rswm_q_2021, \n               nsim=999)\nbperm2021_geary\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  occupancy_2021_avg$avg_occupancy \nweights: rswm_q_2021  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.7109, observed rank = 2, p-value = 0.002\nalternative hypothesis: greater\n\n\n\n\n\nbperm2022_geary=geary.mc(occupancy_2022_avg$avg_occupancy, listw=rswm_q_2022, \n               nsim=999)\nbperm2022_geary\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  occupancy_2022_avg$avg_occupancy \nweights: rswm_q_2022  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.71432, observed rank = 3, p-value = 0.003\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\n\n\n\nSpatial correlograms are a powerful tool for analyzing patterns of spatial autocorrelation in your data or model residuals. They illustrate how the correlation between pairs of spatial observations changes as the distance (or lag) between them increases. Essentially, they plot an index of autocorrelation, such as Moran’s I or Geary’s C, against distance.\nWhile correlograms are not as central to geostatistics as variograms—an essential concept in that field—they offer valuable insights as an exploratory and descriptive tool. In fact, for examining spatial autocorrelation, correlograms often provide more detailed information than variograms, making them particularly useful for initial spatial data analysis.\n\nMoran’s I CorrelogramGeary’s C Correlogram\n\n\nWe implement the sp.correlogram() function of the spdep package to compute a 6-lag spatial correlogram of profit from tourism in Thailand. The global spatial autocorrelation used in Moran’s I.\nThe plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q_pro_all, \n                          profit_all$total_value, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\", zero.policy = TRUE)\nplot(MI_corr)\n\n\n\n\n\n\n\n\nThe plot above may not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for profit_all$total_value \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided\n1 (76) -0.0101474  -0.0133333  0.0023578           0.0656          0.9477\n2 (76) -0.0176961  -0.0133333  0.0014567          -0.1143          0.9090\n3 (76) -0.0191112  -0.0133333  0.0011568          -0.1699          0.8651\n4 (76) -0.0304960  -0.0133333  0.0012360          -0.4882          0.6254\n5 (76) -0.0175200  -0.0133333  0.0013957          -0.1121          0.9108\n6 (76) -0.0254808  -0.0133333  0.0020155          -0.2706          0.7867\n\n\nFrom above, we can conclude that there is NO spatial autocorrelation.\n\n\nWe implement the sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of total_value, profit. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q_pro_all, \n                          profit_all$total_value, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\", zero.policy = TRUE)\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the step done for Moran’s I, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for profit_all$total_value \nmethod: Geary's C\n       estimate expectation variance standard deviate Pr(I) two sided\n1 (76) 0.857896    1.000000 0.025084          -0.8972          0.3696\n2 (76) 0.943719    1.000000 0.021602          -0.3829          0.7018\n3 (76) 1.010709    1.000000 0.022887           0.0708          0.9436\n4 (76) 1.082440    1.000000 0.037279           0.4270          0.6694\n5 (76) 0.884287    1.000000 0.079390          -0.4107          0.6813\n6 (76) 0.711056    1.000000 0.161791          -0.7183          0.4725\n\n\nIndeed, our findings are reinforced.\n\n\n\n\n\n\n\nGenerally, using one of the Geary or Moran Test is enough in terms of deriving insights. However, we apply both in our case to have more evidence to support our claims of the spatial clustering exhibited in certain aspects, and the lack thereof in certain aspects."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#local-indicators-of-spatial-association",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#local-indicators-of-spatial-association",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "2.4.3 Local Indicators of Spatial Association",
    "text": "2.4.3 Local Indicators of Spatial Association\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of profits from tourism across Thailand, local clusters in profit mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\n\n2.4.3.1 Computing Local Moran’s I\nWe implement the localmoran() function of spdep compute the local Moran’s I statistic. This function helps us compute li values, given a set of zi values and a listw object providing neighbor weighting information for the polygon associated with the zi values.\nWe compute Local Moran’s I for Profits from Tourism at the County Level\n\nProfitsNumber of tourists\n\n\n\nfips &lt;- order(profit_all$province_eng)\nlocalMI &lt;- localmoran(profit_all$total_value, rswm_q_pro_all)\nhead(localMI)\n\n           Ii          E.Ii       Var.Ii       Z.Ii Pr(z != E(Ii))\n1  0.06181623 -1.012111e-03 0.0252591992  0.3953173      0.6926088\n2  0.15435147 -7.673501e-01 3.2991219598  0.5074475      0.6118408\n3  0.05798144 -9.840716e-04 0.0117753912  0.5433884      0.5868624\n4 -0.01218856 -2.760711e-05 0.0006896679 -0.4630711      0.6433134\n5  0.03017796 -6.694470e-04 0.0097531108  0.3123540      0.7547715\n6  0.03463324 -6.821710e-04 0.0059490181  0.4578695      0.6470462\n\n\n\n\n\nfips_tour &lt;- order(tourist_all$province_eng)\nlocalMI_tour &lt;- localmoran(tourist_all$total_value, rswm_q_tour)\nhead(localMI_tour)\n\n             Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.0380628637 -2.521443e-03 4.647878e-02 -0.16485701   0.8690565295\n2 -1.0645919900 -7.791818e-01 2.060867e+00 -0.19881290   0.8424091066\n3  0.1155194004 -2.384943e-03 4.396864e-02  0.56228734   0.5739202607\n4 -0.2075133865 -2.174592e-02 3.101325e-01 -0.33357695   0.7386988143\n5  0.0002423068 -9.920520e-06 8.657221e-05  0.02710833   0.9783733287\n6  0.0015776720 -1.971715e-08 1.995375e-07  3.53191182   0.0004125669\n\n\n\n\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nWe now use the printCoefmat() to display the content of the local Moran matrix that we created.\n\nProfitNumber of tourists\n\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=profit_all$province_eng[fips]),\n  check.names=FALSE)\n\n                                  Ii        E.Ii      Var.Ii        Z.Ii\nAmnat Charoen             2.7517e-02 -1.0590e-03  1.0706e-02  2.7618e-01\nAng Thong                 6.1816e-02 -1.0121e-03  2.5259e-02  3.9532e-01\nBangkok                   1.5435e-01 -7.6735e-01  3.2991e+00  5.0745e-01\nBueng Kan                 4.1289e-02 -9.9856e-04  2.4921e-02  2.6787e-01\nBuri Ram                  4.7904e-02 -6.5817e-04  5.7399e-03  6.4098e-01\nChachoengsao              2.0651e-02 -6.5230e-04  6.5970e-03  2.6229e-01\nChai Nat                  5.7981e-02 -9.8407e-04  1.1775e-02  5.4339e-01\nChaiyaphum                4.8334e-02 -9.2325e-04  8.0495e-03  5.4902e-01\nChanthaburi               3.8221e-02 -5.0560e-04  1.2625e-02  3.4466e-01\nChiang Mai                7.5088e-01 -9.0097e-03  9.0357e-02  2.5279e+00\nChiang Rai               -8.6369e-03 -1.9489e-04  2.8407e-03 -1.5839e-01\nChon Buri                -4.8006e-01 -4.2017e-02  4.8212e-01 -6.3087e-01\nChumphon                  3.8186e-02 -6.6103e-04  1.2208e-02  3.5159e-01\nKalasin                  -1.6174e-01 -1.0037e-03  1.4618e-02 -1.3295e+00\nKamphaeng Phet            0.0000e+00  0.0000e+00  0.0000e+00         NaN\nKanchanaburi             -1.2189e-02 -2.7607e-05  6.8967e-04 -4.6307e-01\nKhon Kaen                -9.0533e-03 -1.6317e-04  4.0756e-03 -1.3926e-01\nKrabi                    -1.1084e-01 -2.3556e-03  3.4261e-02 -5.8607e-01\nLampang                   4.3281e-02 -7.0044e-04  1.2935e-02  3.8671e-01\nLamphun                   5.9526e-02 -9.4275e-04  3.5778e-02  3.1969e-01\nLoei                      5.7872e-02 -7.3364e-04  2.7848e-02  3.5119e-01\nLop Buri                  3.0178e-02 -6.6945e-04  9.7531e-03  3.1235e-01\nMae Hong Son              5.5731e-02 -6.7594e-04  1.6875e-02  4.3422e-01\nMaha Sarakham            -1.1444e-01 -1.0061e-03  2.5110e-02 -7.1586e-01\nMukdahan                 -8.1527e-02 -8.3509e-04  1.5420e-02 -6.4982e-01\nNakhon Nayok             -1.8823e-01 -6.1097e-04  5.3285e-03 -2.5702e+00\nNakhon Pathom             3.4633e-02 -6.8217e-04  5.9490e-03  4.5787e-01\nNakhon Phanom            -1.4286e-02 -8.8800e-04  1.6396e-02 -1.0464e-01\nNakhon Ratchasima         2.0960e-03 -3.3343e-05  3.9936e-04  1.0655e-01\nNakhon Sawan              5.7515e-02 -7.2892e-04  1.0619e-02  5.6521e-01\nNakhon Si Thammarat       1.1975e-02 -2.6910e-04  3.2224e-03  2.1568e-01\nNan                       2.1631e-02 -8.1506e-04  3.0936e-02  1.2762e-01\nNarathiwat               -2.9111e-01 -9.3157e-04  9.4188e-03 -2.9899e+00\nNong Bua Lam Phu          1.7743e-03 -1.0648e-03  2.6572e-02  1.7416e-02\nNong Khai                 5.5920e-02 -7.0367e-04  1.7567e-02  4.2722e-01\nNonthaburi                3.6169e-02 -7.5938e-04  1.4023e-02  3.1185e-01\nPathum Thani              6.2241e-02 -8.5849e-04  1.5851e-02  5.0118e-01\nPattani                   6.5826e-02 -1.0189e-03  1.4840e-02  5.4873e-01\nPhangnga                 -5.2853e-03 -1.1310e-05  2.0901e-04 -3.6480e-01\nPhatthalung               4.1280e-02 -9.0214e-04  6.8888e-03  5.0823e-01\nPhayao                    4.2170e-02 -9.3588e-04  1.1199e-02  4.0733e-01\nPhetchabun                3.2121e-02 -4.8503e-04  7.0677e-03  3.8784e-01\nPhetchaburi              -1.6631e-02 -6.6598e-05  9.7084e-04 -5.3162e-01\nPhichit                   5.6141e-02 -9.6542e-04  1.1552e-02  5.3131e-01\nPhitsanulok               4.7478e-02 -4.7233e-04  1.7934e-02  3.5805e-01\nPhra Nakhon Si Ayutthaya  1.4604e-02 -1.3274e-04  1.9348e-03  3.3503e-01\nPhrae                     6.8038e-02 -8.9708e-04  1.6563e-02  5.3564e-01\nPhuket                   -8.5193e-01 -1.4125e-01  2.2416e+00 -4.7468e-01\nPrachin Buri              4.2618e-02 -7.2836e-04  2.7648e-02  2.6069e-01\nPrachuap Khiri Khan      -3.6589e-02 -4.6886e-04  1.1708e-02 -3.3382e-01\nRanong                   -1.8162e-02 -8.5754e-04  6.5974e-02 -6.7372e-02\nRatchaburi                3.3106e-02 -7.8960e-04  1.9710e-02  2.4144e-01\nRayong                    9.4808e-04 -2.8939e-07  4.2189e-06  4.6172e-01\nRoi Et                   -2.1489e-01 -9.7817e-04  1.8059e-02 -1.5918e+00\nSa Kaeo                   6.0448e-02 -6.6356e-04  7.9427e-03  6.8571e-01\nSakon Nakhon              1.5207e-03 -8.7858e-04  1.6222e-02  1.8838e-02\nSamut Prakan              5.8752e-02 -6.8479e-04  1.7096e-02  4.5458e-01\nSamut Sakhon              5.9036e-02 -9.5877e-04  1.1473e-02  5.6011e-01\nSamut Songkhram           5.3885e-02 -7.5637e-04  1.1018e-02  5.2055e-01\nSaraburi                  3.5939e-02 -5.8367e-04  8.5042e-03  3.9604e-01\nSatun                     4.7736e-02 -4.7190e-04  1.1783e-02  4.4410e-01\nSi Sa Ket                -1.9604e-02 -9.4121e-04  1.1263e-02 -1.7585e-01\nSing Buri                -1.8877e-04 -1.0164e-03  7.7603e-03  9.3949e-03\nSongkhla                 -4.8208e-02 -4.9426e-04  7.2021e-03 -5.6223e-01\nSukhothai                 5.9366e-02 -8.2070e-04  2.0486e-02  4.2050e-01\nSuphan Buri              -1.3730e-01 -6.3974e-04  1.1815e-02 -1.2573e+00\nSurat Thani              -3.9306e-02 -1.9060e-03  3.5155e-02 -1.9947e-01\nSurin                    -1.1748e-02 -8.7318e-04  8.8289e-03 -1.1574e-01\nTak                      -9.6728e-03 -5.7672e-04  8.4030e-03 -9.9228e-02\nTrang                     6.6840e-03 -5.5674e-04  1.3901e-02  6.1413e-02\nTrat                      2.0154e-02 -1.5065e-04  2.1960e-03  4.3330e-01\nUbon Ratchathani          5.4361e-02 -6.1752e-04  1.5418e-02  4.4277e-01\nUdon Thani                4.5242e-02 -3.9636e-04  7.3218e-03  5.3337e-01\nUthai Thani              -3.0925e-01 -9.6439e-04  2.4069e-02 -1.9871e+00\nUttaradit                -3.5255e-01 -9.2454e-04  1.3466e-02 -3.0301e+00\nYala                      6.0220e-02 -8.5365e-04  1.2435e-02  5.4770e-01\nYasothon                 -6.3268e-02 -1.0348e-03  1.2382e-02 -5.5928e-01\n                         Pr.z....E.Ii..\nAmnat Charoen                    0.7824\nAng Thong                        0.6926\nBangkok                          0.6118\nBueng Kan                        0.7888\nBuri Ram                         0.5215\nChachoengsao                     0.7931\nChai Nat                         0.5869\nChaiyaphum                       0.5830\nChanthaburi                      0.7303\nChiang Mai                       0.0115\nChiang Rai                       0.8741\nChon Buri                        0.5281\nChumphon                         0.7251\nKalasin                          0.1837\nKamphaeng Phet                      NaN\nKanchanaburi                     0.6433\nKhon Kaen                        0.8892\nKrabi                            0.5578\nLampang                          0.6990\nLamphun                          0.7492\nLoei                             0.7254\nLop Buri                         0.7548\nMae Hong Son                     0.6641\nMaha Sarakham                    0.4741\nMukdahan                         0.5158\nNakhon Nayok                     0.0102\nNakhon Pathom                    0.6470\nNakhon Phanom                    0.9167\nNakhon Ratchasima                0.9151\nNakhon Sawan                     0.5719\nNakhon Si Thammarat              0.8292\nNan                              0.8985\nNarathiwat                       0.0028\nNong Bua Lam Phu                 0.9861\nNong Khai                        0.6692\nNonthaburi                       0.7552\nPathum Thani                     0.6162\nPattani                          0.5832\nPhangnga                         0.7153\nPhatthalung                      0.6113\nPhayao                           0.6838\nPhetchabun                       0.6981\nPhetchaburi                      0.5950\nPhichit                          0.5952\nPhitsanulok                      0.7203\nPhra Nakhon Si Ayutthaya         0.7376\nPhrae                            0.5922\nPhuket                           0.6350\nPrachin Buri                     0.7943\nPrachuap Khiri Khan              0.7385\nRanong                           0.9463\nRatchaburi                       0.8092\nRayong                           0.6443\nRoi Et                           0.1114\nSa Kaeo                          0.4929\nSakon Nakhon                     0.9850\nSamut Prakan                     0.6494\nSamut Sakhon                     0.5754\nSamut Songkhram                  0.6027\nSaraburi                         0.6921\nSatun                            0.6570\nSi Sa Ket                        0.8604\nSing Buri                        0.9925\nSongkhla                         0.5740\nSukhothai                        0.6741\nSuphan Buri                      0.2087\nSurat Thani                      0.8419\nSurin                            0.9079\nTak                              0.9210\nTrang                            0.9510\nTrat                             0.6648\nUbon Ratchathani                 0.6579\nUdon Thani                       0.5938\nUthai Thani                      0.0469\nUttaradit                        0.0024\nYala                             0.5839\nYasothon                         0.5760\n\n\n\n\n\nprintCoefmat(data.frame(\n  localMI_tour[fips_tour,], \n  row.names=tourist_all$province_eng[fips_tour]),\n  check.names=FALSE)\n\n                                  Ii        E.Ii      Var.Ii        Z.Ii\nAmnat Charoen             1.4440e-01 -3.5167e-03  8.7545e-02  4.9991e-01\nAng Thong                -3.8063e-02 -2.5214e-03  4.6479e-02 -1.6486e-01\nBangkok                  -1.0646e+00 -7.7918e-01  2.0609e+00 -1.9881e-01\nBueng Kan                 1.2282e-01 -2.7246e-03  6.7881e-02  4.8188e-01\nBuri Ram                  9.2307e-04 -2.9542e-04  4.3055e-03  1.8570e-02\nChachoengsao              1.0659e-01 -1.3828e-04  1.2066e-03  3.0726e+00\nChai Nat                  1.1552e-01 -2.3849e-03  4.3969e-02  5.6229e-01\nChaiyaphum               -7.8253e-02 -1.4078e-03  2.5980e-02 -4.7676e-01\nChanthaburi              -7.8012e-02 -5.7990e-04  8.4493e-03 -8.4239e-01\nChiang Mai               -2.5781e-01 -1.8017e-02  2.5793e-01 -4.7216e-01\nChiang Rai                2.5849e-02 -4.1080e-04  1.0259e-02  2.5927e-01\nChon Buri                 1.3150e-01 -5.2488e-02  1.2424e+00  1.6506e-01\nChumphon                 -6.4679e-02 -1.6600e-03  4.1402e-02 -3.0971e-01\nKalasin                   8.9201e-02 -2.5958e-03  3.1011e-02  5.2128e-01\nKamphaeng Phet            1.1287e-01 -2.4293e-03  3.5330e-02  6.1344e-01\nKanchanaburi             -2.0751e-01 -2.1746e-02  3.1013e-01 -3.3358e-01\nKhon Kaen                -3.0183e-02 -5.4953e-04  4.1977e-03 -4.5738e-01\nKrabi                    -3.2130e-03 -1.6954e-05  3.1330e-04 -1.8056e-01\nLampang                   1.8252e-02 -1.2481e-03  1.2615e-02  1.7361e-01\nLamphun                  -7.5909e-02 -1.7169e-03  4.2818e-02 -3.5854e-01\nLoei                      2.2156e-02 -5.8829e-04  7.0422e-03  2.7104e-01\nLop Buri                  2.4231e-04 -9.9205e-06  8.6572e-05  2.7108e-02\nMae Hong Son             -1.7705e-01 -1.8735e-03  7.1034e-02 -6.5727e-01\nMaha Sarakham             1.0703e-01 -2.7167e-03  3.9499e-02  5.5222e-01\nMukdahan                  1.1032e-01 -9.1833e-04  1.0989e-02  1.0612e+00\nNakhon Nayok             -1.5062e-02 -3.2303e-04  4.7079e-03 -2.1480e-01\nNakhon Pathom             1.5777e-03 -1.9717e-08  1.9954e-07  3.5319e+00\nNakhon Phanom             1.1588e-01 -1.4958e-03  3.7313e-02  6.0766e-01\nNakhon Ratchasima        -1.0243e-01 -1.0241e-02  8.8455e-02 -3.0998e-01\nNakhon Sawan              7.8346e-02 -8.0497e-04  7.0190e-03  9.4476e-01\nNakhon Si Thammarat       2.5608e-03 -2.0765e-05  3.0271e-04  1.4838e-01\nNan                       1.4264e-01 -1.6696e-03  4.1641e-02  7.0716e-01\nNarathiwat                2.2606e-01 -3.0469e-03  1.1539e-01  6.7446e-01\nNong Bua Lam Phu         -5.8555e-03 -3.4093e-03  8.4882e-02 -8.3964e-03\nNong Khai                 3.7639e-02 -3.3988e-04  6.2788e-03  4.7929e-01\nNonthaburi               -2.7317e-01 -2.3588e-04  4.3580e-03 -4.1345e+00\nPathum Thani             -3.7830e-01 -9.7639e-04  1.1684e-02 -3.4908e+00\nPattani                   1.1576e-01 -3.5682e-03  8.8824e-02  4.0037e-01\nPhangnga                  8.8450e-03 -1.3043e-04  3.2580e-03  1.5725e-01\nPhatthalung               4.3888e-02 -1.8269e-03  3.3700e-02  2.4903e-01\nPhayao                    9.2570e-02 -2.3577e-03  4.3468e-02  4.5531e-01\nPhetchabun                2.3124e-02 -3.2479e-04  3.2858e-03  4.0906e-01\nPhetchaburi               1.9970e-01 -1.2305e-02  3.0362e-01  3.8475e-01\nPhichit                   9.4452e-02 -2.4146e-03  4.4514e-02  4.5912e-01\nPhitsanulok               1.5742e-02 -3.0078e-05  3.6026e-04  8.3096e-01\nPhra Nakhon Si Ayutthaya -7.1213e-02 -7.1468e-03  7.1808e-02 -2.3908e-01\nPhrae                     1.4222e-01 -1.9730e-03  2.8707e-02  8.5106e-01\nPhuket                    0.0000e+00  0.0000e+00  0.0000e+00         NaN\nPrachin Buri             -4.2596e-02 -1.3462e-03  2.4844e-02 -2.6170e-01\nPrachuap Khiri Khan       2.5964e-01 -9.4776e-03  3.5661e-01  4.5065e-01\nRanong                    4.6365e-02 -2.5896e-03  6.4527e-02  1.9272e-01\nRatchaburi               -7.5141e-02 -5.5852e-04  8.1380e-03 -8.2676e-01\nRayong                    2.7251e-01 -1.2235e-03  4.6421e-02  1.2705e+00\nRoi Et                    1.6554e-01 -2.3267e-03  2.7804e-02  1.0067e+00\nSa Kaeo                  -1.8024e-02 -1.1480e-03  1.6717e-02 -1.3053e-01\nSakon Nakhon              8.4183e-02 -1.2796e-03  1.5307e-02  6.9076e-01\nSamut Prakan             -4.6931e-01 -1.9064e-04  7.2405e-03 -5.5131e+00\nSamut Sakhon             -7.6004e-01 -2.1810e-03  4.0217e-02 -3.7791e+00\nSamut Songkhram          -2.7309e-03 -7.0522e-06  1.7618e-04 -2.0521e-01\nSaraburi                  2.1469e-02 -1.0227e-04  1.4908e-03  5.5868e-01\nSatun                     5.0708e-02 -1.2208e-03  3.0460e-02  2.9754e-01\nSi Sa Ket                 1.2144e-01 -1.6740e-03  3.0884e-02  7.0056e-01\nSing Buri                 9.6538e-02 -2.8754e-03  4.1799e-02  4.8625e-01\nSongkhla                 -7.7244e-02 -7.1528e-04  1.0420e-02 -7.4969e-01\nSukhothai                 1.0716e-01 -1.6880e-03  2.0185e-02  7.6618e-01\nSuphan Buri               1.9710e-03 -3.3990e-05  3.4397e-04  1.0811e-01\nSurat Thani              -2.5482e-02 -2.6241e-04  3.8246e-03 -4.0780e-01\nSurin                     1.2696e-01 -1.7782e-03  3.2803e-02  7.1081e-01\nTak                       1.2199e-03 -7.0668e-04  5.3973e-03  2.6223e-02\nTrang                     6.1288e-02 -1.7049e-03  3.1454e-02  3.5519e-01\nTrat                      5.2763e-02 -8.3115e-04  6.3945e-02  2.1194e-01\nUbon Ratchathani          4.4419e-02 -1.2847e-04  3.2090e-03  7.8639e-01\nUdon Thani               -9.9330e-03 -2.2764e-05  2.7266e-04 -6.0017e-01\nUthai Thani              -3.6369e-02 -2.3361e-03  3.3978e-02 -1.8463e-01\nUttaradit                 1.1228e-01 -2.0087e-03  3.7046e-02  5.9377e-01\nYala                      1.0732e-01 -2.3077e-03  5.7519e-02  4.5712e-01\nYasothon                  1.5741e-01 -2.9679e-03  4.3140e-02  7.7215e-01\n                         Pr.z....E.Ii..\nAmnat Charoen                    0.6171\nAng Thong                        0.8691\nBangkok                          0.8424\nBueng Kan                        0.6299\nBuri Ram                         0.9852\nChachoengsao                     0.0021\nChai Nat                         0.5739\nChaiyaphum                       0.6335\nChanthaburi                      0.3996\nChiang Mai                       0.6368\nChiang Rai                       0.7954\nChon Buri                        0.8689\nChumphon                         0.7568\nKalasin                          0.6022\nKamphaeng Phet                   0.5396\nKanchanaburi                     0.7387\nKhon Kaen                        0.6474\nKrabi                            0.8567\nLampang                          0.8622\nLamphun                          0.7199\nLoei                             0.7864\nLop Buri                         0.9784\nMae Hong Son                     0.5110\nMaha Sarakham                    0.5808\nMukdahan                         0.2886\nNakhon Nayok                     0.8299\nNakhon Pathom                    0.0004\nNakhon Phanom                    0.5434\nNakhon Ratchasima                0.7566\nNakhon Sawan                     0.3448\nNakhon Si Thammarat              0.8820\nNan                              0.4795\nNarathiwat                       0.5000\nNong Bua Lam Phu                 0.9933\nNong Khai                        0.6317\nNonthaburi                       0.0000\nPathum Thani                     0.0005\nPattani                          0.6889\nPhangnga                         0.8751\nPhatthalung                      0.8033\nPhayao                           0.6489\nPhetchabun                       0.6825\nPhetchaburi                      0.7004\nPhichit                          0.6461\nPhitsanulok                      0.4060\nPhra Nakhon Si Ayutthaya         0.8110\nPhrae                            0.3947\nPhuket                              NaN\nPrachin Buri                     0.7936\nPrachuap Khiri Khan              0.6522\nRanong                           0.8472\nRatchaburi                       0.4084\nRayong                           0.2039\nRoi Et                           0.3141\nSa Kaeo                          0.8962\nSakon Nakhon                     0.4897\nSamut Prakan                     0.0000\nSamut Sakhon                     0.0002\nSamut Songkhram                  0.8374\nSaraburi                         0.5764\nSatun                            0.7661\nSi Sa Ket                        0.4836\nSing Buri                        0.6268\nSongkhla                         0.4534\nSukhothai                        0.4436\nSuphan Buri                      0.9139\nSurat Thani                      0.6834\nSurin                            0.4772\nTak                              0.9791\nTrang                            0.7224\nTrat                             0.8322\nUbon Ratchathani                 0.4316\nUdon Thani                       0.5484\nUthai Thani                      0.8535\nUttaradit                        0.5527\nYala                             0.6476\nYasothon                         0.4400\n\n\n\n\n\n\n2.4.3.1.1 Mapping the Local Moran’s I\nBefore we map the local Moran’s I map, it is wise to append the local Moran’s data-frame (localMI) onto the profit SpatialPolygonDataFrame.\n\nProfitOccupancy Rate\n\n\n\nprofit.localMI &lt;- cbind(profit_all,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\ntourists.localMI &lt;- cbind(tourist_all,localMI_tour) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n\nWe map both, the local Moran’s I values as well as p-values side by side for comparison. The tmap package is used for this.\n\nProfitNumber of tourists\n\n\n\nlocalMI.map &lt;- tm_shape(profit.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(profit.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nlocalMI.map_tour &lt;- tm_shape(tourists.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map_tour &lt;- tm_shape(tourists.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map_tour, pvalue.map_tour, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.2 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation.\nBefore we can generate the LISA cluster map, we must plot the Moran scatterplot.\n\n2.4.3.2.1 Plotting a Moran Scatterplot\nThe Moran Scatterplot depicts the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will implement the moran.plot() function of the spdep package to create the plot.\n\nnci &lt;- moran.plot(profit_all$total_value, rswm_q_pro_all,\n                  labels=as.character(profit_all$province_eng), \n                  xlab=\"Total Value\", \n                  ylab=\"Spatially Lag Total Value\")\n\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants.\nThe top right corner belongs to areas that have high profits and are surrounded by other areas that have the average level of profits.\n\n\n\n2.4.3.2.2 Plotting Moran Scatterplot with Standardised variable\nWe first implement the scale() function to center and scale the variable. Here, centering is done by subtracting the mean (omitting NAs) from the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nprofit_all$Z.value &lt;- scale(profit_all$total_value) %&gt;% \n  as.vector \n\n\nNote that the as.vector() function is added so that we get a vector as the output. This allows us to map it neatly into our data-frame.\n\nWe can now plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(profit_all$Z.value, rswm_q_pro_all,\n                   labels=as.character(profit_all$province_eng),\n                   xlab=\"z-Value\", \n                   ylab=\"Spatially Lag z-Value\")\n\n\n\n\n\n\n\n\nOnly one region, Bangkok, is in the top right quadrant. #### 2.4.3.2.3 Preparing LISA Map Classes\nWe now prepare the data in order to facilitate plotting a LISA Cluster Map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNow, we will derive the spatially lagged variable of interest (i.e: GDPPC) and center the spatially lagged variable around its mean for both our variables of interest.\n\nProfitNumber of tourists\n\n\n\nprofit_all$`lag Profit` &lt;- lag.listw(rswm_q_pro_all, profit_all$total_value)\nDV &lt;- profit_all$`lag Profit` - mean(profit_all$`lag Profit`)     \n\n\n\n\ntourist_all$lag_tourists &lt;- lag.listw(rswm_q_tour, tourist_all$total_value)\nDV &lt;- tourist_all$lag_tourists - mean(tourist_all$lag_tourists)     \n\n\n\n\nThe below code chunk performs multiple tasks for us as described in the chunk itself.\nThe key functions are the setting of the significance level at 0.05 as well as the creation of the quadrant data-frame.\n\n# Now, we work on centering the local Moran around the mean.\nLM_I &lt;- localMI[,1]   \n\n# We set the significance level for the Local Moran in the code chunk below.\nsignif &lt;- 0.05       \n\n# The following code chunk defines the four categories (low-low (1), low-high (2), high-low (3), high-high (4))\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4   \n\n# Finally, we place the non-significant Moran in the category 0.\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n2.4.3.2.3 LISA Map\nIn the interest of easier visualization and interpretation, we plot the Total Values and their corresponding quadrants next to each other.\nWe can now implement functions of the tmap package to plot the LISA Map.\n\nProfitsNumber of tourists\n\n\n\nprofits &lt;- tm_shape(profit_all) +\n              tm_polygons(\"total_value\", style = \"jenks\", palette = \"Blues\", title = \"Total Value\") +\n              tm_layout(legend.outside = TRUE)\n\nprofit.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(profit.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(profits, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\ntourism &lt;- tm_shape(tourist_all) +\n              tm_polygons(\"total_value\", style = \"jenks\", palette = \"Blues\", title = \"Total Value\") +\n              tm_layout(legend.outside = TRUE)\n\ntourists.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap_tour &lt;- tm_shape(tourists.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(tourism, LISAmap_tour, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.3.3 Hot and Cold Spot Analysis\nWe now use localized spatial statistics to detect hot and cold spot areas.\n\n“Hot Spot’ is generally used across various disciplines to describe a region or value that is higher relative to its surroundings.\n\n\n2.4.3.3.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistic used to detect spatial anomalies is the Getis-Ord G-statistic (Getis and Ord, 1972; Ord and Getis, 1995). This method examines spatial relationships within a defined proximity to identify clusters of high or low values. Statistically significant hotspots are areas where high values are spatially clustered, meaning that not only do these areas have high values, but their neighboring areas also exhibit similarly high values.\nThe analysis involves three key steps:\nDeriving the spatial weight matrix: This defines the spatial relationships between areas, specifying which locations are considered neighbors based on proximity. Computing the Gi statistic: This step calculates the G-statistic for each location, identifying regions where values are significantly higher or lower than expected. Mapping the Gi statistics: The results are visualized to reveal spatial patterns of high-value clusters (hotspots) and low-value clusters (cold spots). This approach is useful for identifying localized patterns of spatial clustering and detecting significant anomalies in the data.\n\n\n2.4.3.3.2 Deriving Distance Based Weight Matrix\nWe start by defining a new set of neighbors. While the spatial autocorrelation considered units which shared borders, for Getis-Ord, we will define the neighbors based on distance.\nThere are two types of distance-based proximity matrices:\nFixed Distance Weight Matrix\nAdaptive Distance Weight Matrix\n\n2.4.3.3.2.1 Deriving distance-based weight matrix\n\nfixed distance matrixMapping Gi values with fixed distance weights\n\n\nBefore creating our connectivity graph, we need to assign a point to each polygon. This requires more than simply running st_centroid() on the us.bound spatial object. Specifically, we need to extract the coordinates into a separate data frame. We have already done this previously and have the object coords_all\nFor more detailed information, you can refer to the map documentation here.\n\nwm62_lw_profit &lt;- nb2listw(wm_d62_pro_all, style = 'B')\nsummary(wm62_lw_profit)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 350 \nPercentage nonzero weights: 5.903188 \nAverage number of links: 4.545455 \n2 disjoint connected subgraphs\nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 11 12 13 14 \n 8 15 15 13  6  4  2  1  4  4  1  1  2  1 \n8 least connected regions:\n11 26 33 37 47 51 60 63 with 1 link\n1 most connected region:\n8 with 14 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 77 5929 350 700 9560\n\n\n\nfips &lt;- order(profit_all$province_eng)\ngi.fixed_profit &lt;- localG(profit_all$total_value, wm62_lw_profit)\ngi.fixed_profit\n\n [1]  1.72204198  0.32507206 -0.63963877 -0.34656391 -0.63106922  1.85263552\n [7]  1.45185156  1.35082616 -0.28501259  1.41225147  0.07316501 -0.42146553\n[13]  2.55350535  2.15204901  2.29392753  2.02716770 -0.78617455 -0.66718360\n[19]  2.81711623  0.55503719  2.95575400  1.88026186  0.26863597  0.79540880\n[25] -0.38548695 -0.19616145 -0.52581301 -0.35160364 -0.22202539 -0.21957271\n[31] -0.54479866 -0.48275821 -0.28580881 -0.39038265 -0.63470128 -0.36591874\n[37] -0.22285852 -0.38920403 -0.43191914 -0.63354645 -0.50650962 -0.35227572\n[43] -0.39394926 -0.45414601 -0.47661388 -0.40437456 -0.26339386 -0.57279423\n[49]  0.16843044  0.41726596  0.81941327 -0.67447118 -0.37806669 -0.09495497\n[55] -0.42615323 -0.45645978 -0.50084879 -0.51135981 -0.50598386 -0.26988232\n[61] -0.52573156 -0.41343694 -0.25664198  1.53862423  0.16663889 -0.38207690\n[67] -0.19658983  2.37283918 -0.18161089  0.41109227  0.10594488 -0.16352985\n[73] -0.34053906 -0.41978322  0.03763722 -0.09226794 -0.38989571\nattr(,\"internals\")\n                Gi      E(Gi)       V(Gi)       Z(Gi) Pr(z != E(Gi))\n [1,] 0.3858055203 0.14473684 0.019597204  1.72204198    0.085061914\n [2,] 0.1932727918 0.15789474 0.011844279  0.32507206    0.745126534\n [3,] 0.0184957073 0.09210526 0.013243380 -0.63963877    0.522407472\n [4,] 0.0039057092 0.02631579 0.004181385 -0.34656391    0.728918959\n [5,] 0.0193132416 0.09210526 0.013304960 -0.63106922    0.527995263\n [6,] 0.3813548575 0.13157895 0.018176955  1.85263552    0.063934618\n [7,] 0.3889691031 0.17105263 0.022528677  1.45185156    0.146542885\n [8,] 0.3927872620 0.18421053 0.023841458  1.35082616    0.176751126\n [9,] 0.0268929985 0.05263158 0.008155321 -0.28501259    0.775634493\n[10,] 0.3844383845 0.17105263 0.022830045  1.41225147    0.157875930\n[11,] 0.0165472431 0.01315789 0.002145979  0.07316501    0.941674808\n[12,] 0.0241502351 0.06578947 0.009760711 -0.42146553    0.673415178\n[13,] 0.4758402376 0.13157895 0.018176189  2.55350535    0.010664464\n[14,] 0.3951862319 0.11842105 0.016539356  2.15204901    0.031393495\n[15,] 0.3858808558 0.10526316 0.014964793  2.29392753    0.021794662\n[16,] 0.3798739678 0.11842105 0.016634418  2.02716770    0.042645265\n[17,] 0.0258430186 0.13157895 0.018088694 -0.78617455    0.431765234\n[18,] 0.0324122288 0.11842105 0.016618633 -0.66718360    0.504654862\n[19,] 0.4815471011 0.11842105 0.016615189  2.81711623    0.004845699\n[20,] 0.1207543063 0.06578947 0.009806762  0.55503719    0.578869221\n[21,] 0.4213553387 0.07894737 0.013419958  2.95575400    0.003119058\n[22,] 0.3852284095 0.13157895 0.018198317  1.88026186    0.060072399\n[23,] 0.1078287978 0.07894737 0.011558701  0.26863597    0.788209826\n[24,] 0.1018968575 0.03947368 0.006159010  0.79540880    0.426375743\n[25,] 0.0095313437 0.03947368 0.006033261 -0.38548695    0.699876672\n[26,] 0.0041914072 0.01315789 0.002089380 -0.19616145    0.844483802\n[27,] 0.0059294160 0.05263158 0.007888807 -0.52581301    0.599018137\n[28,] 0.0039199342 0.02631579 0.004057220 -0.35160364    0.725135534\n[29,] 0.0121380628 0.02631579 0.004077631 -0.22202539    0.824294115\n[30,] 0.0123226101 0.02631579 0.004061403 -0.21957271    0.826203944\n[31,] 0.0042254150 0.05263158 0.007894584 -0.54479866    0.585892002\n[32,] 0.0017737008 0.03947368 0.006098499 -0.48275821    0.629267429\n[33,] 0.0001736036 0.01315789 0.002063884 -0.28580881    0.775024563\n[34,] 0.0092272618 0.03947368 0.006002982 -0.39038265    0.696253617\n[35,] 0.0031044434 0.06578947 0.009754139 -0.63470128    0.525623256\n[36,] 0.0029903222 0.02631579 0.004063417 -0.36591874    0.714425716\n[37,] 0.0029442098 0.01315789 0.002100421 -0.22285852    0.823645619\n[38,] 0.0180641784 0.05263158 0.007888216 -0.38920403    0.697125223\n[39,] 0.0059355717 0.03947368 0.006029376 -0.43191914    0.665800184\n[40,] 0.0032814385 0.06578947 0.009734525 -0.63354645    0.526376861\n[41,] 0.0075885184 0.05263158 0.007908250 -0.50650962    0.612498940\n[42,] 0.0038576245 0.02631579 0.004064275 -0.35227572    0.724631498\n[43,] 0.0011511480 0.02631579 0.004080383 -0.39394926    0.693618502\n[44,] 0.0041121198 0.03947368 0.006062782 -0.45414601    0.649723737\n[45,] 0.0025532004 0.03947368 0.006000693 -0.47661388    0.633637101\n[46,] 0.0066350187 0.03947368 0.006594826 -0.40437456    0.685937304\n[47,] 0.0009921345 0.01315789 0.002133375 -0.26339386    0.792247020\n[48,] 0.0092649289 0.06578947 0.009738159 -0.57279423    0.566784026\n[49,] 0.0525524825 0.03947368 0.006029684  0.16843044    0.866244663\n[50,] 0.0529041930 0.02631579 0.004060305  0.41726596    0.676483887\n[51,] 0.0504008403 0.01315789 0.002065770  0.81941327    0.412550669\n[52,] 0.0064343489 0.07894737 0.011558599 -0.67447118    0.500011800\n[53,] 0.0022032196 0.02631579 0.004067712 -0.37806669    0.705381053\n[54,] 0.0202649221 0.02631579 0.004060690 -0.09495497    0.924350594\n[55,] 0.0063208919 0.03947368 0.006052136 -0.42615323    0.669996196\n[56,] 0.0120639478 0.05263158 0.007898675 -0.45645978    0.648059389\n[57,] 0.0079439193 0.05263158 0.007960896 -0.50084879    0.616477544\n[58,] 0.0071631695 0.05263158 0.007906174 -0.51135981    0.609099135\n[59,] 0.0076163930 0.05263158 0.007914888 -0.50598386    0.612867981\n[60,] 0.0008813427 0.01315789 0.002069207 -0.26988232    0.787250791\n[61,] 0.0225222310 0.07894737 0.011519063 -0.52573156    0.599074730\n[62,] 0.0074231980 0.03947368 0.006009671 -0.41343694    0.679286515\n[63,] 0.0014919135 0.01315789 0.002066270 -0.25664198    0.797455162\n[64,] 0.2224029785 0.06578947 0.010360800  1.53862423    0.123896059\n[65,] 0.0675325754 0.05263158 0.007996094  0.16663889    0.867654193\n[66,] 0.0019677677 0.02631579 0.004060933 -0.38207690    0.702404325\n[67,] 0.0242434216 0.03947368 0.006001954 -0.19658983    0.844148528\n[68,] 0.2259809615 0.03947368 0.006178100  2.37283918    0.017651948\n[69,] 0.0364839208 0.05263158 0.007905609 -0.18161089    0.855888103\n[70,] 0.0552205480 0.02631579 0.004943791  0.41109227    0.681004878\n[71,] 0.0330707115 0.02631579 0.004065189  0.10594488    0.915626085\n[72,] 0.0267502119 0.03947368 0.006053649 -0.16352985    0.870101275\n[73,] 0.0046162337 0.02631579 0.004060391 -0.34053906    0.733450616\n[74,] 0.0062364667 0.03947368 0.006269013 -0.41978322    0.674643821\n[75,] 0.0560761530 0.05263158 0.008375989  0.03763722    0.969976936\n[76,] 0.0444054673 0.05263158 0.007948543 -0.09226794    0.926485158\n[77,] 0.0014557954 0.02631579 0.004065417 -0.38989571    0.696613665\nattr(,\"cluster\")\n [1] Low  High Low  High Low  Low  Low  Low  High Low  High Low  Low  Low  Low \n[16] Low  Low  Low  Low  Low  High Low  Low  Low  Low  Low  Low  Low  Low  Low \n[31] Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low  Low \n[61] Low  Low  Low  High Low  Low  Low  High Low  High Low  Low  Low  High High\n[76] Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = profit_all$total_value, listw = wm62_lw_profit)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of the localG() function is a vector containing G or G* values, with the following attributes: - “gstari”: Indicates whether the G* version of the statistic was used (TRUE or FALSE). - “call”: Stores the function call. - “class”: Set to “localG”, identifying the object type.\nThe Gi statistic is represented as a Z-score, where larger values signify stronger clustering. The sign of the value indicates the type of cluster: positive values point to high-value clusters (hotspots), while negative values indicate low-value clusters (cold spots).\nTo merge the Gi values with their corresponding geographic data in the Hunan spatial dataframe, use the following code to join the results to the profit sf object. This allows for the spatial visualization of clusters within the geographic data.\n\nprofit.gi &lt;- cbind(profit_all, as.matrix(gi.fixed_profit)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed_profit.)\n\nthe code chunk above actually performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n\nGimap &lt;-tm_shape(profit.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(profits, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nFrom the above plot, we can infer that ‘hot spots’ tend to be neighboring regions and likewise for the cold spots too. We see high value (hot) clusters in the Central region of Thailand, particularly around Bangkok and the Bangkok Metropolitan Region as well as in the Southern Region, while the majority of the western part of Thailand is ‘cold’.\n\n\n\n\n\n\n2.4.3.3.2 Emerging Hot-Spot Analysis\nWe will now conduct Emerging Hot-spot analysis to see if there are any trends popping up recently.\nEmerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. The analysis consist of four main steps:\n\nBuilding a space-time cube,\nCalculating Getis-Ord local Gi* statistic for each bin by using an FDR correction,\nEvaluating these hot and cold spot trends by using Mann-Kendall trend test,\nCategorising each study area location by referring to the resultant trend z-score and p-value for each location with data, and with the hot spot z-score and p-value for each bin.\n\n\n2.4.3.3.2.1 Space-Time Cube\nWe now use the spacetime() function of the sfdep package to create a spatio-temporal cube.\nWe will do this for profits as well as occupancy rate.\n\nProfitsNumber of touristsOccupancy Rates\n\n\n\nprofit_all_temporal=tourists_temporal%&gt;%filter(variable=='revenue_all')\n\n# Rename province_eng to ADM1_EN using base R in order to facilitate the creation of the spacetime cube.\nnames(profit_all_temporal)[names(profit_all_temporal) == \"province_eng\"] &lt;- \"ADM1_EN\"\n\n# Space-time by month\nprofits_st &lt;- spacetime(profit_all_temporal, province,\n                      .loc_col = \"ADM1_EN\",\n                      .time_col = \"date\")\n\nTo verify if the cube has been create, we implement the is_spacetime_cube() function of the sfdep package as shown in the code chunk below.\n\nis_spacetime_cube(profits_st)\n\n[1] TRUE\n\n\nBased on the above output, we can confirm that it has been created as intended.\n\n\n\ntourist_temporal=tourists_temporal%&gt;%filter(variable=='no_tourist_all')\n\n# Rename province_eng to ADM1_EN using base R in order to facilitate the creation of the spacetime cube.\nnames(tourist_temporal)[names(tourist_temporal) == \"province_eng\"] &lt;- \"ADM1_EN\"\n\n# Space-time by month\ntourist_st &lt;- spacetime(tourist_temporal, province,\n                      .loc_col = \"ADM1_EN\",\n                      .time_col = \"date\")\n\nTo verify if the cube has been create, we implement the is_spacetime_cube() function of the sfdep package as shown in the code chunk below.\n\nis_spacetime_cube(tourist_st)\n\n[1] TRUE\n\n\n\n\n\noccupancy_temporal=tourists_temporal%&gt;%filter(variable=='ratio_tourist_stay')\n\n# Rename province_eng to ADM1_EN using base R in order to facilitate the creation of the spacetime cube.\nnames(occupancy_temporal)[names(occupancy_temporal) == \"province_eng\"] &lt;- \"ADM1_EN\"\n\n# Space-time by month\noccupancy_st &lt;- spacetime(occupancy_temporal, province,\n                      .loc_col = \"ADM1_EN\",\n                      .time_col = \"date\")\n\nTo verify if the cube has been create, we implement the is_spacetime_cube() function of the sfdep package as shown in the code chunk below.\n\nis_spacetime_cube(occupancy_st)\n\n[1] TRUE\n\n\nBased on the above output, we can confirm that it has been created as intended.\n\n\n\n\n\n2.4.3.3.2.2 Deriving Spatial Weights\nWe implement the below code chunk to identify neighbors and calculate the inverse-distance weights.\n\nProfitsNumber of TouristsOccupancy Rate\n\n\n\nprofits_nb &lt;- profits_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n# Create RDS File\nwrite_rds(profits_nb, 'data/rds/pro_nb')\n\n\nprofits_nb=read_rds('data/rds/pro_nb')\n\n\n\n\ntourist_nb &lt;- tourist_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n# Create RDS File\nwrite_rds(tourist_nb, 'data/rds/tour_nb')\n\n\ntourist_nb=read_rds('data/rds/tour_nb')\n\n\n\n\noccupancy_nb &lt;- occupancy_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\n\n# Create RDS file\nwrite_rds(occupancy_nb,'data/rds/occ_nb')\n\n\noccupancy_nb=read_rds('data/rds/occ_nb')\n\n\n\n\n\n\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\n\n\n\n2.4.3.3.3 Computing Gi Stats\nWe can use these new columns to manually calculate the local Gi for each location. We do this by grouping by Year and using the local_gstar_perm() function of the sfdep package. After this, we use the unnest() function to unnest the gi_star column of the newly created gi_starts data.frame.\n\nProfitsNumber of touristsOccupancy Rate\n\n\n\n# Calculate the local G* statistics\ngi_stars_profit &lt;- profits_nb %&gt;%\n  group_by(date) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    value,  # Make sure it's numeric\n    nb,                   # Neighbors\n    wt                    # Weights\n  )) %&gt;%\n  tidyr::unnest(gi_star)\n\n\n\n\n# Calculate the local G* statistics\ngi_stars_tour &lt;- tourist_nb %&gt;%\n  group_by(date) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    value,  # Make sure it's numeric\n    nb,                   # Neighbors\n    wt                    # Weights\n  )) %&gt;%\n  tidyr::unnest(gi_star)\n\n\n\n\n# Calculate the local G* statistics\ngi_stars_occ &lt;- occupancy_nb %&gt;%\n  group_by(date) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    value,  # Make sure it's numeric\n    nb,                   # Neighbors\n    wt                    # Weights\n  )) %&gt;%\n  tidyr::unnest(gi_star)\n\n\n\n\n\n\n2.4.3.3.4 Mann-Kendall Test\nWith the above Gi calculations, we can now conduct the Mann-Kendall test to evaluate selected locations, the top 5 most lucrative regions, for a trend.\nFollow this ‘link’ to learn about the Mann-Kendall test and how it helps detects trends over a period of time.\n\nBangkokKrabiPhuketChon BuriChiang Mai\n\n\n\nProfitOccupancy Rate\n\n\n\nbkk &lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Bangkok\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nbkk_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Bangkok\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfitOccupancy Rate\n\n\n\nkra &lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Krabi\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = kra, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nkra_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Krabi\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfitOccupancy Rate\n\n\n\nphk&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Phuket\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now produce a plot to visualize this.\n\nggplot(data = phk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nphk_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Phuket\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfitOccupancy Rate\n\n\n\ncbr&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chon Buri\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now produce a plot for the same\n\nggplot(data = cbr, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\ncbr_occ &lt;- gi_stars_occ%&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chon Buri\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfitOccupancy Rate\n\n\n\nchm&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chiang Mai\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now create a plot for the same.\n\nggplot(data = chm, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nchm_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chiang Mai\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = chm_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor all of these regions, besides Chiang Mai, we see a sharp drop between 2021 and 2022 however for the most part none of these regions reach their peaks between 2020 and 2022, which was when the world was hit by a global pandemic.\n\nAlternatively, we can also create an interactive plot using the ggplotly() function of the plotly package.\nThe code chunk below can be used.\n\n## Interactive plot for Bangkok \n\np &lt;- ggplot(data = bkk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\nWe now generate the report for the Mann Kendall Test by implementing the below code chunk.\nA Monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\n\nH0: No monotic trend.\nH1: Monotonic trend is present\n\n\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series.\n1 is a perfectly increasing series.\n\n\nWe implement the below code chunk to obtain the required report.\n\nBangkokKrabiChiang Mai\n\n\n\nbkk %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n     tau    sl     S     D   varS\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.118 0.228  -145  1225 14292.\n\n\n\n\n\nkra %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n      tau    sl     S     D   varS\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.0318 0.751   -39  1225 14292.\n\n\n\n\n\nchm %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau     sl     S     D   varS\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.249 0.0110   305  1225 14292.\n\n\n\n\n\n\n\n2.4.3.3.5 Mann-Kendall Test Data-Frame\nWe perform the above steps for every location by using the group_by() function of the dplyr package.\n\nProfitsNumber of touristsOccupancy Rate\n\n\n\nehsa &lt;- gi_stars_profit %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  ADM1_EN            tau        sl     S     D   varS\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.138   0.160      -169  1225 14292.\n2 Ang Thong     -0.429   0.0000117  -525  1225 14292.\n3 Bangkok       -0.118   0.228      -145  1225 14292.\n4 Bueng Kan     -0.0971  0.324      -119  1225 14292.\n5 Buriram        0.0204  0.841        25  1225 14292.\n6 Chachoengsao   0.00898 0.933        11  1225 14292.\n\n\n\n\n\nehsa_tour &lt;- gi_stars_tour %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa_tour)\n\n# A tibble: 6 × 6\n  ADM1_EN           tau        sl     S     D   varS\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.238  0.0153     -291  1225 14292.\n2 Ang Thong     -0.0563 0.569       -69  1225 14292.\n3 Bangkok       -0.391  0.0000638  -479  1225 14292.\n4 Bueng Kan     -0.259  0.00821    -317  1225 14292.\n5 Buriram        0.153  0.120       187  1225 14292.\n6 Chachoengsao   0.0988 0.315       121  1225 14292.\n\n\n\n\n\nehsa_occ &lt;- gi_stars_occ %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa_occ)\n\n# A tibble: 6 × 6\n  ADM1_EN          tau        sl     S     D   varS\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.109 0.270      -133  1225 14292.\n2 Ang Thong     -0.420 0.0000171  -515  1225 14292.\n3 Bangkok       -0.205 0.0365     -251  1225 14292.\n4 Bueng Kan      0.257 0.00863     315  1225 14292.\n5 Buriram        0.122 0.216       149  1225 14292.\n6 Chachoengsao  -0.324 0.000925   -397  1225 14292.\n\n\n\n\n\nWe now sort the data-frame to highlight emerging hot/cold spots by implementing the below code chunk for all three variables of interest.\n\nProfitsNumber of touristsOccupancy Rate\n\n\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  ADM1_EN         tau          sl     S     D   varS\n  &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Phichit       0.540 0             661  1225 14292.\n2 Mae Hong Son  0.527 0.000000119   645  1225 14292.\n3 Chiang Rai    0.528 0.000000119   647  1225 14292.\n4 Saraburi     -0.510 0.000000179  -625  1225 14292.\n5 Ratchaburi   -0.499 0.000000335  -611  1225 14292.\n6 Phitsanulok   0.471 0.00000143    577  1225 14292.\n\n\n\n\n\nemerging_tour &lt;- ehsa_tour %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging_tour)\n\n# A tibble: 6 × 6\n  ADM1_EN            tau          sl     S     D   varS\n  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Phichit          0.572 0             701  1225 14292.\n2 Chiang Rai       0.497 0.000000358   609  1225 14292.\n3 Mae Hong Son     0.482 0.000000834   591  1225 14292.\n4 Sa Kaeo         -0.461 0.00000238   -565  1225 14292.\n5 Samut Songkhram  0.424 0.0000147     519  1225 14292.\n6 Ratchaburi      -0.407 0.0000310    -499  1225 14292.\n\n\n\n\n\nemerging_occ &lt;- ehsa_occ %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging_occ)\n\n# A tibble: 6 × 6\n  ADM1_EN         tau          sl     S     D   varS\n  &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Nan           0.553 0             677  1225 14292.\n2 Nakhon Phanom 0.554 0             679  1225 14292.\n3 Phrae         0.587 0             719  1225 14292.\n4 Chiang Mai    0.507 0.000000238   621  1225 14292.\n5 Phayao        0.510 0.000000238   625  1225 14292.\n6 Uttaradit     0.460 0.00000262    563  1225 14292.\n\n\n\n\n\n\n\n2.4.3.3.6 Emerging Hot-Spot Analysis\nWe now perform EHSA by using the emerging_hotspot_analysis() function of the sfdep package.\nIt takes a spacetime object x (i.e: profit_st, tourist_st and occupancy_st), and the quoted name of the variable of interest (i.e. Profit, Occupancy Rate and Number of tourists) as the .var argument.\nThe k argument is used to specify the number of time lags which is set to 1 by default.\nnsim is number of simulations to be performed.\n\nProfitNumber of touristsOccupancy Rate\n\n\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = profits_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa &lt;- province %&gt;%\n  left_join(ehsa,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig &lt;- thai_ehsa  %&gt;%\n  filter(p_value &lt; 0.1)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\n\n\n\nehsa_tour &lt;- emerging_hotspot_analysis(\n  x = tourist_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa_tour,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa_tour &lt;- province %&gt;%\n  left_join(ehsa_tour,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig_tour &lt;- thai_ehsa_tour  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa_tour) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_tour) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\nWe don’t see too many patterns detected, indicating that it is pretty consistent over time. .\n\n\n\nehsa_occ &lt;- emerging_hotspot_analysis(\n  x = occupancy_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa_occ,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa_occ &lt;- province %&gt;%\n  left_join(ehsa_occ,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig_occ &lt;- thai_ehsa_occ  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa_occ) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_occ) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\nWe see a majority of the northern part of Thailand as well as a part of the central region are oscillating hotspots. Whereas, there are oscillating cold spots scattered across the nation.\n\n\n\n\nThere are several categories for emerging hotspot analysis however these are the most common. The below will help you interpret them.\nSporadic Hotspots: Locations with occasional bursts of high activity but without consistent patterns over time.\nOscillating Hotspots: Locations where high activity alternates between being present and absent over different time periods.\nSporadic Coldspots: Locations with occasional periods of low activity, lacking consistent patterns over time.\nOscillating Coldspots: Locations where low activity alternates between being present and absent over time."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, we will build hedonic pricing models using GWR methods.\nThe dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-the-geospatial-data",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.2.1 Importing the geospatial data",
    "text": "7.2.1 Importing the geospatial data\nWe start off by importing the geospatial data into our environment. We use the st_read() function of the sf package for this.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis dataset is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems. The geometry type is multipolygon.\nWe will now check the CRS information and update it if required.\n\nEPSG code for Singapore is 3414.\n\n\nChecking CRSUpdating CRS\n\n\nWe implement the st_crs() function of the sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\nWe note that the current EPSG code is 9001, which is inaccurate. We must update this to 3414. The st_transform() function of the sf package will be implemented.\n\nmpsz_svy21=st_transform(mpsz, 3414)\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\nWe now implement the st_bbox() function to identify the ‘bounding box’ of our data.\n\nst_bbox(mpsz_svy21) \n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-and-wrangling-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#importing-and-wrangling-the-aspatial-data",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.2.2 Importing and wrangling the Aspatial Data",
    "text": "7.2.2 Importing and wrangling the Aspatial Data\nSince this is in CSV format, we implement read_csv() of the readr package to import it.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nXCOORD ColumnYCOORD Column\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\n\n\nWe now implement the summary() function of base R to condo_resale.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n7.2.2.1 Converting aspatial data frame into a sf object\nCurrently, the condo_resale data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() function of sf package.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda-using-statistical-graphics",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.3.1 EDA using statistical graphics",
    "text": "7.3.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.3.2 Multiple Histogram Plots distribution of variables",
    "text": "7.3.2 Multiple Histogram Plots distribution of variables\nWe now plot multiple histograms (also known as trellis plot) by using the ggarrange() function of the ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#drawing-a-statistical-point-map",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.3.3 Drawing a statistical point map",
    "text": "7.3.3 Drawing a statistical point map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))+\n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\nWe change tmap_mode back to plot before proceeding.\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#simple-linear-regression-method",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.1 Simple Linear Regression Method",
    "text": "7.4.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe R-squared value of 0.4518 indicates that the simple regression model explains approximately 45% of the variation in resale prices.\nGiven that the p-value is much smaller than 0.0001, we can confidently reject the null hypothesis that the mean is an adequate predictor of the SELLING_PRICE. This suggests that the simple linear regression model is a significantly better estimator of SELLING_PRICE.\nThe Coefficients section of the report shows that the p-values for both the Intercept and ARA_SQM estimates are less than 0.001. This allows us to reject the null hypothesis that B0 (the intercept) and B1 (the slope for ARA_SQM) are equal to zero. Therefore, we can conclude that B0 and B1 are reliable parameter estimates.\nTo visualize the best fit line on a scatterplot, we can use the lm() method within ggplot’s geometry functions, as demonstrated in the following code snippet.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nThe figure above reveals that there are indeed a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-linear-regression-method",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.2 Multiple Linear Regression Method",
    "text": "7.4.2 Multiple Linear Regression Method\n\n7.4.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "7.4.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.4 Preparing Publication Quality Table: olsrr method",
    "text": "7.4.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.5 Preparing Publication Quality Table: gtsummary method",
    "text": "7.4.5 Preparing Publication Quality Table: gtsummary method\nThe broom package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tidy() function is used to create a well formatted regression report.\n\nbroom::tidy(condo.mlr1, intercept = TRUE)\n\n# A tibble: 15 × 5\n   term                 estimate std.error statistic   p.value\n   &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)           527633.  108183.       4.88 1.20e-  6\n 2 AREA_SQM               12778.     367.      34.8  3.41e-192\n 3 AGE                   -24688.    2755.      -8.96 9.82e- 19\n 4 PROX_CBD              -77131.    5763.     -13.4  1.47e- 38\n 5 PROX_CHILDCARE       -318473.  107960.      -2.95 3.23e-  3\n 6 PROX_ELDERLYCARE      185576.   39902.       4.65 3.61e-  6\n 7 PROX_URA_GROWTH_AREA   39163.   11755.       3.33 8.85e-  4\n 8 PROX_MRT             -294745.   56916.      -5.18 2.56e-  7\n 9 PROX_PARK             570505.   65507.       8.71 8.36e- 18\n10 PROX_PRIMARY_SCH      159856.   60235.       2.65 8.05e-  3\n11 PROX_SHOPPING_MALL   -220947.   36562.      -6.04 1.93e-  9\n12 PROX_BUS_STOP         682482.  134513.       5.07 4.42e-  7\n13 NO_Of_UNITS             -245.      87.9     -2.79 5.32e-  3\n14 FAMILY_FRIENDLY       146308.   46893.       3.12 1.84e-  3\n15 FREEHOLD              350600.   48506.       7.23 7.98e- 13"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#checking-for-multicollinearity",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#checking-for-multicollinearity",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.4.6 Checking for Multicollinearity",
    "text": "7.4.6 Checking for Multicollinearity\nIn this section, we use anl R package designed specifically for conducting OLS (Ordinary Least Squares) regression analysis—olsrr. This package offers a wide range of valuable tools to help you build more robust multiple linear regression models. Its key features include:\n\nComprehensive regression output\nDiagnostic tests for residuals\nInfluence measures for identifying outliers\nTests for heteroskedasticity\nCollinearity diagnostics to detect multicollinearity\nModel fit assessment\nEvaluation of variable contributions\nVarious methods for variable selection\n\nIn the code snippet below, we demonstrate how to use the ols_vif_tol() function from the olsrr package to assess potential multicollinearity among predictors in your regression model.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n7.4.6.1 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n7.4.6.2 Test for Normality Assumption\nThe code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n7.4.6.3 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode('plot')\n\nThe figure above reveals that there are signs of spatial autocorrelation.\nTo prove that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.1 Building Fixed Bandwidth GWR Model",
    "text": "7.5.1 Building Fixed Bandwidth GWR Model\n\n7.5.1.1 Computing fixed bandwith\nIn the code chunk below, the bw.gwr() function of the GWModel package is used to determine the optimal fixed bandwidth to use in the model.\n\nNotice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\n\nThere are two possible approaches can be used to determine the stopping rule.\n\nCV cross-validation approach\nAIC corrected (AICc) approach.\n\nWe define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres.\n\n\n7.5.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nWe use the code chunk below to display the model created above.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-09 21:32:37.460247 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-09 21:32:41.012882 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.2 Building Adaptive Bandwidth GWR Model",
    "text": "7.5.2 Building Adaptive Bandwidth GWR Model\n\n7.5.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\n7.5.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code chunk below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-09 21:32:59.402778 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-09 21:33:03.431795 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-gwr-output",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.3 Visualising GWR Output",
    "text": "7.5.3 Visualising GWR Output\nIn addition to the regression residuals, the output feature class table provides several key metrics, including observed and predicted values, the condition number (cond), Local R², residuals, and the coefficients with their standard errors for the explanatory variables:\n\nCondition Number: This diagnostic assesses local collinearity. When strong local collinearity is present, model results become unstable. A condition number greater than 30 suggests that the results may be unreliable due to multicollinearity.\nLocal R²: Values range from 0.0 to 1.0 and indicate the goodness-of-fit of the local regression model. Low Local R² values signal poor model performance in those regions. Mapping these values can help identify areas where the Geographically Weighted Regression (GWR) model is performing well and where it is underperforming, potentially highlighting missing or unaccounted-for variables.\nPredicted Values: These are the fitted y values estimated by the GWR model.\nResiduals: Residuals are calculated by subtracting the fitted y values from the observed y values. Standardized residuals have a mean of zero and a standard deviation of one. A gradient map (cold-to-hot) of standardized residuals can be created to visualize areas of model under- or overestimation.\nCoefficient Standard Errors: These values reflect the reliability of each coefficient estimate. Smaller standard errors relative to the actual coefficients indicate higher confidence in the estimates. Large standard errors, however, may suggest issues with local collinearity.\n\nAll of these metrics are stored within a SpatialPointsDataFrame or SpatialPolygonsDataFrame object, integrated with the fit points, GWR coefficient estimates, observed and predicted y values, coefficient standard errors, and t-values in the “data” slot of an object called SDF within the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#converting-sdf-into-sf-data.frame",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.4 Converting SDF into sf data.frame",
    "text": "7.5.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() and summary() are used to display the content and summary of condo_resale.sf.adaptive sf data frame.\n\nGlimpseSummary\n\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualizing-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualizing-local-r2",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.5 Visualizing local R2",
    "text": "7.5.5 Visualizing local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualising-coefficient-estimates",
    "title": "Hands On Exercise 7- Geographically Weighted Explanatory Models",
    "section": "7.5.6 Visualising coefficient estimates",
    "text": "7.5.6 Visualising coefficient estimates\nThe code chunk below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode('plot')\n\n\n7.5.6.1 By URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#total-rooms-booked",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#total-rooms-booked",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Total Rooms Booked",
    "text": "Total Rooms Booked\nTotal Rooms Available\nWe do this year by year.\n\n2019202020212022\n\n\n\ntourists_temporal$province_eng &lt;- gsub(\"Nong Bua Lamphu\", \"Nong Bua Lam Phu\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Sisaket\", \"Si Sa Ket\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Phang Nga\", \"Phangnga\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Lopburi\", \"Lop Buri\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Chonburi\", \"Chon Buri\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Chainat\", \"Chai Nat\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Buriram\", \"Buri Ram\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Prachinburi\", \"Prachin Buri\", tourists_temporal$province_eng)\noccupancy_2019_avg =tourists_temporal %&gt;%\n  filter(year == 2019, variable == 'ratio_tourist_stay') %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(avg_occupancy = mean(value, na.rm = TRUE))\noccupancy_2019_avg=left_join(occupancy_2019_avg, province, by=c('province_eng'='ADM1_EN'))\n\noccupancy_2019_avg=st_as_sf(occupancy_2019_avg)\ntm_shape(occupancy_2019_avg) +\n  tm_polygons(col = \"avg_occupancy\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n# 2020 data\noccupancy_2020_avg = tourists_temporal %&gt;%\n  filter(year == 2020, variable == 'ratio_tourist_stay') %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(avg_occupancy = mean(value, na.rm = TRUE))\n\noccupancy_2020_avg = left_join(occupancy_2020_avg, province, by = c('province_eng' = 'ADM1_EN'))\n\noccupancy_2020_avg = st_as_sf(occupancy_2020_avg)\ntm_shape(occupancy_2020_avg) +\n  tm_polygons(col = \"avg_occupancy\", palette = \"Blues\", style = 'quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n# 2021 data\noccupancy_2021_avg = tourists_temporal %&gt;%\n  filter(year == 2021, variable == 'ratio_tourist_stay') %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(avg_occupancy = mean(value, na.rm = TRUE))\n\noccupancy_2021_avg = left_join(occupancy_2021_avg, province, by = c('province_eng' = 'ADM1_EN'))\n\noccupancy_2021_avg = st_as_sf(occupancy_2021_avg)\ntm_shape(occupancy_2021_avg) +\n  tm_polygons(col = \"avg_occupancy\", palette = \"Blues\", style = 'quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n# 2022 data\noccupancy_2022_avg = tourists_temporal %&gt;%\n  filter(year == 2022, variable == 'ratio_tourist_stay') %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(avg_occupancy = mean(value, na.rm = TRUE))\n\noccupancy_2022_avg = left_join(occupancy_2022_avg, province, by = c('province_eng' = 'ADM1_EN'))\n\noccupancy_2022_avg = st_as_sf(occupancy_2022_avg)\ntm_shape(occupancy_2022_avg) +\n  tm_polygons(col = \"avg_occupancy\", palette = \"Blues\", style = 'quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nWe immediately see a big difference based on the year. There was a far lesser occupancy rate during the covid years as we can see from the above choropleth maps.\nOccupancy rates peaked in 2019 and dropped in 2020 and 2021. The occupancy rate has started to rebound and return to higher levels in ‘post-covid’.\nAnother thing to pay attention to is the occupancy rate of each individual region. We notice that regions with high occupancy rates do not necessarily indicate high revenue or high number of tourists. This indicates to us that it’s a smaller region or a region with few hotels in general. There is room for boosting the tourism in these regions by improving the hotels and increasing the number of hotels in these regions.\n\n2.3.1.4 Seasonal Data\n\n2.3.1.4.1 Number of tourists by season\nWe will now analyse how revenue is distributed based on the month of the year.\nFor this, we first aggregate data based on certain features such as holiday periods and seasons.\nWe determine that there are three distinct seasons in Thailand from the [‘UK Meteorological Office’](https://www.metoffice.gov.uk/weather/travel/holiday-weather/asia/thailand#:~:text=Part%20of%20Thailand’s%20appeal%20is,season%20(March%20to%20May).\n\ntourists_temporal$province_eng &lt;- gsub(\"Nong Bua Lamphu\", \"Nong Bua Lam Phu\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Sisaket\", \"Si Sa Ket\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Phang Nga\", \"Phangnga\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Lopburi\", \"Lop Buri\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Chonburi\", \"Chon Buri\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Chainat\", \"Chai Nat\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Buriram\", \"Buri Ram\", tourists_temporal$province_eng)\ntourists_temporal$province_eng &lt;- gsub(\"Prachinburi\", \"Prachin Buri\", tourists_temporal$province_eng)\n# Assuming your dataset is called 'tourists_temporal' and has a 'month' column\ntourists_temporal &lt;- tourists_temporal %&gt;%\n  mutate(season = case_when(\n    month %in% c(5, 6, 7, 8, 9, 10) ~ \"Wet Season\",\n    month %in% c(11, 12, 1, 2) ~ \"Cool Season\",\n    month %in% c(3, 4, 5) ~ \"Hot Season\"\n  ))\n\n# View the result\nhead(tourists_temporal)\n\n# A tibble: 6 × 10\n  date       province_thai province_eng    region_thai region_eng variable value\n  &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;\n1 2019-01-01 กรุงเทพมหานคร  Bangkok         ภาคกลาง     central    ratio_t…  93.4\n2 2019-01-01 ลพบุรี          Lop Buri        ภาคกลาง     central    ratio_t…  61.3\n3 2019-01-01 พระนครศรีอยุธยา Phra Nakhon Si… ภาคกลาง     central    ratio_t…  73.4\n4 2019-01-01 สระบุรี         Saraburi        ภาคกลาง     central    ratio_t…  67.3\n5 2019-01-01 ชัยนาท         Chai Nat        ภาคกลาง     central    ratio_t…  79.3\n6 2019-01-01 นครปฐม        Nakhon Pathom   ภาคกลาง     central    ratio_t…  71.7\n# ℹ 3 more variables: month &lt;dbl&gt;, year &lt;dbl&gt;, season &lt;chr&gt;\n\n\nWe now join tourists_temporal df to the province df create separate data-frames for each.\n\n# Separate data frames for each season\n\nwet_season_df &lt;- tourists_temporal %&gt;%\n  filter(season == \"Wet Season\")\n\ncool_season_df &lt;- tourists_temporal %&gt;%\n  filter(season == \"Cool Season\")\n\nhot_season_df &lt;- tourists_temporal %&gt;%\n  filter(season == \"Hot Season\")\n\nWe now sum the values using the group_by() function.\n\n# Obtaining aggregates\nwet_sum= wet_season_df %&gt;%\n  group_by(province_eng, variable) %&gt;%\n  summarize(total_value = sum(value, na.rm = TRUE))\n\n# JOINING DF TO THE PROVINCE DF\nwet_sum=left_join(wet_sum, province, by=c('province_eng'='ADM1_EN'))\n\n# Obtaining Aggregates\ncool_sum= cool_season_df %&gt;%\n  group_by(province_eng, variable) %&gt;%\n  summarize(total_value = sum(value, na.rm = TRUE))\n\n#Joining to province df\ncool_sum= left_join(cool_sum, province, by=c('province_eng'='ADM1_EN'))\n\n# Obtaining Aggregates\nhot_sum= hot_season_df %&gt;%\n  group_by(province_eng, variable) %&gt;%\n  summarize(total_value = sum(value, na.rm = TRUE))\n\n#Joining to province df\nhot_sum=left_join(hot_sum, province, by=c('province_eng'='ADM1_EN'))\n\nWe now create choropleth maps for each by implementing functions of the tmap packages.\n\nWet SeasonHot seasonCool season\n\n\n\nwet_sum=st_as_sf(wet_sum)\n\nwet_tourism_foreign=wet_sum%&gt;%filter(variable=='no_tourist_foreign')\nwet_tourism_thai= wet_sum%&gt;%filter(variable=='no_tourist_thai')\n\n# Create the basemap\nbasemap11 &lt;- tm_shape(wet_tourism_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap12&lt;- tm_shape(wet_tourism_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap11, basemap12)\n\n\n\n\n\n\n\n\nThere are far more domestic travellers in the rainy season compared to foreign travellers.\n\n\n\nhot_sum=st_as_sf(hot_sum)\n\nhot_tourism_foreign=hot_sum%&gt;%filter(variable=='no_tourist_foreign')\nhot_tourism_thai= hot_sum%&gt;%filter(variable=='no_tourist_thai')\n\n# Create the basemap\nbasemap13 &lt;- tm_shape(hot_tourism_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap14&lt;- tm_shape(hot_tourism_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap13, basemap14)\n\n\n\n\n\n\n\n\n\n\n\ncool_sum=st_as_sf(cool_sum)\n\ncool_tourism_foreign=cool_sum%&gt;%filter(variable=='no_tourist_foreign')\ncool_tourism_thai= cool_sum%&gt;%filter(variable=='no_tourist_thai')\n\n# Create the basemap\nbasemap15 &lt;- tm_shape(cool_tourism_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap16&lt;- tm_shape(cool_tourism_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='jenks') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap15, basemap16)\n\n\n\n\n\n\n\n\n\n\n\nWe see clear differences in number of tourists across regions based on the season, indicating to us that tourism is not independent from temporal factors such as time of the year.\n\n\n2.3.1.4.2 Profit from tourists by season\n\nWet SeasonHot seasonCool Season\n\n\n\nwet_sum=st_as_sf(wet_sum)\n\nwet_profit_foreign=wet_sum%&gt;%filter(variable=='revenue_foreign')\nwet_profit_thai= wet_sum%&gt;%filter(variable=='revenue_thai')\n\n# Create the basemap\nbasemap21 &lt;- tm_shape(wet_profit_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap22&lt;- tm_shape(wet_profit_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap21, basemap22)\n\n\n\n\n\n\n\n\n\n\n\nhot_sum=st_as_sf(hot_sum)\n\nhot_profit_foreign=hot_sum%&gt;%filter(variable=='revenue_foreign')\nhot_profit_thai= hot_sum%&gt;%filter(variable=='revenue_thai')\n\n# Create the basemap\nbasemap23 &lt;- tm_shape(hot_profit_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap24&lt;- tm_shape(hot_profit_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap23, basemap24)\n\n\n\n\n\n\n\n\n\n\n\ncool_sum=st_as_sf(cool_sum)\n\ncool_profit_foreign=cool_sum%&gt;%filter(variable=='revenue_foreign')\ncool_profit_thai= cool_sum%&gt;%filter(variable=='revenue_thai')\n\n# Create the basemap\nbasemap25 &lt;- tm_shape(cool_profit_foreign) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\n\nbasemap26&lt;- tm_shape(cool_profit_thai) +\n  tm_polygons(col = \"total_value\", palette = \"Blues\", style='quantile') +\n  tm_text(\"province_eng\", size = 0.5)\n\ntmap_arrange(basemap25, basemap26)\n\n\n\n\n\n\n\n\n\n\n\nWe notice that while for the most part, there are significantly more domestic travellers, more profit is earned from foreign travellers throughout the year.\nWe infer from our above visualizations that tourism statistics are not independent from space and time. Both of these factors impact the different metrics significantly."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#bangkok",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#bangkok",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Bangkok",
    "text": "Bangkok\n\nProfitOccupancy Rate\n\n\n\nbkk &lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Bangkok\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nbkk_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Bangkok\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#krabi",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#krabi",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Krabi",
    "text": "Krabi\n\nProfitOccupancy Rate\n\n\n\nkra &lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Krabi\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = kra, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nkra_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Krabi\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#phuket",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#phuket",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Phuket",
    "text": "Phuket\n\nProfitOccupancy Rate\n\n\n\nphk&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Phuket\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now produce a plot to visualize this.\n\nggplot(data = phk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nphk_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Phuket\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#chon-buri",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#chon-buri",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Chon Buri",
    "text": "Chon Buri\n\nProfitOccupancy Rate\n\n\n\ncbr&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chon Buri\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now produce a plot for the same\n\nggplot(data = cbr, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\ncbr_occ &lt;- gi_stars_occ%&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chon Buri\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = bkk_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#chiang-mai",
    "href": "Take-home_Ex/Take-home_Ex2/Take-home_Ex02.html#chiang-mai",
    "title": "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics",
    "section": "Chiang Mai",
    "text": "Chiang Mai\n\nProfitOccupancy Rate\n\n\n\nchm&lt;- gi_stars_profit %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chiang Mai\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe now create a plot for the same.\n\nggplot(data = chm, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\nchm_occ &lt;- gi_stars_occ %&gt;% \n  ungroup() %&gt;% \n  filter(ADM1_EN == \"Chiang Mai\") %&gt;% \n  select(ADM1_EN, date, gi_star)\n\nWe can now produce a plot by using the ggplot package.\n\nggplot(data = chm_occ, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\n\n\n\n:::\nFor all of these regions, besides Chiang Mai, we see a sharp drop between 2021 and 2022 however for the most part none of these regions reach their peaks between 2020 and 2022, which was when the world was hit by a global pandemic.\n\nAlternatively, we can also create an interactive plot using the ggplotly() function of the plotly package.\nThe code chunk below can be used.\n\n## Interactive plot for Bangkok \n\np &lt;- ggplot(data = bkk, \n       aes(x = date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\nWe now generate the report for the Mann Kendall Test by implementing the below code chunk.\nA Monotonic series or function is one that only increases (or decreases) and never changes direction. So long as the function either stays flat or continues to increase, it is monotonic.\n\nH0: No monotic trend.\nH1: Monotonic trend is present\n\n\nTau ranges between -1 and 1 where:\n\n-1 is a perfectly decreasing series.\n1 is a perfectly increasing series.\n\n\nWe implement the below code chunk to obtain the required report.\n\nBangkokKrabiChiang Mai\n\n\n\nbkk %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n     tau    sl     S     D   varS\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.118 0.228  -145  1225 14292.\n\n\n\n\n\nkra %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n      tau    sl     S     D   varS\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.0318 0.751   -39  1225 14292.\n\n\n\n\n\nchm %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau     sl     S     D   varS\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.249 0.0110   305  1225 14292.\n\n\n\n\n\n\n2.4.3.3.5 Mann-Kendall Test Data-Frame\nWe perform the above steps for every location by using the group_by() function of the dplyr package.\n\nProfitsNumber of touristsOccupancy Rate\n\n\n\nehsa &lt;- gi_stars_profit %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  ADM1_EN            tau        sl     S     D   varS\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.138   0.160      -169  1225 14292.\n2 Ang Thong     -0.429   0.0000117  -525  1225 14292.\n3 Bangkok       -0.118   0.228      -145  1225 14292.\n4 Bueng Kan     -0.0971  0.324      -119  1225 14292.\n5 Buriram        0.0204  0.841        25  1225 14292.\n6 Chachoengsao   0.00898 0.933        11  1225 14292.\n\n\n\n\n\nehsa_tour &lt;- gi_stars_tour %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa_tour)\n\n# A tibble: 6 × 6\n  ADM1_EN           tau        sl     S     D   varS\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.238  0.0153     -291  1225 14292.\n2 Ang Thong     -0.0563 0.569       -69  1225 14292.\n3 Bangkok       -0.391  0.0000638  -479  1225 14292.\n4 Bueng Kan     -0.259  0.00821    -317  1225 14292.\n5 Buriram        0.153  0.120       187  1225 14292.\n6 Chachoengsao   0.0988 0.315       121  1225 14292.\n\n\n\n\n\nehsa_occ &lt;- gi_stars_occ %&gt;%\n  group_by(ADM1_EN) %&gt;%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %&gt;%\n  tidyr::unnest_wider(mk)\nhead(ehsa_occ)\n\n# A tibble: 6 × 6\n  ADM1_EN          tau        sl     S     D   varS\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Amnat Charoen -0.109 0.270      -133  1225 14292.\n2 Ang Thong     -0.420 0.0000171  -515  1225 14292.\n3 Bangkok       -0.205 0.0365     -251  1225 14292.\n4 Bueng Kan      0.257 0.00863     315  1225 14292.\n5 Buriram        0.122 0.216       149  1225 14292.\n6 Chachoengsao  -0.324 0.000925   -397  1225 14292.\n\n\n\n\n\nWe now sort the data-frame to highlight emerging hot/cold spots by implementing the below code chunk for all three variables of interest.\n\nProfitsNumber of touristsOccupancy Rate\n\n\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  ADM1_EN         tau          sl     S     D   varS\n  &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Phichit       0.540 0             661  1225 14292.\n2 Mae Hong Son  0.527 0.000000119   645  1225 14292.\n3 Chiang Rai    0.528 0.000000119   647  1225 14292.\n4 Saraburi     -0.510 0.000000179  -625  1225 14292.\n5 Ratchaburi   -0.499 0.000000335  -611  1225 14292.\n6 Phitsanulok   0.471 0.00000143    577  1225 14292.\n\n\n\n\n\nemerging_tour &lt;- ehsa_tour %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging_tour)\n\n# A tibble: 6 × 6\n  ADM1_EN            tau          sl     S     D   varS\n  &lt;chr&gt;            &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Phichit          0.572 0             701  1225 14292.\n2 Chiang Rai       0.497 0.000000358   609  1225 14292.\n3 Mae Hong Son     0.482 0.000000834   591  1225 14292.\n4 Sa Kaeo         -0.461 0.00000238   -565  1225 14292.\n5 Samut Songkhram  0.424 0.0000147     519  1225 14292.\n6 Ratchaburi      -0.407 0.0000310    -499  1225 14292.\n\n\n\n\n\nemerging_occ &lt;- ehsa_occ %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging_occ)\n\n# A tibble: 6 × 6\n  ADM1_EN         tau          sl     S     D   varS\n  &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Nan           0.553 0             677  1225 14292.\n2 Nakhon Phanom 0.554 0             679  1225 14292.\n3 Phrae         0.587 0             719  1225 14292.\n4 Chiang Mai    0.507 0.000000238   621  1225 14292.\n5 Phayao        0.510 0.000000238   625  1225 14292.\n6 Uttaradit     0.460 0.00000262    563  1225 14292.\n\n\n\n\n\n\n\n2.4.3.3.6 Emerging Hot-Spot Analysis\nWe now perform EHSA by using the emerging_hotspot_analysis() function of the sfdep package.\nIt takes a spacetime object x (i.e: profit_st, tourist_st and occupancy_st), and the quoted name of the variable of interest (i.e. Profit, Occupancy Rate and Number of tourists) as the .var argument.\nThe k argument is used to specify the number of time lags which is set to 1 by default.\nnsim is number of simulations to be performed.\n\nProfitNumber of touristsOccupancy Rate\n\n\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = profits_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa &lt;- province %&gt;%\n  left_join(ehsa,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig &lt;- thai_ehsa  %&gt;%\n  filter(p_value &lt; 0.1)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\n\n\n\nehsa_tour &lt;- emerging_hotspot_analysis(\n  x = tourist_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa_tour,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa_tour &lt;- province %&gt;%\n  left_join(ehsa_tour,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig_tour &lt;- thai_ehsa_tour  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa_tour) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_tour) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\nWe don’t see too many patterns detected, indicating that it is pretty consistent over time. .\n\n\n\nehsa_occ &lt;- emerging_hotspot_analysis(\n  x = occupancy_st, \n  .var = \"value\", \n  k = 1, \n  nsim = 99\n)\n\nWe now implement various ggplot2 functions to reveal the distributions of EHSA classes as a bar chart.\n\nggplot(data = ehsa_occ,\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can proceed with Visualizing EHSA.\n\nthai_ehsa_occ &lt;- province %&gt;%\n  left_join(ehsa_occ,\n            by = join_by(ADM1_EN == location))\n\nWe can now implement functions of the tmap package to produce a visualization for the above.\n\nehsa_sig_occ &lt;- thai_ehsa_occ  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thai_ehsa_occ) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_occ) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)+\n  tm_text('ADM1_EN', size=0.3)\n\n\n\n\n\n\n\n\nWe see a majority of the northern part of Thailand as well as a part of the central region are oscillating hotspots. Whereas, there are oscillating cold spots scattered across the nation.\n\n\n\n\nThere are several categories for emerging hotspot analysis however these are the most common. The below will help you interpret them.\nSporadic Hotspots: Locations with occasional bursts of high activity but without consistent patterns over time.\nOscillating Hotspots: Locations where high activity alternates between being present and absent over different time periods.\nSporadic Coldspots: Locations with occasional periods of low activity, lacking consistent patterns over time.\nOscillating Coldspots: Locations where low activity alternates between being present and absent over time."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html",
    "title": "In Class Exercise 7",
    "section": "",
    "text": "In this exercise, we will work on reinforcing our learning from Hands-on Exercise 7 with further exercises."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices. On the other hands, Geovisualization works by providing graphical ideations to render a place, a phenomenon or a process visible, enabling a humans most powerful information-processing abilities- those of spatial cognition associated with our eye-brain vision system, to be directly brought to bear.\n\n\nTo fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nAs discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nChoropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#getting-started",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "To fulfill the learning objectives for this section, the key R package is the tmap package. In addition to tmap, the other packages used are: readr, tidyr, dplyr [all of which can be loaded by loading the tidyverse package], and sf.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#importing-the-data-into-r",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "As discussed earlier, we will be using the st_read() function of the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data-frame.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe further examine the contents of the simple feature data-frame below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\n\n\nNow, we import the respopagsex2011to2020.csv file into R and save the file into an R data-frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nAs with any form analysis, data preparation is key for Geospatial Analysis as well. Before preparing a thematic map, preparing a data table with values from the year 2020 is required. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age groups, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions are used: pivot_wider() of the tidyr package, and mutate(), filter(), group_by(), and select() of the dplyr package.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\n\nBefore we can proceed with the georelational join, we must convert the values in the PA and SZ columns to uppercase. This is because the values in the PA and SZ columns are made up of upper- and lowercase characters while the SUBZONE_N and PLN_AREA_N columns contain only uppercase characters.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe now use the left_join() function of the dplyr package to join the geographical data with the attribute table using the name of the Planning Subzone (SUBZONE_N and SZ as the common key).\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUsing left_join() above, we ensure that the resulting table is a simple feature data-frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#chropleth-mapping-geospatial-data-using-tmap.",
    "title": "Hands-On Exercise 1-Part 2",
    "section": "",
    "text": "Choropleth Mapping involves the symbolization of enumeration units such as countries, provinces, states, counties, or census units, using area patterns or graduated colors. For example, a social scientist may need to use a Choropleth Map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThe following approaches can be used to prepare thematic maps using tmap:\n\nPlotting a thematic map quickly using qtm().\nPlotting a highly customisable thematic map by using tmap elements.\n\n\n\nThis is the simplest way to produce a Choropleth Map using tmap. It is concise and generally produces a good visualization.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe tmap_mode() function with the “plot” option is used to produce a static map. To produce an interactive plot, the “view” option should be used. The fill argument is used to map the required attribute, which in this case is “DEPENDENCY”.\n\n\n\nDespite its ease of use, the big disadvantage of using qtm() is that it makes controlling the aesthetics of the individual layers harder. To produce a high quality cartographic Choropleth map, tmaps drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elements such as tm_fill() and tm_polygons().\ntm_shape() is used to define the input data (mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\nTo draw a Choropleth Map that shows the geographical distribution of a selected variable based on the Planning Subzone, we need to assign the target variable, DEPENDENCY for example, to tm_polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe default interval binning used to draw the Choropleth Map is called “pretty”. The data classification methods supported by tmap will be discussed in section 1.11.3 below\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default color scheme while tm_borders() adds the borders of the shapefile onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThe planning subzones are shared according to their respective dependency values.\nTo add the boundary of the planning subzones, we use the tm_borders() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument in the function defines the transparency number between 0 (transparent) and 1 (not transparent). By default, the alpha value of the col is used (generally 1).\nBesides alpha, the other 3 arguments are col (border color), lwd (border line width- the default is 1), and lty (border line type- the default is ‘solid.’)\n\n\n\n\nMost Choropleth maps employ some data classification methods. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total of 10 data classification methods (namely fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.)\nTo define a data classification method, the style argument of tm_fill() or tm_polygons will be used.\n\n\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBelow, we see the equal data classification in use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nBased on our outputs above, the distribution of the quantile data classification method is more evenly distributed relative to the equal data classification method.\nWe must test out different data classification methods and compare their differences to decide the best method to use.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 8,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nFor example, we see wide ranges above due to uneven distribution when using the kmeans method, indicating that 8 clusters is too many.\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly using the breaks argument of the tm_fill() function.\nWhen using the tmap, the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements MUST be specified in the breaks option (the values must be in increasing order.)\nWe have a look at the descriptive statistics to gain a better understanding of the data-frame before proceeding.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nBased on the above statistics, we can set the breakpoints at 0.6, 0.7, 0.8, and 0.9. Additionally, we also have to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is then c(0, 0.6, 0.7, 0.8, 0.9, 1.0)\nNow, we plot the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap supports both user-defined color ramps as well as a set of predefined color ramps from the RColorBrewer package.\n1.11.4.1 Using ColorBrewer Palette.\nTo change the color, we assign the preferred color to the palette argument of the tm_fill() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWhen shading it in green, we can use ‘-green’ to reverse the shading pattern- the lower, the better in this case!\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nMap Layout refers to the combination of all map elements into a cohesive map. Map elements include the objects to be mapped, the title, the scale bar, margins, the compass, and aspect ratios, among other elements.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of changes to the layout settings. They can be called using tmap_style().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\n\nBesides map styles, tmap also provides arguments to draw other map furniture such as a compass, a scale bar, and grid lines.\nBelow, we use tm_compass(), tm_scale_bar(), and tm_grid() to add a compass, scale bar and grid lines onto the Choropleth Map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSmall multiple maps, also known as facet maps, are composed of many maps arranged side by side, and sometimes stacked vertically. Small multiple maps enable us the visualize how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in the following three ways:\n\nBy assigning multiple values to at least one of the asthetic arguments,\nBy defining a group-by variable in tm_facets()\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this case, small multiple Choropleth Maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\n\n\n\n\nIn thie following example, small multiple Choropleth Maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small Chloropleth Maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\n\n\n\n\n\n\n\nIn the example below, we create multiple small Chloropleth Maps by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of creating multiple small Chloropleth Map, we can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\n\n\n\n\nThanks for following, this is the end of hands on exercise 1."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#importing-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#importing-the-geospatial-data",
    "title": "In Class Exercise 7",
    "section": "7.2.1 Importing the geospatial data",
    "text": "7.2.1 Importing the geospatial data\nWe start off by importing the geospatial data into our environment. We use the st_read() function of the sf package for this.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\arjxn11\\ISSS626-GAA\\In-class_Ex\\In-class_Ex7\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis dataset is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems. The geometry type is multipolygon.\nWe will now check the CRS information and update it if required.\nEPSG code for Singapore is 3414.\n\nChecking CRSUpdating CRS\n\n\nWe implement the st_crs() function of the sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\nWe note that the current EPSG code is 9001, which is inaccurate. We must update this to 3414. The st_transform() function of the sf package will be implemented.\n\nmpsz_svy21=st_transform(mpsz, 3414) \nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#importing-and-wrangling-the-aspatial-data",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#importing-and-wrangling-the-aspatial-data",
    "title": "In Class Exercise 7",
    "section": "7.2.2 Importing and wrangling the Aspatial Data",
    "text": "7.2.2 Importing and wrangling the Aspatial Data\nSince this is in CSV format, we implement read_csv() of the readr package to import it.\nAlways be careful to use read_csv() rather than read.csv().\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nXCOORD ColumnYCOORD Column\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\n\n\nWe now implement the summary() function of base R to condo_resale.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n7.2.2.1 Converting aspatial data frame into a sf object\nCurrently, the condo_resale data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() function of sf package.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414). We first set the CRS to 4326 as CSV data does not have the projection information.\n\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\n\nNotice that the output is in point feature data frame. This is because it has only latitude and longitude."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#eda-using-statistical-graphics",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#eda-using-statistical-graphics",
    "title": "In Class Exercise 7",
    "section": "7.3.1 EDA using statistical graphics",
    "text": "7.3.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%   mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#multiple-histogram-plots-distribution-of-variables",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#multiple-histogram-plots-distribution-of-variables",
    "title": "In Class Exercise 7",
    "section": "7.3.2 Multiple Histogram Plots distribution of variables",
    "text": "7.3.2 Multiple Histogram Plots distribution of variables\nWe now plot multiple histograms (also known as trellis plot) by using the ggarrange() function of the ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) +    geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\") \nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) +    geom_histogram(bins=20, color=\"black\", fill=\"light blue\") \nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf,                                 aes(x= `PROX_URA_GROWTH_AREA`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\")  \nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf,                                 aes(x= `PROX_TOP_PRIMARY_SCH`)) +   geom_histogram(bins=20, color=\"black\", fill=\"light blue\") \nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE,            PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,           PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,             ncol = 3, nrow = 4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#drawing-a-statistical-point-map",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#drawing-a-statistical-point-map",
    "title": "In Class Exercise 7",
    "section": "7.3.3 Drawing a statistical point map",
    "text": "7.3.3 Drawing a statistical point map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\n\ntmap_mode(\"view\") \ntm_shape(mpsz_svy21)+   \n  tm_polygons() + \n  tm_shape(condo_resale.sf) +     \n  tm_dots(col = \"SELLING_PRICE\", alpha = 0.6,style=\"quantile\")+   \n  tm_view(set.zoom.limits = c(11,14))+   \n  tmap_options(check.and.fix = TRUE)\n\n\n\n\n\nWe change tmap_mode back to plot before proceeding.\n\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#simple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#simple-linear-regression-method",
    "title": "In Class Exercise 7",
    "section": "7.4.1 Simple Linear Regression Method",
    "text": "7.4.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe R-squared value of 0.4518 indicates that the simple regression model explains approximately 45% of the variation in resale prices.\nGiven that the p-value is much smaller than 0.0001, we can confidently reject the null hypothesis that the mean is an adequate predictor of the SELLING_PRICE. This suggests that the simple linear regression model is a significantly better estimator of SELLING_PRICE.\nThe Coefficients section of the report shows that the p-values for both the Intercept and ARA_SQM estimates are less than 0.001. This allows us to reject the null hypothesis that B0 (the intercept) and B1 (the slope for ARA_SQM) are equal to zero. Therefore, we can conclude that B0 and B1 are reliable parameter estimates.\nTo visualize the best fit line on a scatterplot, we can use the lm() method within ggplot’s geometry functions, as demonstrated in the following code snippet.\n\nggplot(data=condo_resale.sf,          aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +   geom_point() +   geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nThe figure above reveals that there are indeed a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#multiple-linear-regression-method",
    "title": "In Class Exercise 7",
    "section": "7.4.2 Multiple Linear Regression Method",
    "text": "7.4.2 Multiple Linear Regression Method\n\n7.4.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), \n         diag = FALSE, order = \"AOE\",          \n         tl.pos = \"td\", tl.cex = 0.5, \n         method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\nggcorrmat(condo_resale[, 5:23])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "In Class Exercise 7",
    "section": "7.4.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "7.4.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\nNote that we have added an additional variable LEASEHOLD_99YR to the below model for this in-class exercise.\n\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE+\n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH +  \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET +  \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD+ LEASEHOLD_99YR,\n                data=condo_resale.sf) \nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD + \n    LEASEHOLD_99YR, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3471036  -286903   -22426   239412 12254549 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           543071.4   136210.9   3.987 7.03e-05 ***\nAREA_SQM               12688.7      370.1  34.283  &lt; 2e-16 ***\nAGE                   -24566.0     2766.0  -8.881  &lt; 2e-16 ***\nPROX_CBD              -78122.0     6791.4 -11.503  &lt; 2e-16 ***\nPROX_CHILDCARE       -333219.0   111020.3  -3.001 0.002734 ** \nPROX_ELDERLYCARE      170950.0    42110.8   4.060 5.19e-05 ***\nPROX_URA_GROWTH_AREA   38507.6    12523.7   3.075 0.002147 ** \nPROX_HAWKER_MARKET     23801.2    29299.9   0.812 0.416739    \nPROX_KINDERGARTEN     144098.0    82738.7   1.742 0.081795 .  \nPROX_MRT             -322775.9    58528.1  -5.515 4.14e-08 ***\nPROX_PARK             564487.9    66563.0   8.481  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      186170.5    65515.2   2.842 0.004553 ** \nPROX_TOP_PRIMARY_SCH    -477.1    20598.0  -0.023 0.981525    \nPROX_SHOPPING_MALL   -207721.5    42855.5  -4.847 1.39e-06 ***\nPROX_SUPERMARKET      -48074.7    77145.3  -0.623 0.533273    \nPROX_BUS_STOP         675755.0   138552.0   4.877 1.20e-06 ***\nNO_Of_UNITS             -216.2       90.3  -2.394 0.016797 *  \nFAMILY_FRIENDLY       142128.3    47055.1   3.020 0.002569 ** \nFREEHOLD              300646.5    77296.5   3.890 0.000105 ***\nLEASEHOLD_99YR        -77137.4    77570.9  -0.994 0.320192    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1416 degrees of freedom\nMultiple R-squared:  0.652, Adjusted R-squared:  0.6474 \nF-statistic: 139.6 on 19 and 1416 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#preparing-publication-quality-table-olsrr-method",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#preparing-publication-quality-table-olsrr-method",
    "title": "In Class Exercise 7",
    "section": "7.4.4 Preparing Publication Quality Table: olsrr method",
    "text": "7.4.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD+ LEASEHOLD_99YR,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751634.509 \nR-Squared                    0.651       MSE                571320119490.610 \nAdj. R-Squared               0.647       Coef. Var                    43.162 \nPred R-Squared               0.637       AIC                       42967.367 \nMAE                     413020.461       SBC                       43056.951 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.513372e+15          15        1.008915e+14    176.594    0.0000 \nResidual      8.112746e+14        1420    571320119490.610                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     591539.643    121110.937                   4.884    0.000     353964.068     829115.218 \n            AREA_SQM      12754.325       367.962        0.582     34.662    0.000      12032.517      13476.133 \n                 AGE     -24822.087      2756.860       -0.168     -9.004    0.000     -30230.043     -19414.132 \n            PROX_CBD     -76833.361      5767.956       -0.262    -13.321    0.000     -88147.991     -65518.730 \n      PROX_CHILDCARE    -297608.214    109400.497       -0.078     -2.720    0.007    -512212.168     -83004.261 \n    PROX_ELDERLYCARE     183303.549     39943.561        0.089      4.589    0.000     104948.823     261658.276 \nPROX_URA_GROWTH_AREA      39752.039     11763.983        0.061      3.379    0.001      16675.385      62828.692 \n            PROX_MRT    -305114.878     57591.189       -0.116     -5.298    0.000    -418087.828    -192141.927 \n           PROX_PARK     572038.799     65511.407        0.150      8.732    0.000     443529.265     700548.334 \n    PROX_PRIMARY_SCH     164542.899     60358.977        0.064      2.726    0.006      46140.557     282945.241 \n  PROX_SHOPPING_MALL    -220515.279     36558.846       -0.115     -6.032    0.000    -292230.427    -148800.131 \n       PROX_BUS_STOP     674997.951    134646.651        0.133      5.013    0.000     410870.234     939125.668 \n         NO_Of_UNITS       -228.616        89.102       -0.049     -2.566    0.010       -403.402        -53.830 \n     FAMILY_FRIENDLY     148152.863     46913.189        0.058      3.158    0.002      56126.263     240179.463 \n            FREEHOLD     281136.713     76537.974        0.109      3.673    0.000     130997.067     431276.358 \n      LEASEHOLD_99YR     -89655.454     76421.659       -0.035     -1.173    0.241    -239566.931      60256.022 \n-----------------------------------------------------------------------------------------------------------------\n\n\nWe use the olsrrr package to generate a report for the model we created above (condo.mlr), similar to the method shown in the above code chunk.\n\nols_regress(condo.mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.223 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.223                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\nThis method even shows you the meaning of RMSE and other important statistics and facilitates analysis further.\nIt is a better method to use for detailed output compared to the basic lm() method.\nAdjusted R-squared value tells you how good your model is by informing you how much of the variation in price our model accounts for.\n\n\n\nMulticollinearity check using vif\nWe can check for multicollinearity using the code chunk below. (vif= variance inflation factor)\n\nols_vif_tol(condo.mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\nHigher vif indicates (over 5) multicollinearity. Above 10 means they must be eliminated from the model.\nIn our case, it shows that we do not need to eliminate them.\n\nHighly continuous correlated variables impact the model more so than correlated dummy variables would.\n\n\n\nVariable Selection using Stepwise Regression\nThere is forward and backward stepwise regression.\n\nForward: Start with no variables and add them one by one based on model improvement.\nBackward: Start with all variables and remove them one by one based on model deterioration.\n\n\nforwardbackward\n\n\n\ncondo_fw_mlr=ols_step_forward_p(condo.mlr,\n                                 p_val = 0.05,\n                                 details = FALSE)\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.582    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_fw_mlr)\n\n\n\n\n\n\n\n\n\n\n\ncondo_bw_mlr=ols_step_backward_p(condo.mlr,\n                    p_val = 0.05,\n                    details = FALSE)\ncondo_bw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Full Model              42971.173    43081.835    38896.546    0.65203    0.64736 \n 1      PROX_TOP_PRIMARY_SCH    42969.173    43074.565    38894.518    0.65203    0.64761 \n 2      PROX_SUPERMARKET        42967.567    43067.689    38892.873    0.65193    0.64776 \n 3      PROX_HAWKER_MARKET      42966.461    43061.315    38891.719    0.65172    0.64779 \n 4      LEASEHOLD_99YR          42965.558    43055.141    38890.764    0.65145    0.64777 \n 5      PROX_KINDERGARTEN       42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_bw_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#preparing-publication-quality-table-gtsummary-method",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#preparing-publication-quality-table-gtsummary-method",
    "title": "In Class Exercise 7",
    "section": "7.4.5 Preparing Publication Quality Table: gtsummary method",
    "text": "7.4.5 Preparing Publication Quality Table: gtsummary method\nThe broom package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tidy() function is used to create a well formatted regression report.\n\nbroom::tidy(condo.mlr1, intercept = TRUE)\n\n# A tibble: 16 × 5\n   term                 estimate std.error statistic   p.value\n   &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)           591540.  121111.       4.88 1.16e-  6\n 2 AREA_SQM               12754.     368.      34.7  2.84e-191\n 3 AGE                   -24822.    2757.      -9.00 6.84e- 19\n 4 PROX_CBD              -76833.    5768.     -13.3  3.11e- 38\n 5 PROX_CHILDCARE       -297608.  109400.      -2.72 6.60e-  3\n 6 PROX_ELDERLYCARE      183304.   39944.       4.59 4.85e-  6\n 7 PROX_URA_GROWTH_AREA   39752.   11764.       3.38 7.47e-  4\n 8 PROX_MRT             -305115.   57591.      -5.30 1.36e-  7\n 9 PROX_PARK             572039.   65511.       8.73 6.91e- 18\n10 PROX_PRIMARY_SCH      164543.   60359.       2.73 6.49e-  3\n11 PROX_SHOPPING_MALL   -220515.   36559.      -6.03 2.06e-  9\n12 PROX_BUS_STOP         674998.  134647.       5.01 6.03e-  7\n13 NO_Of_UNITS             -229.      89.1     -2.57 1.04e-  2\n14 FAMILY_FRIENDLY       148153.   46913.       3.16 1.62e-  3\n15 FREEHOLD              281137.   76538.       3.67 2.48e-  4\n16 LEASEHOLD_99YR        -89655.   76422.      -1.17 2.41e-  1"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#checking-for-multicollinearity",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#checking-for-multicollinearity",
    "title": "In Class Exercise 7",
    "section": "7.4.6 Checking for Multicollinearity",
    "text": "7.4.6 Checking for Multicollinearity\nIn this section, we use anl R package designed specifically for conducting OLS (Ordinary Least Squares) regression analysis—olsrr. This package offers a wide range of valuable tools to help you build more robust multiple linear regression models. Its key features include:\n\nComprehensive regression output\nDiagnostic tests for residuals\nInfluence measures for identifying outliers\nTests for heteroskedasticity\nCollinearity diagnostics to detect multicollinearity\nModel fit assessment\nEvaluation of variable contributions\nVarious methods for variable selection\n\nIn the code snippet below, we demonstrate how to use the ols_vif_tol() function from the olsrr package to assess potential multicollinearity among predictors in your regression model.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8703348 1.148983\n2                   AGE 0.7059074 1.416616\n3              PROX_CBD 0.6343823 1.576337\n4        PROX_CHILDCARE 0.2984991 3.350094\n5      PROX_ELDERLYCARE 0.6582967 1.519072\n6  PROX_URA_GROWTH_AREA 0.7496642 1.333931\n7              PROX_MRT 0.5112747 1.955896\n8             PROX_PARK 0.8275963 1.208319\n9      PROX_PRIMARY_SCH 0.4504807 2.219851\n10   PROX_SHOPPING_MALL 0.6738111 1.484095\n11        PROX_BUS_STOP 0.3506229 2.852067\n12          NO_Of_UNITS 0.6721417 1.487781\n13      FAMILY_FRIENDLY 0.7236014 1.381976\n14             FREEHOLD 0.2783151 3.593049\n15       LEASEHOLD_99YR 0.2726438 3.667789\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n7.4.6.1 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nNotice that we pass the newly generated forward stepwise model we created above. We explicitly state that it must use the model.\n\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n7.4.6.2 Test for Normality Assumption\nThe code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo_fw_mlr$model)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n7.4.6.3 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo_fw_mlr$model$residuals)%&gt;%\nrename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.sf &lt;- cbind(condo_resale.sf, \n                        mlr.output$`FW_MLR_RES`)%&gt;%\n  rename('MLR_RES'='mlr.output.FW_MLR_RES')\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) + # If we know that this particular layer is cause us issues, we specifically mention check.and.fix=TRUE here.\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode('plot')\n\n\nResiduals show the difference between actual transaction price and estimated price by the model.\n\nTO prove that our observation is indeed true, the Moran’s I test will be performed.\nWe first compute the distance-based weight matrix by using the st_knn() function of the sfdep package.\n\ncondo_resale.sf= condo_resale.sf%&gt;%\n  mutate(nb=st_knn(geometry, k=6, \n                   longlat=FALSE),\n         wt= st_weights(nb, \n                        style='W'),\n         .before=1)\n\n\nglobal_moran_perm(condo_resale.sf$MLR_RES, \n                  condo_resale.sf$nb,\n                  condo_resale.sf$wt,\n                  alternative='two.sided',\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe global Moran’s I test for residual spatial autocorrelation shows that it’s P value is less than 0.05, meaning we have sufficient evidence to reject the null hypothesis that the residuals are randomly distributed.\nSince the observed Global Moran I=0.25586, which is greater than 0, we can infer that the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-fixed-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-fixed-bandwidth-gwr-model",
    "title": "In Class Exercise 7",
    "section": "7.5.1 Building Fixed Bandwidth GWR Model",
    "text": "7.5.1 Building Fixed Bandwidth GWR Model\n\n7.5.1.1 Computing fixed bandwith\nIn the code chunk below, the bw.gwr() function of the GWModel package is used to determine the optimal fixed bandwidth to use in the model.\n\nNotice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\n\nThere are two possible approaches can be used to determine the stopping rule.\n\nCV cross-validation approach\nAIC corrected (AICc) approach.\n\nWe define the stopping rule using approach argeement.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sf, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres.\n\n\n7.5.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sf, \n                       approach='CV', \n                       kernel = 'gaussian', \n                    adaptive = FALSE,\n                       longlat = FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nWe use the code chunk below to display the model created above.\n\ngwr.fixed\n\n[1] 971.3405\n\n\n\ngwr.fixed&lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sf,\n                      bw=bw.fixed, \n                          kernel = 'gaussian', \n                          \n                          longlat = FALSE)\n\nThe output is saved in a list of flass ‘gwrm’. The code chunk below is used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 13:24:34.435927 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 13:24:36.082047 \n\n\n\nNotice the change, the improvement, in Adjusted R-Squared Value."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-adaptive-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#building-adaptive-bandwidth-gwr-model",
    "title": "In Class Exercise 7",
    "section": "7.5.2 Building Adaptive Bandwidth GWR Model",
    "text": "7.5.2 Building Adaptive Bandwidth GWR Model\n\n7.5.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\n\nConstructing Adaptive Model\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sf, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code chunk below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-17 13:24:46.474889 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-17 13:24:47.943393"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#visualising-gwr-output",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#visualising-gwr-output",
    "title": "In Class Exercise 7",
    "section": "7.5.3 Visualising GWR Output",
    "text": "7.5.3 Visualising GWR Output\nIn addition to the regression residuals, the output feature class table provides several key metrics, including observed and predicted values, the condition number (cond), Local R², residuals, and the coefficients with their standard errors for the explanatory variables:\n\nCondition Number: This diagnostic assesses local collinearity. When strong local collinearity is present, model results become unstable. A condition number greater than 30 suggests that the results may be unreliable due to multicollinearity.\nLocal R²: Values range from 0.0 to 1.0 and indicate the goodness-of-fit of the local regression model. Low Local R² values signal poor model performance in those regions. Mapping these values can help identify areas where the Geographically Weighted Regression (GWR) model is performing well and where it is underperforming, potentially highlighting missing or unaccounted-for variables.\nPredicted Values: These are the fitted y values estimated by the GWR model.\nResiduals: Residuals are calculated by subtracting the fitted y values from the observed y values. Standardized residuals have a mean of zero and a standard deviation of one. A gradient map (cold-to-hot) of standardized residuals can be created to visualize areas of model under- or overestimation.\nCoefficient Standard Errors: These values reflect the reliability of each coefficient estimate. Smaller standard errors relative to the actual coefficients indicate higher confidence in the estimates. Large standard errors, however, may suggest issues with local collinearity.\n\nAll of these metrics are stored within a SpatialPointsDataFrame or SpatialPolygonsDataFrame object, integrated with the fit points, GWR coefficient estimates, observed and predicted y values, coefficient standard errors, and t-values in the “data” slot of an object called SDF within the output list."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#converting-sdf-into-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#converting-sdf-into-sf-data.frame",
    "title": "In Class Exercise 7",
    "section": "7.5.4 Converting SDF into sf data.frame",
    "text": "7.5.4 Converting SDF into sf data.frame\n::: insights-box\nSDF provides you data of the intercepts.\n:::\n::: {.cell}\n\n```{.r .cell-code}\ngwr.adaptive.output=as.data.frame(gwr.adaptive$SDF)%&gt;%\n  select(-c(2:15)) # this removes the unnecessary columns and makes your work tidier. \n:::\n\ngwr_sf_adaptive=cbind(condo_resale.sf, gwr.adaptive.output)\n\nNext, glimpse() and summary() are used to display the content and summary of condo_resale.sf.adaptive sf data frame.\n\nGlimpseSummary\n\n\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 64\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\n\n\nsummary(gwr_sf_adaptive$SDF$yhat)\n\nLength  Class   Mode \n     0   NULL   NULL"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#visualizing-local-r2",
    "href": "In-class_Ex/In-class_Ex7/In-class_Ex7.html#visualizing-local-r2",
    "title": "In Class Exercise 7",
    "section": "7.5.5 Visualizing local R2",
    "text": "7.5.5 Visualizing local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modeling leverages statistical learning or machine learning techniques to forecast outcomes, typically focusing on future events. It relies on a dataset of known outcomes and predictor variables to train and fine-tune the model.\nGeospatial predictive modeling is grounded in the understanding that events of interest aren’t randomly or uniformly distributed across space. Instead, their occurrence is influenced by a number of geospatial factors such as infrastructure, sociocultural dynamics, and topography.\nBy analyzing geographically referenced data, geospatial predictive modeling seeks to capture and describe these influences and constraints, creating spatial correlations between historical event locations and relevant environmental factors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.1.1 The Data",
    "text": "8.1.1 The Data\n\nAspatial dataset:\n\nHDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n\nGeospatial dataset:\n\nMP14_SUBZONE_WEB_PL: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n\nLocational factors with geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nEldercare data is a list of eldercare in Singapore. It is in shapefile format.\nHawker Centre data is a list of hawker centres in Singapore. It is in geojson format.\nParks data is a list of parks in Singapore. It is in geojson format.\nSupermarket data is a list of supermarkets in Singapore. It is in geojson format.\nCHAS clinics data is a list of CHAS clinics in Singapore. It is in geojson format.\nChildcare service data is a list of childcare services in Singapore. It is in geojson format.\nKindergartens data is a list of kindergartens in Singapore. It is in geojson format.\n\nDownloaded from Datamall.lta.gov.sg.\n\nMRT data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\nBus stops data is a list of bus stops in Singapore. It is in shapefile format.\n\n\nLocational factors without geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nPrimary school data is extracted from the list on General information of schools from data.gov portal. It is in csv format.\n\nRetrieved/Scraped from other sources\n\nCBD coordinates obtained from Google.\nShopping malls data is a list of Shopping malls in Singapore obtained from Wikipedia.\nGood primary schools is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at Local Salary Forum."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#the-packages",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.1.2 The Packages",
    "text": "8.1.2 The Packages\nWe will use the following packages for our analysis:\n\nsf: R package for handling, analyzing, and visualizing spatial data using simple features.\nspdep: R package for spatial dependence modeling, including spatial autocorrelation and regression analysis.\nGWmodel: R package for geographically weighted regression (GWR) and other localized spatial models.\nSpatialML: R package for spatial machine learning, offering tools for spatially explicit predictive modeling.\ntmap: R package for creating thematic maps, offering a flexible and layered approach for spatial visualization.\nrsample: R package for resampling datasets, facilitating model training and evaluation with various sampling methods.\nMetrics: R package for calculating common metrics for regression and classification models, such as RMSE and accuracy.\ntidyverse: A collection of R packages designed for data manipulation, analysis, and visualization in a consistent and coherent syntax.\n\nWe use the p_load() function of the pacman package as shown in the code chunk below to import these packages into our environment.\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse)\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-sampling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-sampling",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.2.1 Data Sampling",
    "text": "8.2.1 Data Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using the initial_split() function of the rsample package.\nAfter splitting the data, we will store them as RDS files. We use the write_rds() function to create the RDS file and the read_rds() function to load the RDS file into our environment. This facilitates computational efficiency.\n\nData SamplingRDS File creationReading RDS Files\n\n\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\n\n\nwrite_rds(train_data, \"data/train_data.rds\")\nwrite_rds(test_data, \"data/test_data.rds\")\n\n\n\n\ntrain_data=read_rds('data/train_data.rds')\ntest_data=read_rds('data/test_data.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-the-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-the-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.1 Converting the sf data.frame to SpatialPointDataFrame",
    "text": "8.5.1 Converting the sf data.frame to SpatialPointDataFrame\nWe implement the as_Spatial() function of the sf package to conduct the conversion as shown in the code chunk below.\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-adaptive-bandwidth",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.2 Computing adaptive bandwidth",
    "text": "8.5.2 Computing adaptive bandwidth\nWe now use the bw.gwr() function of the GWmodel package to determine the optimal bandwidth to be used.\n\nThe code chunk below helps us determine adaptive bandwidth and the Cross Validation (CV) method is used to determine the optimal bandwidth.\n\n\nCalculationRDS File creationRead RDS File\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\nwrite_rds(bw_adaptive, \"data/bw_adaptive.rds\")\n\n\n\n\nbw_adaptive &lt;- read_rds(\"data/bw_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.3 Converting the test data from sf data.frame to SpatialPointDataFrame",
    "text": "8.5.3 Converting the test data from sf data.frame to SpatialPointDataFrame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#constructing-the-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#constructing-the-adaptive-bandwidth-gwr-model",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.4 Constructing the adaptive bandwidth gwr model",
    "text": "8.5.4 Constructing the adaptive bandwidth gwr model\nWe can now calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\nComputationRDS File creationReading RDS File\n\n\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\n\n\nwrite_rds(gwr_adaptive, 'data/gwr_adaptive.rds')\n\n\n\n\ngwr_adaptive=read_rds('data/gwr_adaptive.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-adaptive-bandwidth-for-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-adaptive-bandwidth-for-the-test-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.5 Computing adaptive bandwidth for the test data",
    "text": "8.5.5 Computing adaptive bandwidth for the test data\n\nComputationRDS File CreationRead RDS File\n\n\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\n\nwrite_rds(gwr_bw_test_adaptive, 'data/gwr_bw_test_adaptive.rds')\n\n\n\n\ngwr_bw_test_adaptive=read_rds('data/gwr_bw_test_adaptive.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-predicted-values-of-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computing-predicted-values-of-the-test-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.5.6 Computing predicted values of the test data",
    "text": "8.5.6 Computing predicted values of the test data\nThe gwr.predict() function is applied as shown in the code chunk below."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computation-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#computation-2",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "Computation",
    "text": "Computation\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw=40, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE,\n                        theta = 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#rds-file-creation-5",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#rds-file-creation-5",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "RDS File creation",
    "text": "RDS File creation\n\nwrite_rds(gwr_pred, 'data/gwr_pred.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reading-rds-file-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reading-rds-file-2",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "Reading RDS file",
    "text": "Reading RDS file\n\ngwr_pred=read_rds('data/gwr_pred.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extracting-coordinate-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extracting-coordinate-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.6.1 Extracting Coordinate Data",
    "text": "8.6.1 Extracting Coordinate Data\nWe extract the coordinates for each of the following three data-frames: mdata, train_data, test_data.\nThe st_coordinates() function is used.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#dropping-the-geometry-field",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#dropping-the-geometry-field",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.6.2 Dropping the Geometry Field",
    "text": "8.6.2 Dropping the Geometry Field\nWe now drop the geometry field from the train_data data-frame.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-using-training-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calibrating-using-training-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.8.1 Calibrating using training data",
    "text": "8.8.1 Calibrating using training data\nThe code chunk below is used to calibrate a geographic ranform forest model by using the grf() function of the SpatialML package.\n\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\nwrite_rds(gwRF_adaptive, \"data/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive=read_rds('data/gwRF_adaptive.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#predicting-by-using-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#predicting-by-using-test-data",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.8.2 Predicting by using test data",
    "text": "8.8.2 Predicting by using test data\n\n8.8.2.1 Preparing the test data\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n8.8.2.2 Predicting with test data\nWe now implement the predict.grf() function of the spatialML package to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\nCalibrationRDS File CreationReading RDS File\n\n\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\n\n\nwrite_rds(gwRF_pred, \"data/GRF_pred.rds\")\n\n\n\n\nGRF_pred &lt;- read_rds(\"data/GRF_pred.rds\")\n\n\n\n\n\n\n8.8.2.3 Converting the output into a data-frame\nWe implement the as.data.frame() function as shown in the code chunk below.\n\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nIn the code chunk below, we use the cbind() function to append the predicted values onto the test_data data-frame.\n\nRDS File CreationReading RDS File\n\n\n\n#| eval: false\n\nwrite_rds(test_data_p, \"data/test_data_p.rds\")\n\n\n\n\ntest_data_p=read_rds('data/test_data_p.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#root-mean-square-error-rmse",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#root-mean-square-error-rmse",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.8.3 Root Mean Square Error (RMSE)",
    "text": "8.8.3 Root Mean Square Error (RMSE)\nThe root mean square error (RMSE) allows us to measure how far the predicted values are from the observed values in a regression analysis.\nIn the code chunk below, the rmse() function of the Metrics package is used to compute the RMSE.\n\nrmse(test_data_p$resale_price,\n     test_data_p$GRF_pred)\n\n[1] 27302.16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualizing-the-predicted-values",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualizing-the-predicted-values",
    "title": "Hands On Exercise 8- Geographically Weighted Predictive Models",
    "section": "8.8.4 Visualizing the predicted values",
    "text": "8.8.4 Visualizing the predicted values\nAlternatively, we can use a scatterplot to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nA better predictive model would have the scattered points close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  }
]