---
title: "Take Home Exercise 3"
author: "Arjun Singh"
date: 2024-10-28
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
  warning: false
format:
  html:
    css: styles.css 
---

# 3 Introduction

Housing is a critical component of household wealth across the globe, and purchasing a home represents one of the most significant investments for many individuals. Housing prices are influenced by various factors, some of which are global—such as a country’s economic conditions and inflation rates—while others are specific to the properties themselves. These factors can be broadly categorized into structural and locational aspects.

Structural factors are attributes directly related to the property, such as its size, features, and ownership tenure. In contrast, locational factors pertain to the surrounding neighborhood and accessibility, including proximity to childcare centers, public transportation, and shopping facilities.

Traditionally, predictive models for housing resale prices have relied on the Ordinary Least Squares (OLS) method. However, OLS does not account for spatial autocorrelation and spatial heterogeneity—two common characteristics in geographical data like housing transactions. Ignoring spatial autocorrelation can lead to biased, inconsistent, or inefficient results in predictive housing pricing models (Anselin, 1998). To address this limitation, Geographically Weighted Models (GWMs) have been introduced, offering a more accurate approach to calibrating predictive models for housing resale prices by accounting for spatial variability.

# 3.1 Data and Packages

For this exercise, we use **HDB Resale Flat Prices** provided by [**Data.gov.sg**](https://data.gov.sg/) should be used as the core data set. The study should focus on either three-room, four-room or five-room flat.

![](images/clipboard-1921776033.png)

The following data-sets are used to incorporate locational factors:

-   CHAS Clinics

-   Eldercare

-   Supermarkets

-   Hawkers

-   Kindergartens

-   Parks

-   Childcare

All of the above have been acquired from [data.gov.sg](https://data.gov.sg/). The below have been acquired from [LTADataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

-   MRTs

-   Bus Stops

All the above datasets are downloaded from two main data sources- [data.gov.sg](https://data.gov.sg/) and [LTADataMall](https://datamall.lta.gov.sg/content/datamall/en.html).

We will use the following packages for our analysis:

-   **sf**: R package for handling, analyzing, and visualizing spatial data using simple features.

-   **spdep**: R package for spatial dependence modeling, including spatial autocorrelation and regression analysis.

-   **GWmodel**: R package for geographically weighted regression (GWR) and other localized spatial models.

-   **SpatialML**: R package for spatial machine learning, offering tools for spatially explicit predictive modeling.

-   **tmap**: R package for creating thematic maps, offering a flexible and layered approach for spatial visualization.

-   **rsample**: R package for resampling datasets, facilitating model training and evaluation with various sampling methods.

-   **Metrics**: R package for calculating common metrics for regression and classification models, such as RMSE and accuracy.

-   **tidyverse**: A collection of R packages designed for data manipulation, analysis, and visualization in a consistent and coherent syntax.

We use the p_load() function of the pacman package to load these packages into our environment.

```{r}
pacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse, spatstat, httr, jsonlite, rvest)
set.seed(1234)
```



## 3.1.2 Importing the data

### 3.1.2.1 Aspatial Data

The aspatial data for this exercise is the HDB Flat Resale data that we acquired from data.gov.sg.

We implement the read_csv() function to import this data-set into our environment.

We filter our data down to the time of interest- January 2023 till September 2024. 



```{r}
resale <- read_csv("data/aspatial/resale.csv") %>%
  filter(month >= "2023-01" & month <= "2024-09")
```
Additionally, we are going to focus on 3/4/5 room flats for this study.

```{r}
rooms=c('3 ROOM', '4 ROOM', '5 ROOM')
resale=resale%>%
  filter(flat_type %in% rooms)
```

We have over 43000 flats in our study.

The below code chunk tidies the data by combining the `block` and `street_name` columns to form the entire address.

Doing this will allow us to obtain the geographical coordinates accurately to facilitate the creation of our predictive model.

```{r}
resale_tidy <- resale %>%
  mutate(address = paste(block,street_name)) %>%
  mutate(remaining_lease_yr = as.integer(
    str_sub(remaining_lease, 0, 2)))%>%
  mutate(remaining_lease_mth = as.integer(
    str_sub(remaining_lease, 9, 11)))
```

The code chunk below creates a list of **unique** addresses in order to avoid having the same street and area being geocoded multiple times. Geocoding is usually 'first come, first serve', so sorting actually makes the code chunk more efficient.

```{r}
address_list <- sort(unique(resale_tidy$address))
```

The code chunk below is used in order to acquire the postal codes of the required addresses with the help of geocoding. The jsonlite and rvest packages are important for this.

::: insights-box

Geocoding is the process of converting a physical address or place name into geographic coordinates (latitude and longitude). This allows location data in address format to be mapped, visualized, and analyzed in spatial systems.

For example, if you have an address like "1600 Amphitheatre Parkway, Mountain View, CA," geocoding will convert it into coordinates, such as `37.4220° N, 122.0841° W`.

Geocoding is applied for a multitude of reasons, such as:

- **Mapping and navigation services**: To display locations on maps or provide directions.
- **Location-based services**: For ride-sharing, food delivery, and on-demand services, geocoding enables finding the user's location.
- **Data analysis**: Geocoding addresses in datasets allows analysis based on geography, such as customer distribution, logistics, and demographic studies.

Geocoding is typically done through APIs like Google Maps, OpenStreetMap, or **OneMap in Singapore** (which we will be using), which processes the address and returns the corresponding coordinates for our use.

:::


::: panel-tabset

## Reverse Geocoding

We start by defining a function `get_coords`.

```{r}
get_coords <- function(address_list){
  
  # Create a data frame to store all retrieved coordinates
  postal_coords <- data.frame()
    
  for (i in add_list){
    #print(i)

    r <- GET('https://www.onemap.gov.sg/api/common/elastic/search?',
           query=list(searchVal=i,
                     returnGeom='Y',
                     getAddrDetails='Y'))
    data <- fromJSON(rawToChar(r$content))
    found <- data$found
    res <- data$results
    
    # Create a new data frame for each address
    new_row <- data.frame()
    
    # If single result, append 
    if (found == 1){
      postal <- res$POSTAL 
      lat <- res$LATITUDE
      lng <- res$LONGITUDE
      new_row <- data.frame(address= i, 
                            postal = postal, 
                            latitude = lat, 
                            longitude = lng)
    }
    
    # If multiple results, drop NIL and append top 1
    else if (found > 1){
      # Remove those with NIL as postal
      res_sub <- res[res$POSTAL != "NIL", ]
      
      # Set as NA first if no Postal
      if (nrow(res_sub) == 0) {
          new_row <- data.frame(address= i, 
                                postal = NA, 
                                latitude = NA, 
                                longitude = NA)
      }
      
      else{
        top1 <- head(res_sub, n = 1)
        postal <- top1$POSTAL 
        lat <- top1$LATITUDE
        lng <- top1$LONGITUDE
        new_row <- data.frame(address= i, 
                              postal = postal, 
                              latitude = lat, 
                              longitude = lng)
      }
    }

    else {
      new_row <- data.frame(address= i, 
                            postal = NA, 
                            latitude = NA, 
                            longitude = NA)
    }
    
    # Add the row
    postal_coords <- rbind(postal_coords, new_row)
  }
  return(postal_coords)
}
```

## Obtain Coordinates and Postal Code

```{r}
#| eval: false 
coords <- get_coords(address_list)
```

## RDS File Creation

```{r}
#| eval: false 
write_rds(coords, "data/rds/coords.rds")
```

## Reading RDS File

```{r}
coords=read_rds('data/rds/coords.rds')
```

:::

Now that we have obtained the coordinates, we can create an sf object by using the st_as_sf() function of the sf package as shown in the code chunk below.

Converting it into an sf data-frame is necessary to conduct analysis and ensure consistent geometries. We first set the EPSG code to 4326 as it is undefined, and then convert it to the correct EPSG code of 3414 for Singapore. Skipping out on setting the initial CRS as 4326 will cause issues down the line as the geometries will not be accurate.

```{r}
resale_sf=st_as_sf(coords, coords = c('longitude', 'latitude'), crs= 4326, agr = 'constant')%>%
  st_transform(crs=3414)
```


#### 3.1.2.1.1 Relational Joins

We will now join our `resale_sf` data

```{r}
#| eval: false
resale_sf= resale_geom %>%
  left_join(resale_tidy, by = "address")


```


### 3.1.2.2 Geospatial Data

We first import the URA Master Plan data by implementing the st_read() function of the sf package.

Additionally, we ensure that the CRS information is consistent with that of Singapore to facilitate the creation of our predictive model. The st_transform() function of the sf package is implemented for this.

```{r}
mpsz=st_read(dsn = 'data/geospatial', layer='MP14_SUBZONE_WEB_PL')%>%
  st_transform(crs=3414)
```

::: note-box
The EPSG code of Singapore is 3414.
:::

#### 3.1.2.2.1 Extracting the CBD

::: panel-tabset
## CBD Planning Areas

```{r}
cbd_spots=c('ORCHARD', 'SINGAPORE RIVER', 'DOWNTOWN CORE', 'MUSUEM', 'RIVER VALLEY', 'NEWTON', ' ROCHOR', 'OUTRAM')
```

## CBD Data

```{r}
cbd=mpsz%>%
  filter(PLN_AREA_N %in% cbd_spots)%>%
  st_transform(crs=3414)
```
:::

We verify if it has been extracted as expected by plotting a highly cartographic map using the tmap package.

```{r}
tmap_mode('view')
tm_shape(cbd)+
  tm_polygons(col = 'green')
```

```{r}
tmap_mode('plot')
```
### 3.1.2.2 Locational Factors (Geospatial)

We will now import a number of data-sets that carry the data necessary for us to measure the impact of proximity to these facilities on housing prices.

Additionally, we ensure that the CRS information is consistent with that of Singapore to facilitate the creation of our predictive model. The st_transform() function of the sf package is implemented for this.

::: panel-tabset
## Eldercare

```{r}
eldercare= st_read(dsn='data/locational_factors', layer='ELDERCARE')%>%
  st_transform(crs=3414)
```

## CHAS Clinics

```{r}
CHAS=st_read('data/locational_factors/CHASClinics.kml')%>%
               st_transform(crs=3414)
```

## Supermarkets

```{r}
supermarket=st_read('data/locational_factors/SupermarketsKML.kml')%>%
  st_transform(crs=3414)
supermarket <- st_zm(supermarket, drop = TRUE, what = "ZM")
```

## MRT

```{r}
#| eval: false
mrt=st_read(dsn='data/locational_factors', layer='RapidTransitSystemStation')%>%
  st_transform(crs=3414)

Sys.setenv(OGR_GEOMETRY_ACCEPT_UNCLOSED_RING = "NO")

mrt <- mrt[!st_is_empty(mrt), ]

# Convert Polygon to Point
mrt <- st_centroid(mrt)

```
::: note-box
Generally, GDAL (Geospatial Data Abstraction Library) might accept polygons with unclosed rings which may result in invalid geometries. These cause issues when conducting spatial analysis and operations on R. Setting the `OGR_GEOMETRY_ACCEPT_UNCLOSED_RING`='NO' tells GDAL explicitly to reject these unclosed rings.
:::

Given we have modified the mrt data, we will create an RDS file to facilitate computational efficiency. The write_rds() function is used to create and store the RDS file on the local system. The read_rds() function is used to import it into our environment.

```{r}
#| eval: false
write_rds(mrt, 'data/rds/mrt.rds')
```

```{r}
mrt=read_rds('data/rds/mrt.rds')

```



## Bus Stops

```{r}
bus=st_read(dsn='data/locational_factors', layer='BusStop')%>%
  st_transform(crs=3414)
```

## Hawkers

```{r}
hawkers=st_read('data/locational_factors/HawkerCentresGEOJSON.geojson')%>%
  st_transform(crs=3414)
```

## Kindgergartens

```{r}
kindergartens=st_read('data/locational_factors/Kindergartens.geojson')%>%
  st_transform(crs=3414)
```

## Parks

```{r}
parks=st_read('data/locational_factors/Parks.geojson')%>%
  st_transform(crs=3414)
```

## Childcare

```{r}
childcare=st_read(dsn='data/locational_factors', layer='CHILDCARE')%>%
  st_transform(crs=3414)
```
:::

Now that we have imported relevant locational factors, we want to determine the proximity of flats to these factors. We will do so in the next section below.


# 3.2 Data Wrangling and Manipulation

We calculate the number of data points within a distance. We will use the st_buffer() function of the sf package for this.

::: note-box
if we set the `dist` argument to 1000, we create a buffer of 1KM around each point in the resale data-set.This allows us to determine the number of data-points of other Points of Interest within this zone.
:::

::: panel-tabset

## Defining Buffers

```{r}
# We first create a buffer. Alter this based on the input data. (eg: 200m for bus stops, 1000m for medical and care facilities, schools, parks and supermarkets)
buffer_200m=st_buffer(resale_sf, dist=200)

buffer_500m=st_buffer(resale_sf, dist=500)

buffer_1000m=st_buffer(resale_sf, dist=1000)

```

## Creating Point Counts

```{r}
# 200M
buffer_200m$bus_pts_count= lengths(
  st_intersects(buffer_200m, bus)
)

#500m
buffer_500m$hawker_pts_count= lengths(
  st_intersects(buffer_500m, hawkers)
)

# 1000M
buffer_1000m$chas_pts_count= lengths(
  st_intersects(buffer_1000m, CHAS)
)

buffer_1000m$eldercare_pts_count= lengths(
  st_intersects(buffer_1000m, eldercare)
)

buffer_1000m$supermarket_pts_count= lengths(
  st_intersects(buffer_1000m, supermarket)
)

buffer_1000m$park_pts_count= lengths(
  st_intersects(buffer_1000m, parks)
)

buffer_1000m$childcare_pts_count= lengths(
  st_intersects(buffer_1000m, childcare)
)

buffer_1000m$mrt_pts_count= lengths(
  st_intersects(buffer_1000m, mrt)
)

```

:::



## 3.2.1 Combining Data-frames

After creating the above data-frames (`buffer_200m`, `buffer_500m`, and `buffer_1000m`), we join all of these together to create one data-frame containing all relevant counts. 

The steps are as follows:

- The first step is to drop the geometry for a data-frame to facilitate the join. As seen below, we do it first for `buffer_1000m` and then combine it with `buffer_200m`. We use the st_drop_geometry() function for this. We select the columns we want to extract from buffer_1000m using the select function as well.

- Second, we use the left_join function and join `buffer_200m` with `buffer_1000m_no_geom` by using the common keys.

::: note-box
Do note that the bind_rows() simply stacks these data-frames.
:::
```{r}
# Drop geometry from `y` and select only the necessary columns
buffer_1000m_no_geom <- buffer_1000m %>%
  st_drop_geometry() %>%
  select(address, postal, chas_pts_count, eldercare_pts_count, park_pts_count, supermarket_pts_count, mrt_pts_count, childcare_pts_count)

# Perform a join on the common columns (address and postal)
combined_sf <- buffer_200m %>%
  left_join(buffer_1000m_no_geom, by = c("address", "postal"))

```


We repeat the above steps to join `buffer_500m`. We name the resulting data-frame `points_count` as it contains all relevant point counts that we generated.

```{r}
buffer_500m_no_geom <- buffer_500m %>%
  st_drop_geometry() %>%
  select(address, postal, hawker_pts_count)

# Perform a join on the common columns (address and postal)
points_count <- combined_sf %>%
  left_join(buffer_500m_no_geom, by = c("address", "postal"))
```

## 3.2.2 Distance Matrix

The next step of our analysis is to determine the proximity of each location to the closest locational factor. The distance will denoted in metres, as Singapores coordinates are projected in SVY21.

::: panel-tabset

## Eldercare

```{r}
#| eval: false
# Calculate distances between all houses and all eldercare facilities
dist_matrix_eldercare <- st_distance(points_count, eldercare)
# Get the minimum distance for each house
min_distances_eldercare <- apply(dist_matrix_eldercare, 1, min)
points_count$nearest_eldercare_dist <- min_distances_eldercare
```

## Childcare

```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_childcare <- st_distance(points_count, childcare)
# Get the minimum distance for each house
min_distances_childcare <- apply(dist_matrix_childcare, 1, min)
points_count$nearest_childcare_dist <- min_distances_childcare
```

## MRT

```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_mrt <- st_distance(points_count, mrt)
# Get the minimum distance for each house
min_distances_mrt <- apply(dist_matrix_mrt, 1, min)
points_count$nearest_mrt_dist <- min_distances_mrt
```

## Bus
```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_bus<- st_distance(points_count, bus)
# Get the minimum distance for each house
min_distances_bus <- apply(dist_matrix_bus, 1, min)
points_count$nearest_bus_dist <- min_distances_bus
```

## CBD
```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_cbd <- st_distance(points_count, cbd)
# Get the minimum distance for each house
min_distances_cbd <- apply(dist_matrix_cbd, 1, min)
points_count$nearest_cbd_dist <- min_distances_cbd
```

## CHAS
```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_chas <- st_distance(points_count, CHAS)
# Get the minimum distance for each house
min_distances_chas <- apply(dist_matrix_chas, 1, min)
points_count$nearest_chas_dist <- min_distances_chas
```

## Parks
```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_parks <- st_distance(points_count, parks)
# Get the minimum distance for each house
min_distances_parks <- apply(dist_matrix_parks, 1, min)
points_count$nearest_park_dist <- min_distances_parks
```

## Supermarket
```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_supermarket <- st_distance(points_count, supermarket)
# Get the minimum distance for each house
min_distances_supermarket <- apply(dist_matrix_supermarket, 1, min)
points_count$nearest_childcare_dist <- min_distances_supermarket
```

## Kindergartens

```{r}
#| eval: false
# Calculate distances between all houses and all childcare facilities
dist_matrix_kg <- st_distance(points_count, kindergartens)
# Get the minimum distance for each house
min_distances_kg <- apply(dist_matrix_kg, 1, min)
points_count$nearest_kindergarten_dist <- min_distances_kg
```

:::

We now create an RDS file using the write_rds() function to facilitate computational efficiency.

::: panel-tabset

## RDS File Creation

```{r}
#| eval: false
write_rds(points_count, 'data/rds/points_count.rds')

```

## Reading RDS File

```{r}
points_count=read_rds('data/rds/points_count.rds')

```

:::

We now join `points_count` back with `resale_tidy` in order to have all the details consolidated. We use the left_join() function and join using the common key of address. We will only keep selected rows for our analysis. We name this data-frame `resale_data`.

```{r}
resale_data= points_count %>%
  left_join(resale_tidy, by = "address")

```

We can check if the columns have been selected as intended by using the head() function as shown in the code chunk below.

```{r}
head(resale_data)

```

Be sure to go through and verify that there are no null values with regards to coordinates. If there are, then remove those columns.

Do refer to Hands-on exercise 1 to calculate the 'direct flying distance' between HDB block and locational factors such as CHAS clinics

```{r}
mdata=read_rds('data/rds/mdata.rds')
```



