---
title: "Take Home Exercise 2- Discovering impacts of COVID-19 on Thailand tourism economy at the province level using spatial and spatio-temporal statistics"
author: "Arjun Singh"
date: 2024-09-30
date-modified: "last-modified"
execute: 
  eval: true
  echo: true
  message: false
  freeze: true
  warning: false
format:
  html:
    css: styles.css 
---

# 2 Introduction

Tourism is one of Thailand’s largest industries, accounting for some 20% of the gross domestic product (GDP). In 2019, Thailand earned 90 billion US\$ from domestic and international tourism, but the COVID-19 pandemic caused revenues to crash to 24 billion US\$ in 2020.

The figure below shows the total revenue for the tourism sector from January 2019 until Feb 2023. The figure reveals that the revenue for the industry have been recovering gradually since September 2021.

![](images/clipboard-378385426.png)

However, it is important to note that the tourism economy of Thailand is not evenly distributed- not all provinces make a lot of revenue.

The figure below reveals that the tourism economy of Thailand is carried by five provinces, namely Bangkok, Phuket, Chiang Mai, Sukhothai and Phetchaburi.

![](images/clipboard-986836251.png)

# 2.1 Objectives

The objectives of this exercise are to understand:

-   if the key indicators of the tourism economy of Thailand are independent from space and space and time.

-   If the tourism economy is indeed spatial and spatio-temporal dependent. If so, then we would like to detect where the clusters and outliers are, as well as the emerging hot spot/cold spot areas.

# 2.2 Data and Packages

The data used for this exercise are as follows:

-   [Thailand Domestic Tourism Statistics](https://www.kaggle.com/datasets/thaweewatboy/thailand-domestic-tourism-statistics) which is sourced from Kaggle. 

    ![](images/Screenshot%202024-10-02%20180644.png)

-   [Thailand - Subnational Administrative Boundaries](https://data.humdata.org/dataset/cod-ab-tha?) which is sourced from Humanitarian Data Exchange. We will use the data at the province level (i.e: ADM1).

    ![](images/clipboard-3292985936.png)

The following packages are used:

-   **`sf`**: Provides simple features support for handling and analyzing spatial vector data in R.
-   **`spdep`**: A package for spatial dependence and spatial regression analysis, particularly for handling spatial weights.
-   **`tmap`**: A flexible visualization package for thematic maps, supporting both static and interactive mapping in R.
-   **`tidyverse`**: A collection of R packages designed for data science, emphasizing data manipulation, visualization, and functional programming.
-   **`knitr`**: A dynamic report generation tool in R, allowing for the integration of code, results, and narrative in reproducible documents.

We now load these packages into our environment by using the p_load() function of the pacman package.

```{r}
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
set.seed(123)
tmap_mode('plot')
```

## 2.1 Importing the data

### 2.1.1 Importing the aspatial data

We will now import the aspatial data by implementing the read_csv() function of the readr package as shown in the code chunk below.

```{r}
tourists=read_csv('data/aspatial/thailand_domestic_tourism_2019_2023.csv')
# Summing the 'value' based on 'province_eng' and 'variable'
summed_data <- tourists %>%
  group_by(province_eng, variable) %>%
  summarize(total_value = sum(value, na.rm = TRUE))

# View the result
head(summed_data)

```

### 2.1.2 Importing the geospatial data

We now import the geospatial data using the st_read() function of the sf package.

```{r}
province=st_read(dsn = "data/geospatial", 
                 layer = "tha_admbnda_adm1_rtsd_20220121")%>%
  select(1:5, 17)
```

We now check the CRS information using the st_crs() function of the sf package and transform the EPSG code using the st_transform() function if it is not 32647, the EPSG code of Thailand.

```{r}
st_crs(province)

st_transform(province, 32647)
```

### 2.1.3 Performing relational join

After performing consistency checks, we notice that the provinces aren't named correctly in our tourist data-set. We correct the names below.

```{r}
summed_data$province_eng <- gsub("Nong Bua Lamphu", "Nong Bua Lam Phu", summed_data$province_eng)
summed_data$province_eng <- gsub("Sisaket", "Si Sa Ket", summed_data$province_eng)
summed_data$province_eng <- gsub("Phang Nga", "Phangnga", summed_data$province_eng)
summed_data$province_eng <- gsub("Lopburi", "Lop Buri", summed_data$province_eng)
summed_data$province_eng <- gsub("Chonburi", "Chon Buri", summed_data$province_eng)
summed_data$province_eng <- gsub("Chainat", "Chai Nat", summed_data$province_eng)
summed_data$province_eng <- gsub("Buriram", "Buri Ram", summed_data$province_eng)
summed_data$province_eng <- gsub("Prachinburi", "Prachin Buri", summed_data$province_eng)
```

We will now join the aspatial and geospatial data by using the left_join() function of the package as showing in the code chunk below.

```{r}
pro_tourism=left_join(summed_data, province, by= c("province_eng"="ADM1_EN"))
```

# 2.3 Exploratory Data Analysis

## 2.3.1 Visualizing regional indicators

After successfully completing the relational join, we can now plot a choropleth map to visualize the tourism in each province in Thailand using various functions of the tmap package.

#### 2.3.1.1 Number of tourists

We first take a look at the number of tourists, both foreign and domestic, across all provinces in Thailand.

::: panel-tabset
## Number of Foreign Tourists

```{r}
tourist_foreign=pro_tourism%>%
  filter(variable=='no_tourist_foreign')
profit_foreigners=st_as_sf(tourist_foreign)

tourist_foreign=st_as_sf(tourist_foreign)


# Create the interactive basemap
basemap01 <- tm_shape(profit_foreigners) +
  tm_polygons(col = "total_value", palette = "Blues", style= 'jenks')+
  tm_text("province_eng", size = 0.3) 


# Display the interactive map
basemap01
```

## Number of Domestic Tourists

```{r}
tourist_domestic=pro_tourism%>%
  filter(variable=='no_tourist_foreign')%>%
  filter(!st_is_empty(geometry))
profit_foreigners=st_as_sf(tourist_domestic)

tourist_domestic=st_as_sf(tourist_domestic)


# Create the interactive basemap
basemap02 <- tm_shape(tourist_domestic) +
  tm_polygons(col = "total_value", palette = "Blues", style='jenks')+
  tm_text("province_eng", size = 0.3) 

# Display the interactive map
basemap02
```
:::

#### 2.3.1.2 Revenue

We now take a look at the revenue generated by foreign and domestic tourists in Thailand

::: panel-tabset
## Revenue generated by Foreigners

```{r}
#| cache: true
profit_foreigners=pro_tourism%>%
  filter(variable=='net_profit_foreign')
profit_foreigners=st_as_sf(profit_foreigners)
  


# Create the interactive basemap
basemap <- tm_shape(profit_foreigners) +
  tm_polygons(col = "total_value", palette = "Blues", style= 'jenks') +
  tm_text("province_eng", size = 0.5)

# Display the interactive map
basemap


```

## Revenue generated by Domestic Tourists

```{r}
#| cache: true
profit_domestic=pro_tourism%>%
  filter(variable=='net_profit_thai')
profit_foreigners=st_as_sf(profit_domestic)

profit_domestic=st_as_sf(profit_domestic)


# Create the interactive basemap
basemap2 <- tm_shape(profit_domestic) +
  tm_polygons(col = "total_value", palette = "Blues", style='jenks') +
  tm_text("province_eng", size = 0.5)

# Display the interactive map
basemap2

```
:::

Bangkok seems to be the most lucrative province for both foreign and domestic tourists.

```{r}
#| eval: false
#| cache: true
basemap <- tm_shape(profit_domestic) +
  tm_polygons() +
  tm_text("province_eng", size=0.5)

gdppc <- qtm(profit_domestic, "total_value")
tmap_arrange(basemap, gdppc, asp=1, ncol=2)
```

# 2.4 Spatial Analysis

We now implement the **poly2nb()** function of the **spdep** package to compute contiguity weight matrices for the study area selected.

Using this function, we are able to build a ‘neighbors list’ based on regions with contiguous boundaries.

In this function, we will pass an argument, ‘queen’, that can be set as either TRUE (default) or FALSE. If the ‘queen’ argument is not explicitly set to FALSE, the function returns a list of first order neighbors using the Queen criteria.

[You may refer to the `spdep` package documentation here](https://cran.r-project.org/web/packages/spdep/spdep.pdf) to learn more about its functions and arguments.

## 2.4.1 Spatial Weights

### 2.4.1.1 Computing Contiguity Spatial Weights

We use the poly2nb() function as shown in the code chunk below. Using this, we are able to compute a Queen contiguity weight matrix.

```{r}
#| eval: false
# Rook contiguity
wm_r <- poly2nb(profit_foreigners, queen=FALSE)
write_rds(wm_r, 'data/rds/wm_r_pro_foreign')

# Queen Contiguity
wm_q <- poly2nb(profit_foreigners, queen=TRUE)
write_rds(wm_q, 'data/rds/wm_q_pro_foreign')
```

::: panel-tabset
## Rook Contiguity

```{r}
wm_r_pro_foreign=read_rds("data/rds/wm_r_pro_foreign")
summary(wm_r_pro_foreign)
```

## Queen Contiguity

```{r}
wm_q_pro_foreign=read_rds("data/rds/wm_q_pro_foreign")
summary(wm_q_pro_foreign)
```
:::

We now repeat the same steps for Domestic tourists.

```{r}
#| eval: false
# Rook contiguity
wm_r <- poly2nb(profit_domestic, queen=FALSE)
write_rds(wm_r, 'data/rds/wm_r_pro_dom')

# Queen Contiguity
wm_q <- poly2nb(profit_domestic, queen=TRUE)
write_rds(wm_q, 'data/rds/wm_q_pro_dom')
```

We now look at a summary of both using the code chunks below.

::: panel-tabset
## Rook Contiguity

```{r}
wm_r_pro_dom=read_rds("data/rds/wm_r_pro_dom")
summary(wm_r_pro_dom)
```

## Queen Contiguity

```{r}
wm_q_pro_dom=read_rds("data/rds/wm_q_pro_dom")
summary(wm_q_pro_dom)
```
:::

### 2.4.1.2 Visualizing Contiguity Spatial Weights

A connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons in this situation, so we need to ensure that our points are in order to produce our connectivity graphs.

Usually, the method of choice will be polygon centroids. We calculate using the sf package before moving onto the graphs. Getting latitude and longitude of the Polygon Centroids.

We need points to associate with each polygon before we can make our connectivity graph. It won’t be as simple as applying the st_centroid() function of the sf sf object: *`us.bound`*. We need the coordinates in a separate data-frame for this to work.

To do this, we will use a mapping function which will apply a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of `us.bound`.

The function that we implement in this situation will be st_centroid().

We will be using the map_dbl variation of map from the purrr package.

::: panel-tabset
## Longitude & Latitude of Foreign Travellers

We start by extracting the longitude and latitude values for foreign travellers.

```{r}
longitude_profit_foreign= map_dbl(profit_foreigners$geometry, ~st_centroid(.x)[[1]])
latitude_profit_foreign= map_dbl(profit_foreigners$geometry, ~st_centroid(.x)[[2]])
```

Now that we have the latitude and longitude values, we can use the cbind() function to put the longitude and latitude values into the same object, `coords`.

```{r}
coords_profit_foreign <- cbind(longitude_profit_foreign, latitude_profit_foreign)
```

We use the head() function to verify if `coords` is in the correct format.

```{r}
head(coords_profit_foreign)
```

## Longitude and Latitude of Domestic Travellers

```{r}
#| eval: false
longitude_profit_domestic
```

```{r}
#| eval: false
latitude_profit_domestic=
```

We now create the coords object.

```{r}
#| eval: false
coords_profit_domestic
```
:::

We can now visualize it using the plot() function as shown in the following code chunks.

::: panel-tabset
## Profits from foreign travellers

```{r}
plot(profit_foreigners$geometry, border="lightgrey")
plot(wm_r_pro_foreign, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = "purple")
```

```{r}
plot(profit_foreigners$geometry, border="lightgrey")
plot(wm_q_pro_foreign, coords_profit_foreign, pch = 19, cex = 0.6, add = TRUE, col = "purple")
```

## Profits from domestic travellers

```{r}
#| eval: false
plot(profit_domestic$geometry, border="lightgrey")
plot(wm_r_pro_domestic, coords_profit_domestic, pch = 19, cex = 0.6, add = TRUE, col = "purple")
```
:::

### 2.4.1.3 Computing Distance Based Neighbors

In order to derive distance-based weight matrices, we will implement the **dnearneigh()** function of the **spdep** package.

This function identifies neighbors of region points by Euclidean Distance with a distance band with lower d1 and upper d2 bounds controlled by the `bounds=` argument.

If un-projected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and `longlat=TRUE,` great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.

#### 2.4.1.3.1 Determining cut-off distance

We must first determine the upper limit for the distance band by using the steps shown below:

-   **Find k Nearest Neighbours**: Use **`knearneigh()`** from the **`spdep`** package to get a matrix of indices for the k nearest neighbours of each point.

-   **Convert to Neighbours List**: Convert the **`knn`** object returned by **`knearneigh()`** into a neighbours list of class **`nb`** using **`knn2nb()`**. This list contains integer vectors with neighbour region number IDs.

-   **Calculate Edge Lengths**: Use **`nbdists()`** from **`spdep`** to return the lengths of neighbour relationship edges. The function returns distances in the units of the coordinates if projected, otherwise in kilometers.

-   **Flatten the List**: Remove the list structure of the returned object using **`unlist()`**

::: panel-tabset
## Profits from foreign travellers

```{r}
k1_pro_foreign <- knn2nb(knearneigh(coords_profit_foreign))
k1dists_pro_foreign <- unlist(nbdists(k1_pro_foreign, coords_profit_foreign, longlat = TRUE))
summary(k1dists_pro_foreign)
```

From the output above, we can infer that the largest first nearest neighbor distance is just under 125KM. Using this value, 125KM, as the upper threshold gives certainty that all units will have at least one neighbor.

## Profits from domestic travellers

```{r}

```
:::

#### 2.4.1.3.2 Computing Distance Based Weight Matrix

We now implement the dnearneigh() function to compute the distance weight matrix.

```{r}
wm_d62_pro_foreign <- dnearneigh(coords_profit_foreign, 0, 111, longlat = TRUE)
wm_d62_pro_foreign
```

::: insights-box
From the output above, we infer that there are 69 distinct regions, as we identified earlier. There are 368 connections between regions where the distance is within the threshold that we have set. 7.73% of all possible region pairs have a connection. On average, each region is connected to approximately 5.3 other regions.
:::

We now use the combination of table() and card() functions from the spdep package to display the structure of the weight matrix.

```{r}
table(profit_foreigners$province_eng, card(wm_d62_pro_foreign))
```

Next, we implement the n.comp.nb() function to identify the number of connected components in a neighbor list object of class nb.

::: note-box
Note: A connected component is a subset of regions where each region is reachable from any other region within the same subset. The function returns an object that includes the number of connected components (`nc`) and a vector indicating the component membership for each region.
:::

```{r}
n_comp_pro_foreign <- n.comp.nb(wm_d62_pro_foreign)
n_comp_pro_foreign$nc
```

```{r}
table(n_comp_pro_foreign$comp.id)
```

#### 2.4.1.3.3 **Plotting fixed distance weight matrix**

We now plot the distance weight matrix using the plot() function.

```{r}
plot(profit_foreigners$geometry, border="lightgrey")
plot(wm_d62_pro_foreign, coords_profit_foreign, add=TRUE)
plot(k1_pro_foreign, coords_profit_foreign, add=TRUE, col="purple", length=0.08)
```

As identified earlier, we see two distinct groups. The upper 63 and the bottom 14.

```{r}
par(mfrow=c(1,2))
plot(profit_foreigners$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1_pro_foreign, coords_profit_foreign, add=TRUE, col="red", length=0.08)
plot(profit_foreigners$geometry, border="lightgrey", main="Distance link")
plot(wm_d62_pro_foreign, coords_profit_foreign, add=TRUE, pch = 19, cex = 0.6)
```

### 2.4.1.4 **Weights based on Inversed Distance Weighting (IDW)**

We first compute the distances between areas by implementing the **nbdists()** function of the **spdep** package.

```{r}
dist_pro_foreign <- nbdists(wm_q_pro_foreign, coords_profit_foreign, longlat = TRUE)
ids_pro_foreign <- lapply(dist_pro_foreign, function(x) 1/(x))
ids_pro_foreign
```

### 2.4.1.5 **Row-Standardized Weights Matrix**

We now need to assign weights to each neighboring polygon. We use equal weights (style=“W”), where each neighboring polygon is assigned a weight of 1 divided by the number of neighbors.

This means each neighboring county’s weight is calculated as 1/(# of neighbors), and these weights are then used to sum the weighted income values.

While this method is intuitive for summarizing neighbors’ values, it has a drawback: polygons at the edges of the study area may rely on fewer neighbors, potentially skewing the spatial autocorrelation results.

::: note-box
Note: For simplicity, we’ll use the style=“W” option in this example, but be aware that more robust options, such as style=“B”, are available.
:::

```{r}
rswm_q_pro_foreign <- nb2listw(wm_q_pro_foreign, style="W", zero.policy = TRUE)
rswm_q_pro_foreign
```

Setting the argument `zero.policy` to TRUE allows for lists of non-neighbors. This should be used with caution as users may not be aware of missing neighbors in their data however setting `zero,policy` to FALSE would return an error.

::: insights-box
The `nb2listw()` function requires an input of class `nb`, representing a neighborhood object. The function’s two key arguments are `style` and `zero.policy`.

-   The `style` argument defines how the weights are calculated. It can take several values:

    -   `"B"`: Binary coding, where weights are either 0 or 1.

    -   `"W"`: Row-standardized, where the sum of weights across all neighbors equals 1.

    -   `"C"`: Globally standardized, where the sum of weights across all neighbors equals the total number of neighbors.

    -   `"U"`: A variation of `"C"`, where weights are normalized by the number of neighbors.

    -   `"S"`: A variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999), which adjusts weights based on the number of neighbors.

-   The `zero.policy` argument, when set to `TRUE`, handles regions with no neighbors by assigning them a weight vector of zero length. This results in a spatial lag value of zero for regions without neighbors, which may or may not be a suitable assumption depending on the context. For such regions, the spatially lagged value is computed as the sum of the products of a zero vector with any numerical vector `x`, effectively setting the lagged value to zero for those regions.
:::

The code chunk below is implemented to check the weights of the first polygons three neighbors type:

```{r}
rswm_q_pro_foreign$weights[10]
```

::: insights-box
Each neighbor is assigned a 0.33 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.
:::

Using the same method, we derive a row standardized distance weight matrix by using the code chunk below.

```{r}
rswm_ids_pro_foreign <- nb2listw(wm_q_pro_foreign, glist=ids_pro_foreign, style="B", zero.policy=TRUE)
rswm_ids_pro_foreign

```

### 2.4.1.6 Application of Spatial Weight Matrix

We now create four different spatial lagged variables:

-   spatial lag with row-standardized weights

-   spatial lag as a sum of neighbouring values

-   spatial window average

-   spatial window sum

#### 2.4.1.6.1 **Spatial Lag With Row-Standardized Weights**

We now compute the average neighbor profit value for each polygon. We often refer to these values as Spatially Lagged Values.

```{r}
pro_foreign.lag <- lag.listw(rswm_q_pro_foreign, profit_foreigners$total_value)
pro_foreign.lag
```

We can append the spatially lagged profit values onto our `profit_foreigners` sf data-frame by using the code chunk shown below.

```{r}
lag.list_pro_foreign <- list(profit_foreigners$province_eng, lag.listw(rswm_q_pro_foreign, profit_foreigners$total_value))
lag.res_pro_foreign <- as.data.frame(lag.list_pro_foreign)
colnames(lag.res_pro_foreign) <- c("province_eng", "lag Profit")
profit_foreigners <- left_join(profit_foreigners,lag.res_pro_foreign)
```

We now plot the actual profit and spatial lag profits side by side to facilitate comparison.

```{r}
pro_foreign <- qtm(profit_foreigners, "total_value")
lag_pro_foreign <- qtm(profit_foreigners, "lag Profit")
tmap_arrange(pro_foreign, lag_pro_foreign, asp=1, ncol=2)
```

We see a difference in the surrounding regions of Bangkok as well as Mae Hong Son, all of which are in a higher band as compared to the non-spatially lagged values.

#### 2.4.1.6.2 **Spatial Window Sum**

The spatial window sum is the counter part of the window average, but without using row-standardized weights.

To add the diagonal element to the neighbour list, we just need to use *include.self()* from **spdep**.

```{r}
wm_qs_profit <- include.self(wm_q_pro_foreign)
wm_qs_profit
```

We now assign binary weights to the neighbour structure that includes the diagonal element.

```{r}
b_weights <- lapply(wm_qs_profit, function(x) 0*x + 1)
b_weights[1]
```

Notice that now \[1\] has four neighbours instead of three.

Again, we use *nb2listw()* and *glist()* to explicitly assign weight values.

```{r}
b_weights2 <- nb2listw(wm_qs_profit, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With our newly obtained weight structure, we can compute the lag variable with *lag.listw()*.

```{r}
w_sum_profit <- list(profit_foreigners$province_eng, lag.listw(b_weights2, profit_foreigners$total_value))
w_sum_profit
```

Next, we will convert the lag variable listw object into a data.frame by using *as.data.frame()*.

```{r}
w_sum_profit.res <- as.data.frame(w_sum_profit)
colnames(w_sum_profit.res) <- c("province_eng", "w_sum Profit")
```

::: note-box
Do note that the second command line on the code chunk above renames the field names of *w_sum_profit.res* object into province_eng and *w_sum Profit* respectively.
:::

Next, the code chunk below will be used to append w_sum *Profit* values onto our profit sf data.frame by using left_join() of **dplyr** package.

```{r}
profit_foreigners <- left_join(profit_foreigners, w_sum_profit.res)
```

To compare the values of lag Profit and Spatial window average, the `kable()` function of the Knitr package is used to prepare a table using the code chunk below.

```{r}
profit_foreigners %>%
  select("province_eng", "total_value", "w_sum Profit") %>%
  kable()
```

We now plot the actual profit and w_sum_profit maps next to each other using the qtm() function of the tmap package.

```{r}
# Create the first map for 'total_value' using Jenks classification
profit_map <- tm_shape(profit_foreigners) +
              tm_polygons("total_value", style = "jenks", palette = "Blues", title = "Total Value") +
              tm_layout(legend.outside = TRUE)

# Create the second map for 'w_sum Profit' using Jenks classification
w_sum_profit_map <- tm_shape(profit_foreigners) +
                    tm_polygons("w_sum Profit", style = "jenks", palette = "Reds", title = "W Sum Profit") +
                    tm_layout(legend.outside = TRUE)
tmap_arrange(profit_map, w_sum_profit_map, ncol = 2)

```

## 2.4.2 Global Measures of Spatial Autocorrelation

::: panel-tabset
### 2.4.2.1 Maron's I test

We now conduct Moran’s I statistics testing by using the **moran.test()** function of the **spdep** package.

::: note-box
Statistical tests are conducted at a 5% significance level.
:::

The hypotheses for the test are as follows:

-   H0: Regions with similar levels of profit from tourism are randomly distributed.

-   H1: Regions with similar levels of profit from tourism are not randomly distributed and exhibit spatial clustering.

```{r}
moran.test(profit_foreigners$total_value, 
           listw=rswm_q_pro_foreign, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

From the output above, we can infer the following:

-   The p-value 0.7224\>0.05, indicating that the observed spatial autocorrelation is not statistically significant.

-   Moran’s I statistic: The observed value of -0.037 indicates **no spatial autocorrelation**, meaning that regions with similar levels of profit from tourism are randomly distributed.

There isn't sufficient evidence to reject H0 and we conclude that there is no spatial clustering with regards to profits from tourism in Thailand.

::: note-box
If Morans I Statistic is = 0, there is Complete Random Spatial Distribution.
:::

#### 2.4.2.1.1 Monte Carlo Moran's I

We now implement the moran.mc() function of the spdep package. In this scenario, we will run 1000 simulations.

```{r}
bperm= moran.mc(profit_foreigners$total_value, 
           listw=rswm_q_pro_foreign, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

::: insights-box
From the above output, notice that the observed rank is 326. This indicates that the observed Moran's I value of -0.037893 is not 'unusual' compared to the distribution that was generated by the simulations run. This further supports the high p-value and reinforces our earlier conclusion that there is no significant spatial autocorrelation in the data.
:::

We visualize the test statistics obtained from the above simulation by implementing the below code chunk.

::: panel-tabset
## Summary Statistics

```{r}
# Mean
mean(bperm$res[1:999])

# Variance
var(bperm$res[1:999])

# Summary
summary(bperm$res[1:999])
```

## The plot

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=20, 
     xlab="Simulated Moran's I")
abline(v=0, 
       col="red") 
```
:::

### 2.4.2.2 Geary's C

We now implement a further test to verify if our findings from the above test are indeed correct.

The Geary’s C test for spatial autocorrelation is implemented by using the **geary.test()** function of the **spdep** package.

```{r}
geary.test(profit_foreigners$total_value, listw=rswm_q_pro_foreign)
```

We once again see that the p-value (0.8784) is greater than 0.05. We do not have sufficient evidence to reject the null hypothesis. In fact, from the Geary C statistic value, we infer that there is actually **negative** spatial autocorrelation.

#### 2.4.2.2.1 Monte Carlo Geary's C

We implement the the geary.mc() function of the spdep package to conduct 1000 simulations.

```{r}
bperm=geary.mc(profit_foreigners$total_value, listw=rswm_q_pro_foreign, 
               nsim=999)
bperm
```

The simulations above reinforce our earlier conclusion.
:::

### 2.4.2.3 Spatial Correlogram

Spatial correlograms are a powerful tool for analyzing patterns of spatial autocorrelation in your data or model residuals. They illustrate how the correlation between pairs of spatial observations changes as the distance (or lag) between them increases. Essentially, they plot an index of autocorrelation, such as Moran’s I or Geary’s C, against distance.

While correlograms are not as central to geostatistics as variograms—an essential concept in that field—they offer valuable insights as an exploratory and descriptive tool. In fact, for examining spatial autocorrelation, correlograms often provide more detailed information than variograms, making them particularly useful for initial spatial data analysis.

::: panel-tabset
## Moran's I Correlogram

We implement the sp.correlogram() function of the spdep package to compute a 6-lag spatial correlogram of profit from tourism in Thailand. The global spatial autocorrelation used in Moran’s I.

The **plot()** of base Graph is then used to plot the output.

```{r}
MI_corr <- sp.correlogram(wm_q_pro_foreign, 
                          profit_foreigners$total_value, 
                          order=6, 
                          method="I", 
                          style="W", zero.policy = TRUE)
plot(MI_corr)
```

The plot above may not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.

```{r}
print(MI_corr)
```

From above, we can conclude that there is NO spatial autocorrelation.

## Geary's C Correlogram

We implement the `sp.correlogram()` of **spdep** package is used to compute a 6-lag spatial correlogram of total_value, profit. The global spatial autocorrelation used in Geary’s C. The **plot()** of base Graph is then used to plot the output.

```{r}
GC_corr <- sp.correlogram(wm_q_pro_foreign, 
                          profit_foreigners$total_value, 
                          order=6, 
                          method="C", 
                          style="W", zero.policy = TRUE)
plot(GC_corr)
```

Similar to the step done for Moran's I, we will print out the analysis report by using the code chunk below.

```{r}
print(GC_corr)
```

Indeed, our findings are reinforced.
:::

## 2.4.3 Local Indicators of Spatial Association

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of profits from tourism across Thailand, local clusters in profit mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.

### 2.4.3.1 Computing Local Moran's I

We implement the localmoran() function of spdep compute the local Moran’s I statistic. This function helps us compute li values, given a set of zi values and a listw object providing neighbor weighting information for the polygon associated with the zi values.

We compute Local Moran's I for Profits from Tourism at the County Level

```{r}
fips <- order(profit_foreigners$province_eng)
localMI <- localmoran(profit_foreigners$total_value, rswm_q_pro_foreign)
head(localMI)
```

::: insights-box
*localmoran()* function returns a matrix of values whose columns are:

-   Ii: the local Moran’s I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local moran statistic

-   Pr(): the p-value of local moran statistic
:::

We now use the printCoefmat() to display the content of the local Moran matrix that we created.

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=profit_foreigners$province_eng[fips]),
  check.names=FALSE)
```

#### 2.4.3.1.1 Mapping the Local Moran's I

Before we map the local Moran’s I map, it is wise to append the local Moran’s data-frame (`localMI`) onto the profit SpatialPolygonDataFrame.

```{r}
profit.localMI <- cbind(profit_foreigners,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

::: panel-tabset
## Mapping the Local Moran's I

We now make use of the tmap package and its choropleth mapping functions to plot the local Moran’s I values.

```{r}
tm_shape(profit.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)
```

## Mapping Local Moran's P-values

The Choropleth reveals the presence of both positive, as well as negative I values. This indicates that there are varying levels of spatial autocorrelation, however, we must examine the p-values for these I values to check for statistical significance.

We use the tmap package to draw a choropleth map of Moran’s I p-values.

```{r}
tm_shape(profit.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

```
:::

We map both of the above plots side by side for comparison.

```{r}
localMI.map <- tm_shape(profit.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty", 
          title = "local moran statistics") +
  tm_borders(alpha = 0.5)

pvalue.map <- tm_shape(profit.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5)

tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

### 2.4.3.2 Creating a LISA Cluster Map

### 2.4.3.3 Hot and Cold Spot Analysis

#### 2.4.3.3.1 Emerging Hot-Spot Analysis

### 2.4.4 Gi Statistics
